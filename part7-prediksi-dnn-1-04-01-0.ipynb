{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51498646",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-04T10:52:47.352638Z",
     "iopub.status.busy": "2021-11-04T10:52:47.350875Z",
     "iopub.status.idle": "2021-11-04T10:52:55.227376Z",
     "shell.execute_reply": "2021-11-04T10:52:55.226539Z",
     "shell.execute_reply.started": "2021-11-04T10:48:34.207266Z"
    },
    "papermill": {
     "duration": 7.907628,
     "end_time": "2021-11-04T10:52:55.227588",
     "exception": false,
     "start_time": "2021-11-04T10:52:47.319960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Melakukan impor libraries yang diperlukan untuk membangun model dan prediksi data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13031c0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:52:55.280368Z",
     "iopub.status.busy": "2021-11-04T10:52:55.279706Z",
     "iopub.status.idle": "2021-11-04T10:52:55.281791Z",
     "shell.execute_reply": "2021-11-04T10:52:55.281167Z",
     "shell.execute_reply.started": "2021-11-04T04:01:49.258697Z"
    },
    "papermill": {
     "duration": 0.030055,
     "end_time": "2021-11-04T10:52:55.281955",
     "exception": false,
     "start_time": "2021-11-04T10:52:55.251900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mencatat waktu dimulainya keseluruhan program model dan prediksi data.\n",
    "global_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ddd400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:52:55.333510Z",
     "iopub.status.busy": "2021-11-04T10:52:55.332843Z",
     "iopub.status.idle": "2021-11-04T10:52:55.335422Z",
     "shell.execute_reply": "2021-11-04T10:52:55.334912Z",
     "shell.execute_reply.started": "2021-11-04T10:04:54.282612Z"
    },
    "papermill": {
     "duration": 0.030823,
     "end_time": "2021-11-04T10:52:55.335575",
     "exception": false,
     "start_time": "2021-11-04T10:52:55.304752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menetapkan nilai seed untuk reproduksi model.\n",
    "seed = 2021\n",
    "def set_seed(seed = seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = str(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd83d808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:52:55.385822Z",
     "iopub.status.busy": "2021-11-04T10:52:55.383807Z",
     "iopub.status.idle": "2021-11-04T10:52:55.387401Z",
     "shell.execute_reply": "2021-11-04T10:52:55.387901Z",
     "shell.execute_reply.started": "2021-11-04T10:04:57.579289Z"
    },
    "papermill": {
     "duration": 0.029606,
     "end_time": "2021-11-04T10:52:55.388066",
     "exception": false,
     "start_time": "2021-11-04T10:52:55.358460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menentukan indeks fold, kode penamaan program, banyak epoch, dan ukuran batch.\n",
    "fold_index = 0\n",
    "codename = '1_04_01_{}'.format(fold_index)\n",
    "epochs = 128\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "844d4573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:52:55.438161Z",
     "iopub.status.busy": "2021-11-04T10:52:55.437185Z",
     "iopub.status.idle": "2021-11-04T10:54:00.251073Z",
     "shell.execute_reply": "2021-11-04T10:54:00.251606Z",
     "shell.execute_reply.started": "2021-11-04T10:05:01.137768Z"
    },
    "papermill": {
     "duration": 64.840351,
     "end_time": "2021-11-04T10:54:00.251801",
     "exception": false,
     "start_time": "2021-11-04T10:52:55.411450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyusun data training.\n",
    "df_train = pd.read_csv('../input/bdc-sd2021-train-tabular-data/train_gray.csv')\n",
    "fake_train = pd.DataFrame(np.array(df_train).reshape((2305, 128, 128))[:, :, ::-1].reshape((2305, 128*128)))\n",
    "fake_train.columns = df_train.columns\n",
    "df_train = pd.concat([df_train, fake_train], ignore_index = True)\n",
    "del fake_train\n",
    "\n",
    "# Menyusun data testing.\n",
    "df_test = pd.read_csv('../input/bdc-sd2021-test-tabular-data/test_gray.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7048c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:54:00.303242Z",
     "iopub.status.busy": "2021-11-04T10:54:00.302451Z",
     "iopub.status.idle": "2021-11-04T10:54:00.904943Z",
     "shell.execute_reply": "2021-11-04T10:54:00.905447Z",
     "shell.execute_reply.started": "2021-11-04T10:06:09.166332Z"
    },
    "papermill": {
     "duration": 0.630308,
     "end_time": "2021-11-04T10:54:00.905615",
     "exception": false,
     "start_time": "2021-11-04T10:54:00.275307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16374</th>\n",
       "      <th>16375</th>\n",
       "      <th>16376</th>\n",
       "      <th>16377</th>\n",
       "      <th>16378</th>\n",
       "      <th>16379</th>\n",
       "      <th>16380</th>\n",
       "      <th>16381</th>\n",
       "      <th>16382</th>\n",
       "      <th>16383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.183857</td>\n",
       "      <td>0.139013</td>\n",
       "      <td>0.098655</td>\n",
       "      <td>0.116592</td>\n",
       "      <td>0.121076</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.116592</td>\n",
       "      <td>0.094170</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>0.076233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242152</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.121076</td>\n",
       "      <td>0.134529</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.174888</td>\n",
       "      <td>0.152466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.827411</td>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.827411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319797</td>\n",
       "      <td>0.294416</td>\n",
       "      <td>0.253807</td>\n",
       "      <td>0.208122</td>\n",
       "      <td>0.147208</td>\n",
       "      <td>0.116751</td>\n",
       "      <td>0.096447</td>\n",
       "      <td>0.065990</td>\n",
       "      <td>0.055838</td>\n",
       "      <td>0.040609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.559091</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.486364</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.368182</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.154167</td>\n",
       "      <td>0.154167</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.893023</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.804651</td>\n",
       "      <td>0.879070</td>\n",
       "      <td>0.869767</td>\n",
       "      <td>0.637209</td>\n",
       "      <td>0.479070</td>\n",
       "      <td>0.269767</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106977</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.018605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.356828</td>\n",
       "      <td>0.370044</td>\n",
       "      <td>0.396476</td>\n",
       "      <td>0.409692</td>\n",
       "      <td>0.396476</td>\n",
       "      <td>0.422907</td>\n",
       "      <td>0.471366</td>\n",
       "      <td>0.515419</td>\n",
       "      <td>0.480176</td>\n",
       "      <td>0.436123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.039648</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.035242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.306977</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.339535</td>\n",
       "      <td>0.330233</td>\n",
       "      <td>0.320930</td>\n",
       "      <td>0.367442</td>\n",
       "      <td>0.367442</td>\n",
       "      <td>0.316279</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>0.339535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060465</td>\n",
       "      <td>0.074419</td>\n",
       "      <td>0.065116</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.083721</td>\n",
       "      <td>0.065116</td>\n",
       "      <td>0.055814</td>\n",
       "      <td>0.097674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>0.157258</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.137097</td>\n",
       "      <td>0.108871</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.068548</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.060484</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100806</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.044355</td>\n",
       "      <td>0.044355</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.052419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4610 rows × 16384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.183857  0.139013  0.098655  0.116592  0.121076  0.103139  0.116592   \n",
       "1     0.857868  0.857868  0.857868  0.857868  0.857868  0.857868  0.842640   \n",
       "2     0.018182  0.013636  0.013636  0.018182  0.018182  0.018182  0.018182   \n",
       "3     0.162500  0.162500  0.154167  0.154167  0.166667  0.187500  0.216667   \n",
       "4     0.893023  0.860465  0.804651  0.879070  0.869767  0.637209  0.479070   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4605  0.090476  0.076190  0.095238  0.114286  0.090476  0.109524  0.076190   \n",
       "4606  0.356828  0.370044  0.396476  0.409692  0.396476  0.422907  0.471366   \n",
       "4607  0.306977  0.279070  0.339535  0.330233  0.320930  0.367442  0.367442   \n",
       "4608  0.145000  0.240000  0.290000  0.295000  0.230000  0.170000  0.185000   \n",
       "4609  0.157258  0.161290  0.137097  0.108871  0.112903  0.096774  0.068548   \n",
       "\n",
       "             7         8         9  ...     16374     16375     16376  \\\n",
       "0     0.094170  0.089686  0.076233  ...  0.242152  0.089686  0.103139   \n",
       "1     0.827411  0.842640  0.827411  ...  0.319797  0.294416  0.253807   \n",
       "2     0.018182  0.013636  0.018182  ...  0.568182  0.559091  0.536364   \n",
       "3     0.254167  0.233333  0.183333  ...  0.666667  0.675000  0.745833   \n",
       "4     0.269767  0.186047  0.186047  ...  0.106977  0.032558  0.027907   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4605  0.061905  0.052381  0.076190  ...  0.157143  0.114286  0.133333   \n",
       "4606  0.515419  0.480176  0.436123  ...  0.030837  0.035242  0.030837   \n",
       "4607  0.316279  0.283721  0.339535  ...  0.060465  0.074419  0.065116   \n",
       "4608  0.200000  0.200000  0.230000  ...  0.015000  0.015000  0.015000   \n",
       "4609  0.072581  0.060484  0.072581  ...  0.100806  0.064516  0.044355   \n",
       "\n",
       "         16377     16378     16379     16380     16381     16382     16383  \n",
       "0     0.121076  0.134529  0.156951  0.156951  0.156951  0.174888  0.152466  \n",
       "1     0.208122  0.147208  0.116751  0.096447  0.065990  0.055838  0.040609  \n",
       "2     0.518182  0.486364  0.436364  0.368182  0.254545  0.113636  0.045455  \n",
       "3     0.887500  0.908333  0.900000  0.916667  0.945833  0.966667  0.966667  \n",
       "4     0.018605  0.004651  0.000000  0.000000  0.004651  0.009302  0.018605  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4605  0.047619  0.061905  0.061905  0.052381  0.042857  0.042857  0.042857  \n",
       "4606  0.026432  0.022026  0.017621  0.039648  0.026432  0.017621  0.035242  \n",
       "4607  0.051163  0.051163  0.046512  0.083721  0.065116  0.055814  0.097674  \n",
       "4608  0.015000  0.015000  0.015000  0.015000  0.010000  0.010000  0.010000  \n",
       "4609  0.044355  0.040323  0.032258  0.020161  0.012097  0.016129  0.052419  \n",
       "\n",
       "[4610 rows x 16384 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan normalisasi pada data training.\n",
    "scaler = MinMaxScaler(copy = False)\n",
    "scaler.fit_transform(df_train.T)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e816427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:54:00.956825Z",
     "iopub.status.busy": "2021-11-04T10:54:00.955818Z",
     "iopub.status.idle": "2021-11-04T10:54:01.113879Z",
     "shell.execute_reply": "2021-11-04T10:54:01.113210Z",
     "shell.execute_reply.started": "2021-11-04T10:06:14.713247Z"
    },
    "papermill": {
     "duration": 0.184378,
     "end_time": "2021-11-04T10:54:01.114020",
     "exception": false,
     "start_time": "2021-11-04T10:54:00.929642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16374</th>\n",
       "      <th>16375</th>\n",
       "      <th>16376</th>\n",
       "      <th>16377</th>\n",
       "      <th>16378</th>\n",
       "      <th>16379</th>\n",
       "      <th>16380</th>\n",
       "      <th>16381</th>\n",
       "      <th>16382</th>\n",
       "      <th>16383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347619</td>\n",
       "      <td>0.361905</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.257143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417355</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.471074</td>\n",
       "      <td>0.508264</td>\n",
       "      <td>0.475207</td>\n",
       "      <td>0.541322</td>\n",
       "      <td>0.644628</td>\n",
       "      <td>0.611570</td>\n",
       "      <td>0.512397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.531120</td>\n",
       "      <td>0.493776</td>\n",
       "      <td>0.485477</td>\n",
       "      <td>0.427386</td>\n",
       "      <td>0.402490</td>\n",
       "      <td>0.356846</td>\n",
       "      <td>0.340249</td>\n",
       "      <td>0.356846</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.340249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190871</td>\n",
       "      <td>0.112033</td>\n",
       "      <td>0.062241</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.053942</td>\n",
       "      <td>0.045643</td>\n",
       "      <td>0.053942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.763736</td>\n",
       "      <td>0.763736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>0.906593</td>\n",
       "      <td>0.879121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.248677</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.248677</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>0.608466</td>\n",
       "      <td>0.608466</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.566138</td>\n",
       "      <td>0.502646</td>\n",
       "      <td>0.470899</td>\n",
       "      <td>0.449735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.844898</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.963265</td>\n",
       "      <td>0.987755</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.722449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.848980</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.832653</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.820408</td>\n",
       "      <td>0.783673</td>\n",
       "      <td>0.767347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.077236</td>\n",
       "      <td>0.105691</td>\n",
       "      <td>0.117886</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.126016</td>\n",
       "      <td>0.069106</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.052846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186992</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.223577</td>\n",
       "      <td>0.239837</td>\n",
       "      <td>0.260163</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.321138</td>\n",
       "      <td>0.337398</td>\n",
       "      <td>0.357724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.037915</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.109244</td>\n",
       "      <td>0.155462</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.121849</td>\n",
       "      <td>0.113445</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>0.084034</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525210</td>\n",
       "      <td>0.281513</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.037815</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.042017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.156398</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.165877</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.127962</td>\n",
       "      <td>0.109005</td>\n",
       "      <td>0.118483</td>\n",
       "      <td>0.127962</td>\n",
       "      <td>0.123223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.127962</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.080569</td>\n",
       "      <td>0.142180</td>\n",
       "      <td>0.156398</td>\n",
       "      <td>0.132701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 16384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.095238  0.100000  0.100000  0.095238  0.095238  0.100000  0.109524   \n",
       "1    0.061983  0.061983  0.061983  0.061983  0.061983  0.061983  0.061983   \n",
       "2    0.531120  0.493776  0.485477  0.427386  0.402490  0.356846  0.340249   \n",
       "3    0.796703  0.796703  0.791209  0.791209  0.796703  0.818681  0.818681   \n",
       "4    0.222222  0.232804  0.232804  0.248677  0.253968  0.259259  0.248677   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "985  0.828571  0.844898  0.804082  0.824490  0.918367  0.963265  0.987755   \n",
       "986  0.048780  0.065041  0.077236  0.105691  0.117886  0.121951  0.126016   \n",
       "987  0.056872  0.056872  0.061611  0.061611  0.071090  0.056872  0.037915   \n",
       "988  0.109244  0.155462  0.168067  0.121849  0.113445  0.088235  0.079832   \n",
       "989  0.156398  0.146919  0.151659  0.165877  0.151659  0.127962  0.109005   \n",
       "\n",
       "            7         8         9  ...     16374     16375     16376  \\\n",
       "0    0.114286  0.119048  0.104762  ...  0.347619  0.361905  0.314286   \n",
       "1    0.061983  0.066116  0.066116  ...  0.417355  0.322314  0.285124   \n",
       "2    0.356846  0.336100  0.340249  ...  0.190871  0.112033  0.062241   \n",
       "3    0.785714  0.763736  0.763736  ...  0.961538  0.950549  0.950549   \n",
       "4    0.243386  0.243386  0.243386  ...  0.619048  0.613757  0.608466   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "985  0.959184  0.873469  0.722449  ...  0.857143  0.848980  0.828571   \n",
       "986  0.069106  0.060976  0.052846  ...  0.186992  0.207317  0.223577   \n",
       "987  0.023697  0.009479  0.018957  ...  0.900474  0.890995  0.895735   \n",
       "988  0.084034  0.079832  0.067227  ...  0.525210  0.281513  0.050420   \n",
       "989  0.118483  0.127962  0.123223  ...  0.146919  0.151659  0.146919   \n",
       "\n",
       "        16377     16378     16379     16380     16381     16382     16383  \n",
       "0    0.400000  0.419048  0.261905  0.233333  0.300000  0.266667  0.257143  \n",
       "1    0.471074  0.508264  0.475207  0.541322  0.644628  0.611570  0.512397  \n",
       "2    0.058091  0.074689  0.066390  0.058091  0.053942  0.045643  0.053942  \n",
       "3    0.945055  0.939560  0.928571  0.923077  0.917582  0.906593  0.879121  \n",
       "4    0.608466  0.613757  0.592593  0.566138  0.502646  0.470899  0.449735  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "985  0.832653  0.840816  0.840816  0.816327  0.820408  0.783673  0.767347  \n",
       "986  0.239837  0.260163  0.284553  0.304878  0.321138  0.337398  0.357724  \n",
       "987  0.900474  0.895735  0.895735  0.890995  0.890995  0.890995  0.890995  \n",
       "988  0.033613  0.037815  0.033613  0.033613  0.042017  0.042017  0.042017  \n",
       "989  0.127962  0.151659  0.071090  0.080569  0.142180  0.156398  0.132701  \n",
       "\n",
       "[990 rows x 16384 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan normalisasi pada data testing.\n",
    "scaler.fit_transform(df_test.T)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141e7e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:54:01.168354Z",
     "iopub.status.busy": "2021-11-04T10:54:01.167658Z",
     "iopub.status.idle": "2021-11-04T10:54:01.204688Z",
     "shell.execute_reply": "2021-11-04T10:54:01.204143Z",
     "shell.execute_reply.started": "2021-11-04T10:06:18.909964Z"
    },
    "papermill": {
     "duration": 0.066411,
     "end_time": "2021-11-04T10:54:01.204859",
     "exception": false,
     "start_time": "2021-11-04T10:54:01.138448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usia</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4610 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      usia  fold\n",
       "0       27     3\n",
       "1       27     3\n",
       "2       27     3\n",
       "3       24     0\n",
       "4       24     0\n",
       "...    ...   ...\n",
       "4605    23     4\n",
       "4606    23     4\n",
       "4607    27     4\n",
       "4608    27     4\n",
       "4609    27     4\n",
       "\n",
       "[4610 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Memunculkan target prediksi.\n",
    "target_0 = pd.read_csv('../input/bdc-sd2021-data-tambahan/train_target_and_fold.csv')[['usia', 'fold']]\n",
    "target_1 = pd.concat([target_0 for iteration in range(2)], ignore_index = True)\n",
    "target_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa261539",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:54:01.257893Z",
     "iopub.status.busy": "2021-11-04T10:54:01.257193Z",
     "iopub.status.idle": "2021-11-04T10:54:01.376962Z",
     "shell.execute_reply": "2021-11-04T10:54:01.376406Z",
     "shell.execute_reply.started": "2021-11-04T10:06:23.078369Z"
    },
    "papermill": {
     "duration": 0.147384,
     "end_time": "2021-11-04T10:54:01.377106",
     "exception": false,
     "start_time": "2021-11-04T10:54:01.229722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_le</th>\n",
       "      <th>y_le</th>\n",
       "      <th>x_re</th>\n",
       "      <th>y_re</th>\n",
       "      <th>x_n</th>\n",
       "      <th>y_n</th>\n",
       "      <th>x_ml</th>\n",
       "      <th>y_ml</th>\n",
       "      <th>x_mr</th>\n",
       "      <th>y_mr</th>\n",
       "      <th>...</th>\n",
       "      <th>adj_n_ml</th>\n",
       "      <th>sym_le_mr</th>\n",
       "      <th>adj_le_mr</th>\n",
       "      <th>sym_re_mr</th>\n",
       "      <th>adj_re_mr</th>\n",
       "      <th>sym_n_mr</th>\n",
       "      <th>adj_n_mr</th>\n",
       "      <th>sym_ml_mr</th>\n",
       "      <th>adj_ml_mr</th>\n",
       "      <th>abs_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>0.698052</td>\n",
       "      <td>0.392694</td>\n",
       "      <td>0.405844</td>\n",
       "      <td>0.618721</td>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249515</td>\n",
       "      <td>0.615908</td>\n",
       "      <td>0.693416</td>\n",
       "      <td>0.314818</td>\n",
       "      <td>0.446237</td>\n",
       "      <td>0.339205</td>\n",
       "      <td>0.350364</td>\n",
       "      <td>0.539005</td>\n",
       "      <td>0.539049</td>\n",
       "      <td>0.061566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179724</td>\n",
       "      <td>0.397351</td>\n",
       "      <td>0.589862</td>\n",
       "      <td>0.403974</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.619205</td>\n",
       "      <td>0.202765</td>\n",
       "      <td>0.725166</td>\n",
       "      <td>0.635945</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171500</td>\n",
       "      <td>0.563722</td>\n",
       "      <td>0.648461</td>\n",
       "      <td>0.327759</td>\n",
       "      <td>0.453958</td>\n",
       "      <td>0.362484</td>\n",
       "      <td>0.377599</td>\n",
       "      <td>0.433192</td>\n",
       "      <td>0.433204</td>\n",
       "      <td>0.134023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195946</td>\n",
       "      <td>0.404878</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.404878</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.614634</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.682432</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239078</td>\n",
       "      <td>0.586077</td>\n",
       "      <td>0.664537</td>\n",
       "      <td>0.327457</td>\n",
       "      <td>0.453156</td>\n",
       "      <td>0.325814</td>\n",
       "      <td>0.344595</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.174672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266055</td>\n",
       "      <td>0.373239</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.373239</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.238532</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272772</td>\n",
       "      <td>0.565660</td>\n",
       "      <td>0.629561</td>\n",
       "      <td>0.331113</td>\n",
       "      <td>0.431290</td>\n",
       "      <td>0.323865</td>\n",
       "      <td>0.348745</td>\n",
       "      <td>0.486442</td>\n",
       "      <td>0.486585</td>\n",
       "      <td>0.121842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.244565</td>\n",
       "      <td>0.389764</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.393701</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.578740</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.696850</td>\n",
       "      <td>0.706522</td>\n",
       "      <td>0.712598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254682</td>\n",
       "      <td>0.563583</td>\n",
       "      <td>0.641880</td>\n",
       "      <td>0.319083</td>\n",
       "      <td>0.440352</td>\n",
       "      <td>0.322564</td>\n",
       "      <td>0.346806</td>\n",
       "      <td>0.489384</td>\n",
       "      <td>0.489613</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.362934</td>\n",
       "      <td>0.401146</td>\n",
       "      <td>0.803089</td>\n",
       "      <td>0.383954</td>\n",
       "      <td>0.660232</td>\n",
       "      <td>0.616046</td>\n",
       "      <td>0.389961</td>\n",
       "      <td>0.759312</td>\n",
       "      <td>0.737452</td>\n",
       "      <td>0.753582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327708</td>\n",
       "      <td>0.530242</td>\n",
       "      <td>0.629355</td>\n",
       "      <td>0.364131</td>\n",
       "      <td>0.487068</td>\n",
       "      <td>0.162752</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.347538</td>\n",
       "      <td>0.347576</td>\n",
       "      <td>0.540420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.386256</td>\n",
       "      <td>0.744108</td>\n",
       "      <td>0.398104</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.649289</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.772512</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.779621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274054</td>\n",
       "      <td>0.612584</td>\n",
       "      <td>0.719783</td>\n",
       "      <td>0.387194</td>\n",
       "      <td>0.549482</td>\n",
       "      <td>0.236635</td>\n",
       "      <td>0.267332</td>\n",
       "      <td>0.404103</td>\n",
       "      <td>0.404167</td>\n",
       "      <td>0.552494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.274869</td>\n",
       "      <td>0.400372</td>\n",
       "      <td>0.759162</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>0.523560</td>\n",
       "      <td>0.616387</td>\n",
       "      <td>0.324607</td>\n",
       "      <td>0.780261</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>0.780261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304386</td>\n",
       "      <td>0.562206</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.386895</td>\n",
       "      <td>0.539038</td>\n",
       "      <td>0.230645</td>\n",
       "      <td>0.281800</td>\n",
       "      <td>0.361257</td>\n",
       "      <td>0.361257</td>\n",
       "      <td>0.162489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>0.323887</td>\n",
       "      <td>0.405836</td>\n",
       "      <td>0.801619</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.668016</td>\n",
       "      <td>0.631300</td>\n",
       "      <td>0.425101</td>\n",
       "      <td>0.801061</td>\n",
       "      <td>0.785425</td>\n",
       "      <td>0.814324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370196</td>\n",
       "      <td>0.602490</td>\n",
       "      <td>0.749939</td>\n",
       "      <td>0.395557</td>\n",
       "      <td>0.603456</td>\n",
       "      <td>0.206407</td>\n",
       "      <td>0.284469</td>\n",
       "      <td>0.360568</td>\n",
       "      <td>0.360892</td>\n",
       "      <td>0.456213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>0.357488</td>\n",
       "      <td>0.393750</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>0.384375</td>\n",
       "      <td>0.632850</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>0.314010</td>\n",
       "      <td>0.753125</td>\n",
       "      <td>0.830918</td>\n",
       "      <td>0.753125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405912</td>\n",
       "      <td>0.600094</td>\n",
       "      <td>0.741007</td>\n",
       "      <td>0.362607</td>\n",
       "      <td>0.557652</td>\n",
       "      <td>0.256197</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.378831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4610 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x_le      y_le      x_re      y_re       x_n       y_n      x_ml  \\\n",
       "0     0.204545  0.390411  0.698052  0.392694  0.405844  0.618721  0.194805   \n",
       "1     0.179724  0.397351  0.589862  0.403974  0.290323  0.619205  0.202765   \n",
       "2     0.195946  0.404878  0.662162  0.404878  0.378378  0.614634  0.202703   \n",
       "3     0.266055  0.373239  0.715596  0.373239  0.440367  0.549296  0.238532   \n",
       "4     0.244565  0.389764  0.695652  0.393701  0.413043  0.578740  0.217391   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4605  0.362934  0.401146  0.803089  0.383954  0.660232  0.616046  0.389961   \n",
       "4606  0.232323  0.386256  0.744108  0.398104  0.515152  0.649289  0.313131   \n",
       "4607  0.274869  0.400372  0.759162  0.396648  0.523560  0.616387  0.324607   \n",
       "4608  0.323887  0.405836  0.801619  0.413793  0.668016  0.631300  0.425101   \n",
       "4609  0.357488  0.393750  0.879227  0.384375  0.632850  0.590625  0.314010   \n",
       "\n",
       "          y_ml      x_mr      y_mr  ...  adj_n_ml  sym_le_mr  adj_le_mr  \\\n",
       "0     0.712329  0.733766  0.705479  ...  0.249515   0.615908   0.693416   \n",
       "1     0.725166  0.635945  0.728477  ...  0.171500   0.563722   0.648461   \n",
       "2     0.731707  0.682432  0.731707  ...  0.239078   0.586077   0.664537   \n",
       "3     0.690141  0.724771  0.704225  ...  0.272772   0.565660   0.629561   \n",
       "4     0.696850  0.706522  0.712598  ...  0.254682   0.563583   0.641880   \n",
       "...        ...       ...       ...  ...       ...        ...        ...   \n",
       "4605  0.759312  0.737452  0.753582  ...  0.327708   0.530242   0.629355   \n",
       "4606  0.772512  0.717172  0.779621  ...  0.274054   0.612584   0.719783   \n",
       "4607  0.780261  0.685864  0.780261  ...  0.304386   0.562206   0.678031   \n",
       "4608  0.801061  0.785425  0.814324  ...  0.370196   0.602490   0.749939   \n",
       "4609  0.753125  0.830918  0.753125  ...  0.405912   0.600094   0.741007   \n",
       "\n",
       "      sym_re_mr  adj_re_mr  sym_n_mr  adj_n_mr  sym_ml_mr  adj_ml_mr  \\\n",
       "0      0.314818   0.446237  0.339205  0.350364   0.539005   0.539049   \n",
       "1      0.327759   0.453958  0.362484  0.377599   0.433192   0.433204   \n",
       "2      0.327457   0.453156  0.325814  0.344595   0.479730   0.479730   \n",
       "3      0.331113   0.431290  0.323865  0.348745   0.486442   0.486585   \n",
       "4      0.319083   0.440352  0.322564  0.346806   0.489384   0.489613   \n",
       "...         ...        ...       ...       ...        ...        ...   \n",
       "4605   0.364131   0.487068  0.162752  0.207921   0.347538   0.347576   \n",
       "4606   0.387194   0.549482  0.236635  0.267332   0.404103   0.404167   \n",
       "4607   0.386895   0.539038  0.230645  0.281800   0.361257   0.361257   \n",
       "4608   0.395557   0.603456  0.206407  0.284469   0.360568   0.360892   \n",
       "4609   0.362607   0.557652  0.256197  0.319900   0.516908   0.516908   \n",
       "\n",
       "      abs_angle  \n",
       "0      0.061566  \n",
       "1      0.134023  \n",
       "2      0.174672  \n",
       "3      0.121842  \n",
       "4      0.012195  \n",
       "...         ...  \n",
       "4605   0.540420  \n",
       "4606   0.552494  \n",
       "4607   0.162489  \n",
       "4608   0.456213  \n",
       "4609   0.378831  \n",
       "\n",
       "[4610 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan penambahan data training yang berkaitan dengan posisi relatif fitur pada wajah.\n",
    "df_train_1 = pd.read_csv('../input/bdc-sd2021-data-tambahan/train_facial_relative.csv')\n",
    "fake_train_1 = df_train_1.copy()\n",
    "fake_train_1['x_le'] = 1 - df_train_1['x_re']\n",
    "fake_train_1['x_re'] = 1 - df_train_1['x_le']\n",
    "fake_train_1['x_n'] = 1 - df_train_1['x_n']\n",
    "fake_train_1['x_ml'] = 1 - df_train_1['x_mr']\n",
    "fake_train_1['x_mr'] = 1 - df_train_1['x_ml']\n",
    "fake_train_1[['sym_le_n', 'adj_le_n', 'sym_re_n', 'adj_re_n']] = df_train_1[['sym_re_n', 'adj_re_n', 'sym_le_n', 'adj_le_n']]\n",
    "fake_train_1[['sym_le_ml', 'adj_le_ml', 'sym_re_mr', 'adj_re_mr']] = df_train_1[['sym_re_mr', 'adj_re_mr', 'sym_le_ml', 'adj_le_ml']]\n",
    "fake_train_1[['sym_le_mr', 'adj_le_mr', 'sym_re_ml', 'adj_re_ml']] = df_train_1[['sym_re_ml', 'adj_re_ml', 'sym_le_mr', 'adj_le_mr']]\n",
    "fake_train_1[['sym_n_ml', 'adj_n_ml', 'sym_n_mr', 'adj_n_mr']] = df_train_1[['sym_n_mr', 'adj_n_mr', 'sym_n_ml', 'adj_n_ml']]\n",
    "\n",
    "df_train_1 = pd.concat([df_train_1, fake_train_1], ignore_index = True)\n",
    "del fake_train_1\n",
    "\n",
    "df_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "033f18b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:54:01.434323Z",
     "iopub.status.busy": "2021-11-04T10:54:01.433615Z",
     "iopub.status.idle": "2021-11-04T10:54:01.497597Z",
     "shell.execute_reply": "2021-11-04T10:54:01.498216Z",
     "shell.execute_reply.started": "2021-11-04T10:06:27.057874Z"
    },
    "papermill": {
     "duration": 0.095403,
     "end_time": "2021-11-04T10:54:01.498384",
     "exception": false,
     "start_time": "2021-11-04T10:54:01.402981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_le</th>\n",
       "      <th>y_le</th>\n",
       "      <th>x_re</th>\n",
       "      <th>y_re</th>\n",
       "      <th>x_n</th>\n",
       "      <th>y_n</th>\n",
       "      <th>x_ml</th>\n",
       "      <th>y_ml</th>\n",
       "      <th>x_mr</th>\n",
       "      <th>y_mr</th>\n",
       "      <th>...</th>\n",
       "      <th>adj_n_ml</th>\n",
       "      <th>sym_le_mr</th>\n",
       "      <th>adj_le_mr</th>\n",
       "      <th>sym_re_mr</th>\n",
       "      <th>adj_re_mr</th>\n",
       "      <th>sym_n_mr</th>\n",
       "      <th>adj_n_mr</th>\n",
       "      <th>sym_ml_mr</th>\n",
       "      <th>adj_ml_mr</th>\n",
       "      <th>abs_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.291209</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.521978</td>\n",
       "      <td>0.516432</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.737089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338570</td>\n",
       "      <td>0.596852</td>\n",
       "      <td>0.645365</td>\n",
       "      <td>0.400006</td>\n",
       "      <td>0.467840</td>\n",
       "      <td>0.303782</td>\n",
       "      <td>0.332088</td>\n",
       "      <td>0.434091</td>\n",
       "      <td>0.434101</td>\n",
       "      <td>0.070471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.405128</td>\n",
       "      <td>0.753521</td>\n",
       "      <td>0.394872</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.625641</td>\n",
       "      <td>0.260563</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318229</td>\n",
       "      <td>0.554593</td>\n",
       "      <td>0.623428</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.429635</td>\n",
       "      <td>0.213573</td>\n",
       "      <td>0.227106</td>\n",
       "      <td>0.486159</td>\n",
       "      <td>0.486375</td>\n",
       "      <td>0.029403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214533</td>\n",
       "      <td>0.403023</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>0.397985</td>\n",
       "      <td>0.366782</td>\n",
       "      <td>0.612091</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.727960</td>\n",
       "      <td>0.692042</td>\n",
       "      <td>0.722922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206456</td>\n",
       "      <td>0.574761</td>\n",
       "      <td>0.648943</td>\n",
       "      <td>0.326426</td>\n",
       "      <td>0.447452</td>\n",
       "      <td>0.343624</td>\n",
       "      <td>0.359129</td>\n",
       "      <td>0.456775</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.022553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.365517</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.402062</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>0.597938</td>\n",
       "      <td>0.393103</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346547</td>\n",
       "      <td>0.537095</td>\n",
       "      <td>0.627927</td>\n",
       "      <td>0.356271</td>\n",
       "      <td>0.476312</td>\n",
       "      <td>0.194191</td>\n",
       "      <td>0.240590</td>\n",
       "      <td>0.365844</td>\n",
       "      <td>0.366102</td>\n",
       "      <td>0.064427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.381323</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.369650</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.603113</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.747082</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.735409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279993</td>\n",
       "      <td>0.575064</td>\n",
       "      <td>0.655712</td>\n",
       "      <td>0.366092</td>\n",
       "      <td>0.489833</td>\n",
       "      <td>0.255644</td>\n",
       "      <td>0.281443</td>\n",
       "      <td>0.422036</td>\n",
       "      <td>0.422164</td>\n",
       "      <td>0.044914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.356364</td>\n",
       "      <td>0.398892</td>\n",
       "      <td>0.821818</td>\n",
       "      <td>0.398892</td>\n",
       "      <td>0.650909</td>\n",
       "      <td>0.617729</td>\n",
       "      <td>0.374545</td>\n",
       "      <td>0.739612</td>\n",
       "      <td>0.785455</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319338</td>\n",
       "      <td>0.546195</td>\n",
       "      <td>0.617197</td>\n",
       "      <td>0.339901</td>\n",
       "      <td>0.445124</td>\n",
       "      <td>0.179696</td>\n",
       "      <td>0.206282</td>\n",
       "      <td>0.410918</td>\n",
       "      <td>0.410925</td>\n",
       "      <td>0.124355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.373016</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.563492</td>\n",
       "      <td>0.362637</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369237</td>\n",
       "      <td>0.602016</td>\n",
       "      <td>0.700027</td>\n",
       "      <td>0.381111</td>\n",
       "      <td>0.527587</td>\n",
       "      <td>0.251896</td>\n",
       "      <td>0.311010</td>\n",
       "      <td>0.385352</td>\n",
       "      <td>0.386026</td>\n",
       "      <td>0.047583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328573</td>\n",
       "      <td>0.573337</td>\n",
       "      <td>0.690348</td>\n",
       "      <td>0.364790</td>\n",
       "      <td>0.522544</td>\n",
       "      <td>0.259399</td>\n",
       "      <td>0.308120</td>\n",
       "      <td>0.449389</td>\n",
       "      <td>0.449509</td>\n",
       "      <td>0.031240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.338403</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.338403</td>\n",
       "      <td>0.319048</td>\n",
       "      <td>0.593156</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.779468</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.779468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261948</td>\n",
       "      <td>0.605120</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.444751</td>\n",
       "      <td>0.555329</td>\n",
       "      <td>0.302327</td>\n",
       "      <td>0.333367</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.020199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.280255</td>\n",
       "      <td>0.414596</td>\n",
       "      <td>0.787686</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.556263</td>\n",
       "      <td>0.639752</td>\n",
       "      <td>0.280255</td>\n",
       "      <td>0.729814</td>\n",
       "      <td>0.755839</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302233</td>\n",
       "      <td>0.573150</td>\n",
       "      <td>0.646119</td>\n",
       "      <td>0.323002</td>\n",
       "      <td>0.440643</td>\n",
       "      <td>0.220912</td>\n",
       "      <td>0.237915</td>\n",
       "      <td>0.475607</td>\n",
       "      <td>0.475627</td>\n",
       "      <td>0.145516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_le      y_le      x_re      y_re       x_n       y_n      x_ml  \\\n",
       "0    0.291209  0.333333  0.758242  0.338028  0.521978  0.516432  0.296703   \n",
       "1    0.281690  0.405128  0.753521  0.394872  0.549296  0.625641  0.260563   \n",
       "2    0.214533  0.403023  0.660900  0.397985  0.366782  0.612091  0.235294   \n",
       "3    0.365517  0.391753  0.779310  0.402062  0.648276  0.597938  0.393103   \n",
       "4    0.265625  0.381323  0.734375  0.369650  0.500000  0.603113  0.296875   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "985  0.356364  0.398892  0.821818  0.398892  0.650909  0.617729  0.374545   \n",
       "986  0.274725  0.380952  0.758242  0.373016  0.582418  0.563492  0.362637   \n",
       "987  0.289855  0.373737  0.753623  0.383838  0.521739  0.585859  0.275362   \n",
       "988  0.142857  0.338403  0.614286  0.338403  0.319048  0.593156  0.200000   \n",
       "989  0.280255  0.414596  0.787686  0.413043  0.556263  0.639752  0.280255   \n",
       "\n",
       "         y_ml      x_mr      y_mr  ...  adj_n_ml  sym_le_mr  adj_le_mr  \\\n",
       "0    0.732394  0.730769  0.737089  ...  0.338570   0.596852   0.645365   \n",
       "1    0.723077  0.746479  0.707692  ...  0.318229   0.554593   0.623428   \n",
       "2    0.727960  0.692042  0.722922  ...  0.206456   0.574761   0.648943   \n",
       "3    0.773196  0.758621  0.757732  ...  0.346547   0.537095   0.627927   \n",
       "4    0.747082  0.718750  0.735409  ...  0.279993   0.575064   0.655712   \n",
       "..        ...       ...       ...  ...       ...        ...        ...   \n",
       "985  0.739612  0.785455  0.736842  ...  0.319338   0.546195   0.617197   \n",
       "986  0.777778  0.747253  0.753968  ...  0.369237   0.602016   0.700027   \n",
       "987  0.737374  0.724638  0.747475  ...  0.328573   0.573337   0.690348   \n",
       "988  0.779468  0.557143  0.779468  ...  0.261948   0.605120   0.690476   \n",
       "989  0.729814  0.755839  0.734472  ...  0.302233   0.573150   0.646119   \n",
       "\n",
       "     sym_re_mr  adj_re_mr  sym_n_mr  adj_n_mr  sym_ml_mr  adj_ml_mr  abs_angle  \n",
       "0     0.400006   0.467840  0.303782  0.332088   0.434091   0.434101   0.070471  \n",
       "1     0.312900   0.429635  0.213573  0.227106   0.486159   0.486375   0.029403  \n",
       "2     0.326426   0.447452  0.343624  0.359129   0.456775   0.456800   0.022553  \n",
       "3     0.356271   0.476312  0.194191  0.240590   0.365844   0.366102   0.064427  \n",
       "4     0.366092   0.489833  0.255644  0.281443   0.422036   0.422164   0.044914  \n",
       "..         ...        ...       ...       ...        ...        ...        ...  \n",
       "985   0.339901   0.445124  0.179696  0.206282   0.410918   0.410925   0.124355  \n",
       "986   0.381111   0.527587  0.251896  0.311010   0.385352   0.386026   0.047583  \n",
       "987   0.364790   0.522544  0.259399  0.308120   0.449389   0.449509   0.031240  \n",
       "988   0.444751   0.555329  0.302327  0.333367   0.357143   0.357143   0.020199  \n",
       "989   0.323002   0.440643  0.220912  0.237915   0.475607   0.475627   0.145516  \n",
       "\n",
       "[990 rows x 37 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan penambahan data testing yang berkaitan dengan posisi relatif fitur pada wajah.\n",
    "df_test_1 = pd.read_csv('../input/bdc-sd2021-data-tambahan/test_facial_relative.csv')\n",
    "df_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c36f8306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:54:01.554954Z",
     "iopub.status.busy": "2021-11-04T10:54:01.554316Z",
     "iopub.status.idle": "2021-11-04T10:54:59.724966Z",
     "shell.execute_reply": "2021-11-04T10:54:59.725916Z",
     "shell.execute_reply.started": "2021-11-04T10:10:05.524524Z"
    },
    "papermill": {
     "duration": 58.200649,
     "end_time": "2021-11-04T10:54:59.726236",
     "exception": false,
     "start_time": "2021-11-04T10:54:01.525587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyusun indeks untuk data training dan melakukan shuffle.\n",
    "train_index = list(target_1[target_1['fold'] != fold_index].index)\n",
    "random.seed(seed)\n",
    "random.shuffle(train_index)\n",
    "\n",
    "# Menyusun indeks untuk data validasi.\n",
    "valid_index = list(target_0[target_0['fold'] == fold_index].index)\n",
    "\n",
    "# Memisahkan data validasi dari data training, serta menginisiasi data testing.\n",
    "X_train = df_train.iloc[train_index]\n",
    "X_valid = df_train.iloc[valid_index]\n",
    "X_test = df_test.copy()\n",
    "\n",
    "X_train_1 = df_train_1.iloc[train_index]\n",
    "X_valid_1 = df_train_1.iloc[valid_index]\n",
    "X_test_1 = df_test_1.copy()\n",
    "\n",
    "# Melakukan reduksi dimensi dengan menggunakan PCA.\n",
    "pca = PCA(0.95)\n",
    "X_train = pd.DataFrame(pca.fit_transform(X_train))\n",
    "X_valid = pd.DataFrame(pca.transform(X_valid))\n",
    "X_test = pd.DataFrame(pca.transform(X_test))\n",
    "\n",
    "pca = PCA(0.95)\n",
    "X_train_1 = pd.DataFrame(pca.fit_transform(X_train_1))\n",
    "X_valid_1 = pd.DataFrame(pca.transform(X_valid_1))\n",
    "X_test_1 = pd.DataFrame(pca.transform(X_test_1))\n",
    "\n",
    "# Menggabungkan informasi pada data training, validasi, dan testing.\n",
    "X_train = pd.concat([X_train, X_train_1], axis = 1, ignore_index = True)\n",
    "X_valid = pd.concat([X_valid, X_valid_1], axis = 1, ignore_index = True)\n",
    "X_test = pd.concat([X_test, X_test_1], axis = 1, ignore_index = True)\n",
    "del X_train_1, X_valid_1, X_test_1\n",
    "\n",
    "# Mengubah ukuran data agar sesuai dengan input yang diharapkan oleh model.\n",
    "X_train = X_train.values.reshape(-1, X_train.shape[1], 1).astype('float64')\n",
    "X_valid = X_valid.values.reshape(-1, X_valid.shape[1], 1).astype('float64')\n",
    "X_test = X_test.values.reshape(-1, X_test.shape[1], 1).astype('float64')\n",
    "\n",
    "# Memisahkan target validasi dari target training.\n",
    "y_train = target_1.iloc[train_index, 0].astype('int64')\n",
    "y_valid = target_0.iloc[valid_index, 0].astype('int64')\n",
    "\n",
    "# Membuang informasi yang sudah tidak diperlukan lagi.\n",
    "del df_train, df_test, df_train_1, df_test_1, pca, target_0, target_1, train_index, valid_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "019fdcb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:54:59.835497Z",
     "iopub.status.busy": "2021-11-04T10:54:59.826579Z",
     "iopub.status.idle": "2021-11-04T10:54:59.838659Z",
     "shell.execute_reply": "2021-11-04T10:54:59.838056Z",
     "shell.execute_reply.started": "2021-11-04T10:34:04.234056Z"
    },
    "papermill": {
     "duration": 0.062644,
     "end_time": "2021-11-04T10:54:59.838828",
     "exception": false,
     "start_time": "2021-11-04T10:54:59.776184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mendefinisikan fungsi untuk mencari parameter terbaik dengan nilai error terkecil.\n",
    "def create_model(trial):\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 5)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-10, 1e-3, log = True)\n",
    "    dropout = trial.suggest_float('dropout', 0.2, 0.5, log = True)\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers-1):\n",
    "        num_hidden = trial.suggest_int('n_units_l{}'.format(i), 32, 256, log = True)\n",
    "        if i:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "            model.add(Dropout(dropout))\n",
    "        else:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(weight_decay),\n",
    "                            input_shape = (X_train.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    num_hidden = trial.suggest_int('n_units_l{}'.format(n_layers-1), 32, 256, log = True)\n",
    "    model.add(Dense(num_hidden,\n",
    "                    activation = 'relu',\n",
    "                    kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "    model.add(Dense(1,\n",
    "                    activation = 'linear',\n",
    "                    kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "    return model\n",
    "\n",
    "def create_optimizer(trial):\n",
    "    kwargs = {}\n",
    "    optimizer_options = ['RMSprop', 'Adam', 'SGD']\n",
    "    optimizer_selected = trial.suggest_categorical('optimizer', optimizer_options)\n",
    "    if optimizer_selected == 'RMSprop':\n",
    "        kwargs['learning_rate'] = trial.suggest_float(\n",
    "            'rmsprop_learning_rate', 1e-5, 1e-1, log=True)\n",
    "        kwargs['decay'] = trial.suggest_float('rmsprop_decay', 0.85, 0.99)\n",
    "        kwargs['momentum'] = trial.suggest_float('rmsprop_momentum', 1e-5, 1e-1, log = True)\n",
    "    elif optimizer_selected == 'Adam':\n",
    "        kwargs['learning_rate'] = trial.suggest_float('adam_learning_rate', 1e-5, 1e-1, log = True)\n",
    "    elif optimizer_selected == 'SGD':\n",
    "        kwargs['learning_rate'] = trial.suggest_float(\n",
    "            'sgd_opt_learning_rate', 1e-5, 1e-1, log=True)\n",
    "        kwargs['momentum'] = trial.suggest_float('sgd_opt_momentum', 1e-5, 1e-1, log = True)\n",
    "    \n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "    return optimizer\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    optimizer = create_optimizer(trial)\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = 'mean_squared_error',\n",
    "                  metrics = ['mse'])\n",
    "    set_seed()\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs = 3,\n",
    "                        validation_data = (X_valid, y_valid),\n",
    "                        verbose = 2,\n",
    "                        steps_per_epoch = X_train.shape[0] // batch_size)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    try:\n",
    "        mse = MSE(y_valid, y_valid_pred)\n",
    "    except ValueError:\n",
    "        mse = 1e+32\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90db4a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T10:54:59.901877Z",
     "iopub.status.busy": "2021-11-04T10:54:59.900851Z",
     "iopub.status.idle": "2021-11-04T11:06:24.536859Z",
     "shell.execute_reply": "2021-11-04T11:06:24.537422Z"
    },
    "papermill": {
     "duration": 684.671719,
     "end_time": "2021-11-04T11:06:24.537612",
     "exception": false,
     "start_time": "2021-11-04T10:54:59.865893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:54:59,899]\u001b[0m A new study created in memory with name: no-name-53e4a3a1-81c4-4115-9a05-b56a695298ed\u001b[0m\n",
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   KMP_WARNINGS=0\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_ENABLE_TASK_THROTTLING=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=4\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=false\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=1\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "   OMP_NUM_THREADS: value is not defined\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2021-11-04 10:54:59.948737: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-11-04 10:55:00.195985: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 631.9805 - mse: 631.9769 - val_loss: 432.7738 - val_mse: 432.7702\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 121.9161 - mse: 121.9125 - val_loss: 39.1022 - val_mse: 39.0986\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 39.4282 - mse: 39.4246 - val_loss: 37.0254 - val_mse: 37.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:55:14,674]\u001b[0m Trial 0 finished with value: 37.02178988751884 and parameters: {'n_layers': 4, 'weight_decay': 1.3601459990500093e-05, 'dropout': 0.22715517141780636, 'n_units_l0': 61, 'n_units_l1': 255, 'n_units_l2': 41, 'n_units_l3': 46, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 2.4410551066709827e-05, 'sgd_opt_momentum': 1.7150829926878746e-05}. Best is trial 0 with value: 37.02178988751884.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 10s - loss: 249.5610 - mse: 249.5599 - val_loss: 39.5740 - val_mse: 39.5728\n",
      "Epoch 2/3\n",
      "57/57 - 9s - loss: 36.4546 - mse: 36.4534 - val_loss: 35.6323 - val_mse: 35.6312\n",
      "Epoch 3/3\n",
      "57/57 - 9s - loss: 33.9419 - mse: 33.9407 - val_loss: 34.2731 - val_mse: 34.2720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:55:42,895]\u001b[0m Trial 1 finished with value: 34.27196049662438 and parameters: {'n_layers': 5, 'weight_decay': 2.069674778352553e-06, 'dropout': 0.2165227444547113, 'n_units_l0': 102, 'n_units_l1': 115, 'n_units_l2': 238, 'n_units_l3': 105, 'n_units_l4': 69, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 6.0309245793449296e-05, 'sgd_opt_momentum': 0.0021618027516387694}. Best is trial 1 with value: 34.27196049662438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 76.3010 - mse: 76.3008 - val_loss: 32.9582 - val_mse: 32.9580\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 30.4234 - mse: 30.4232 - val_loss: 28.1503 - val_mse: 28.1501\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 26.8565 - mse: 26.8563 - val_loss: 28.7149 - val_mse: 28.7147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:55:50,086]\u001b[0m Trial 2 finished with value: 28.714712291905055 and parameters: {'n_layers': 3, 'weight_decay': 4.2140608469491625e-07, 'dropout': 0.425181023662834, 'n_units_l0': 146, 'n_units_l1': 36, 'n_units_l2': 129, 'optimizer': 'Adam', 'adam_learning_rate': 0.0029509089780652155}. Best is trial 2 with value: 28.714712291905055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 7s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 2/3\n",
      "57/57 - 6s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 3/3\n",
      "57/57 - 6s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:56:10,190]\u001b[0m Trial 3 finished with value: 1e+32 and parameters: {'n_layers': 4, 'weight_decay': 1.280797128821542e-08, 'dropout': 0.4445600696908863, 'n_units_l0': 108, 'n_units_l1': 247, 'n_units_l2': 80, 'n_units_l3': 41, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.006855869932485577, 'sgd_opt_momentum': 0.03652763447965056}. Best is trial 2 with value: 28.714712291905055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 151.3745 - mse: 151.3738 - val_loss: 36.0831 - val_mse: 36.0823\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 34.7333 - mse: 34.7326 - val_loss: 38.4747 - val_mse: 38.4740\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 32.4348 - mse: 32.4341 - val_loss: 35.6310 - val_mse: 35.6303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:56:20,299]\u001b[0m Trial 4 finished with value: 35.6303068268018 and parameters: {'n_layers': 4, 'weight_decay': 2.869521426120942e-06, 'dropout': 0.2736582989224417, 'n_units_l0': 177, 'n_units_l1': 60, 'n_units_l2': 60, 'n_units_l3': 48, 'optimizer': 'Adam', 'adam_learning_rate': 0.0003587550277569686}. Best is trial 2 with value: 28.714712291905055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 2065956608.0000 - mse: 412045.4062 - val_loss: 2222974976.0000 - val_mse: 1346.7308\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 2222694400.0000 - mse: 457.0128 - val_loss: 2222403072.0000 - val_mse: 95.0377\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 2222123264.0000 - mse: 49.2893 - val_loss: 2221831936.0000 - val_mse: 31.7322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:56:34,601]\u001b[0m Trial 5 finished with value: 31.732215783210204 and parameters: {'n_layers': 4, 'weight_decay': 8.671491605192508e-05, 'dropout': 0.2120474687506201, 'n_units_l0': 75, 'n_units_l1': 63, 'n_units_l2': 143, 'n_units_l3': 85, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.012820573397259222, 'sgd_opt_momentum': 0.01219735525440408}. Best is trial 2 with value: 28.714712291905055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 93.9358 - mse: 93.9356 - val_loss: 53.0189 - val_mse: 53.0187\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 46.8588 - mse: 46.8586 - val_loss: 42.8495 - val_mse: 42.8493\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 42.6458 - mse: 42.6456 - val_loss: 40.2178 - val_mse: 40.2176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:56:38,613]\u001b[0m Trial 6 finished with value: 40.217617781868825 and parameters: {'n_layers': 2, 'weight_decay': 1.4490033299339797e-06, 'dropout': 0.4134236878013778, 'n_units_l0': 56, 'n_units_l1': 69, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.0004666904757351211, 'rmsprop_decay': 0.894925822839254, 'rmsprop_momentum': 0.000308450498248823}. Best is trial 2 with value: 28.714712291905055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 59533.3789 - mse: 59533.3711 - val_loss: 95.1776 - val_mse: 95.1593\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 147.0010 - mse: 146.9827 - val_loss: 62.0804 - val_mse: 62.0621\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 93.8986 - mse: 93.8804 - val_loss: 49.1213 - val_mse: 49.1031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:56:49,372]\u001b[0m Trial 7 finished with value: 49.103136288689086 and parameters: {'n_layers': 3, 'weight_decay': 5.713328696681321e-06, 'dropout': 0.3407865362809055, 'n_units_l0': 241, 'n_units_l1': 75, 'n_units_l2': 63, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.019638650422524002, 'rmsprop_decay': 0.9279674621367233, 'rmsprop_momentum': 0.007481765717358807}. Best is trial 2 with value: 28.714712291905055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 586787.8750 - mse: 586787.8750 - val_loss: 45.7197 - val_mse: 45.7190\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 329.1953 - mse: 329.1946 - val_loss: 460.3760 - val_mse: 460.3753\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 60.0046 - mse: 60.0038 - val_loss: 584.3928 - val_mse: 584.3922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:57:05,412]\u001b[0m Trial 8 finished with value: 584.3921793117908 and parameters: {'n_layers': 5, 'weight_decay': 2.9653117862224153e-07, 'dropout': 0.3197493177048565, 'n_units_l0': 123, 'n_units_l1': 65, 'n_units_l2': 116, 'n_units_l3': 83, 'n_units_l4': 41, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.019054962911205356, 'rmsprop_decay': 0.874518227528278, 'rmsprop_momentum': 8.371297680962848e-05}. Best is trial 2 with value: 28.714712291905055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 10s - loss: 2924.2290 - mse: 2924.2068 - val_loss: 46.9445 - val_mse: 46.9228\n",
      "Epoch 2/3\n",
      "57/57 - 9s - loss: 44.9517 - mse: 44.9300 - val_loss: 48.9451 - val_mse: 48.9234\n",
      "Epoch 3/3\n",
      "57/57 - 9s - loss: 41.4891 - mse: 41.4674 - val_loss: 50.6108 - val_mse: 50.5891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:57:34,081]\u001b[0m Trial 9 finished with value: 50.58907681626543 and parameters: {'n_layers': 4, 'weight_decay': 1.0556840099451229e-05, 'dropout': 0.22909938508654398, 'n_units_l0': 72, 'n_units_l1': 170, 'n_units_l2': 172, 'n_units_l3': 167, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.005553572385099785, 'rmsprop_decay': 0.9526963318618572, 'rmsprop_momentum': 3.908613352528237e-05}. Best is trial 2 with value: 28.714712291905055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 1s - loss: 2722.4336 - mse: 2722.4331 - val_loss: 653.4010 - val_mse: 653.4001\n",
      "Epoch 2/3\n",
      "57/57 - 0s - loss: 594.8613 - mse: 594.8604 - val_loss: 539.0598 - val_mse: 539.0588\n",
      "Epoch 3/3\n",
      "57/57 - 0s - loss: 481.1167 - mse: 481.1158 - val_loss: 428.4093 - val_mse: 428.4083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:57:36,411]\u001b[0m Trial 10 finished with value: 428.408237263743 and parameters: {'n_layers': 2, 'weight_decay': 1.5303673965817338e-08, 'dropout': 0.36337622618058174, 'n_units_l0': 37, 'n_units_l1': 38, 'optimizer': 'Adam', 'adam_learning_rate': 0.07687620678695332}. Best is trial 2 with value: 28.714712291905055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 68.4665 - mse: 67.1793 - val_loss: 32.5214 - val_mse: 31.0822\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 31.0920 - mse: 29.8105 - val_loss: 29.9208 - val_mse: 28.7815\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 28.6899 - mse: 27.6348 - val_loss: 30.1458 - val_mse: 29.1660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:57:44,345]\u001b[0m Trial 11 finished with value: 29.165961369001575 and parameters: {'n_layers': 3, 'weight_decay': 0.0008338016434700748, 'dropout': 0.49767481025136756, 'n_units_l0': 155, 'n_units_l1': 34, 'n_units_l2': 130, 'optimizer': 'Adam', 'adam_learning_rate': 0.009062730720066392}. Best is trial 2 with value: 28.714712291905055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 245.1576 - mse: 243.5074 - val_loss: 32.4874 - val_mse: 30.5341\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 31.9305 - mse: 30.1829 - val_loss: 29.6411 - val_mse: 28.0882\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 31.8450 - mse: 30.4343 - val_loss: 29.2003 - val_mse: 27.9213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:57:51,081]\u001b[0m Trial 12 finished with value: 27.921277833755727 and parameters: {'n_layers': 3, 'weight_decay': 0.0009316945324941113, 'dropout': 0.4942740538589664, 'n_units_l0': 161, 'n_units_l1': 34, 'n_units_l2': 107, 'optimizer': 'Adam', 'adam_learning_rate': 0.010412299178528817}. Best is trial 12 with value: 27.921277833755727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 70.3115 - mse: 70.3115 - val_loss: 31.4408 - val_mse: 31.4408\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 28.1363 - mse: 28.1363 - val_loss: 29.5523 - val_mse: 29.5523\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 27.6773 - mse: 27.6773 - val_loss: 29.5879 - val_mse: 29.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:57:59,502]\u001b[0m Trial 13 finished with value: 29.587869896346913 and parameters: {'n_layers': 3, 'weight_decay': 1.991247839884373e-10, 'dropout': 0.49611215443722484, 'n_units_l0': 255, 'n_units_l1': 45, 'n_units_l2': 87, 'optimizer': 'Adam', 'adam_learning_rate': 0.004142797367627817}. Best is trial 12 with value: 27.921277833755727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 382.9616 - mse: 382.8761 - val_loss: 152.8582 - val_mse: 152.7712\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 74.3260 - mse: 74.2371 - val_loss: 41.8438 - val_mse: 41.7533\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 39.7787 - mse: 39.6878 - val_loss: 36.7911 - val_mse: 36.6999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:58:05,199]\u001b[0m Trial 14 finished with value: 36.6998889809962 and parameters: {'n_layers': 2, 'weight_decay': 0.0008544832045566893, 'dropout': 0.4109404978407691, 'n_units_l0': 165, 'n_units_l1': 47, 'optimizer': 'Adam', 'adam_learning_rate': 3.1014013106972164e-05}. Best is trial 12 with value: 27.921277833755727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 85.0195 - mse: 85.0194 - val_loss: 34.3761 - val_mse: 34.3761\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 32.1213 - mse: 32.1213 - val_loss: 30.0093 - val_mse: 30.0093\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 28.0183 - mse: 28.0183 - val_loss: 29.0360 - val_mse: 29.0360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:58:12,074]\u001b[0m Trial 15 finished with value: 29.036020254905083 and parameters: {'n_layers': 3, 'weight_decay': 3.032810312970203e-08, 'dropout': 0.3815955695340615, 'n_units_l0': 135, 'n_units_l1': 32, 'n_units_l2': 202, 'optimizer': 'Adam', 'adam_learning_rate': 0.0012013708276208072}. Best is trial 12 with value: 27.921277833755727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 4671.2402 - mse: 4671.2402 - val_loss: 27.7789 - val_mse: 27.7789\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 30.1139 - mse: 30.1139 - val_loss: 27.7447 - val_mse: 27.7447\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 29.0744 - mse: 29.0744 - val_loss: 30.9217 - val_mse: 30.9217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:58:19,980]\u001b[0m Trial 16 finished with value: 30.921706644018787 and parameters: {'n_layers': 3, 'weight_decay': 1.1811363658965055e-10, 'dropout': 0.45299317042843545, 'n_units_l0': 190, 'n_units_l1': 47, 'n_units_l2': 108, 'optimizer': 'Adam', 'adam_learning_rate': 0.03750139275787095}. Best is trial 12 with value: 27.921277833755727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 70.5149 - mse: 70.4942 - val_loss: 35.9115 - val_mse: 35.8896\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 32.7806 - mse: 32.7584 - val_loss: 34.3936 - val_mse: 34.3710\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 30.6695 - mse: 30.6463 - val_loss: 34.4213 - val_mse: 34.3975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:58:31,549]\u001b[0m Trial 17 finished with value: 34.397512789092694 and parameters: {'n_layers': 2, 'weight_decay': 8.234843066168191e-05, 'dropout': 0.27353407809110303, 'n_units_l0': 213, 'n_units_l1': 98, 'optimizer': 'Adam', 'adam_learning_rate': 0.0007208519843444955}. Best is trial 12 with value: 27.921277833755727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 126.5842 - mse: 126.5842 - val_loss: 31.2076 - val_mse: 31.2076\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 27.9617 - mse: 27.9617 - val_loss: 27.7690 - val_mse: 27.7690\n",
      "Epoch 3/3\n",
      "57/57 - 6s - loss: 27.3087 - mse: 27.3086 - val_loss: 27.3202 - val_mse: 27.3202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:58:49,742]\u001b[0m Trial 18 finished with value: 27.320157399363325 and parameters: {'n_layers': 3, 'weight_decay': 2.7084578048322714e-09, 'dropout': 0.4354074667103928, 'n_units_l0': 140, 'n_units_l1': 131, 'n_units_l2': 162, 'optimizer': 'Adam', 'adam_learning_rate': 0.008446145801551484}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 942.8757 - mse: 942.8757 - val_loss: 683.4777 - val_mse: 683.4776\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 660.3157 - mse: 660.3157 - val_loss: 642.8516 - val_mse: 642.8516\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 619.8034 - mse: 619.8034 - val_loss: 602.6088 - val_mse: 602.6088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:58:56,334]\u001b[0m Trial 19 finished with value: 602.6087476427476 and parameters: {'n_layers': 2, 'weight_decay': 2.3558618862053574e-09, 'dropout': 0.4696440247450452, 'n_units_l0': 90, 'n_units_l1': 132, 'optimizer': 'Adam', 'adam_learning_rate': 0.016003032784814655}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 8s - loss: 142.3489 - mse: 142.3489 - val_loss: 40.5747 - val_mse: 40.5747\n",
      "Epoch 2/3\n",
      "57/57 - 7s - loss: 38.1741 - mse: 38.1741 - val_loss: 35.2396 - val_mse: 35.2396\n",
      "Epoch 3/3\n",
      "57/57 - 7s - loss: 35.7652 - mse: 35.7652 - val_loss: 34.1196 - val_mse: 34.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:59:18,555]\u001b[0m Trial 20 finished with value: 34.11960683250907 and parameters: {'n_layers': 3, 'weight_decay': 9.971339084246419e-10, 'dropout': 0.3816599353210121, 'n_units_l0': 114, 'n_units_l1': 180, 'n_units_l2': 173, 'optimizer': 'Adam', 'adam_learning_rate': 9.748893009494004e-05}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 113.5088 - mse: 113.5086 - val_loss: 36.6043 - val_mse: 36.6041\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 29.7966 - mse: 29.7964 - val_loss: 28.3952 - val_mse: 28.3949\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 26.7130 - mse: 26.7128 - val_loss: 27.6368 - val_mse: 27.6365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:59:31,281]\u001b[0m Trial 21 finished with value: 27.63652273071942 and parameters: {'n_layers': 3, 'weight_decay': 1.5875527098229412e-07, 'dropout': 0.41551967522517597, 'n_units_l0': 149, 'n_units_l1': 87, 'n_units_l2': 148, 'optimizer': 'Adam', 'adam_learning_rate': 0.00436748582451496}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 7s - loss: 356.3279 - mse: 356.3262 - val_loss: 29.2424 - val_mse: 29.2400\n",
      "Epoch 2/3\n",
      "57/57 - 6s - loss: 27.6461 - mse: 27.6436 - val_loss: 28.1655 - val_mse: 28.1630\n",
      "Epoch 3/3\n",
      "57/57 - 6s - loss: 27.8288 - mse: 27.8263 - val_loss: 30.9415 - val_mse: 30.9390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 10:59:52,021]\u001b[0m Trial 22 finished with value: 30.93902122396233 and parameters: {'n_layers': 3, 'weight_decay': 8.99879863068907e-08, 'dropout': 0.4054087549827675, 'n_units_l0': 203, 'n_units_l1': 144, 'n_units_l2': 163, 'optimizer': 'Adam', 'adam_learning_rate': 0.013430606902861594}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 62.4277 - mse: 62.4277 - val_loss: 32.5530 - val_mse: 32.5530\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 28.4434 - mse: 28.4434 - val_loss: 29.9442 - val_mse: 29.9442\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 26.8722 - mse: 26.8722 - val_loss: 29.4176 - val_mse: 29.4176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:00:03,234]\u001b[0m Trial 23 finished with value: 29.417619093207083 and parameters: {'n_layers': 3, 'weight_decay': 2.678519869566393e-09, 'dropout': 0.28805186382752124, 'n_units_l0': 136, 'n_units_l1': 89, 'n_units_l2': 99, 'optimizer': 'Adam', 'adam_learning_rate': 0.0033365350500803087}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 14s - loss: 11180.6836 - mse: 11180.6602 - val_loss: 705.4277 - val_mse: 705.3965\n",
      "Epoch 2/3\n",
      "57/57 - 13s - loss: 691.3522 - mse: 691.3211 - val_loss: 682.5281 - val_mse: 682.4968\n",
      "Epoch 3/3\n",
      "57/57 - 13s - loss: 665.7532 - mse: 665.7218 - val_loss: 654.4709 - val_mse: 654.4395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:00:43,859]\u001b[0m Trial 24 finished with value: 654.4395449196077 and parameters: {'n_layers': 4, 'weight_decay': 9.901923430976877e-08, 'dropout': 0.467897279541026, 'n_units_l0': 164, 'n_units_l1': 87, 'n_units_l2': 244, 'n_units_l3': 255, 'optimizer': 'Adam', 'adam_learning_rate': 0.025819626104366493}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 90.5823 - mse: 90.5823 - val_loss: 33.1708 - val_mse: 33.1708\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 27.5512 - mse: 27.5512 - val_loss: 28.1176 - val_mse: 28.1176\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 26.7952 - mse: 26.7951 - val_loss: 27.8184 - val_mse: 27.8184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:01:00,028]\u001b[0m Trial 25 finished with value: 27.818381581153407 and parameters: {'n_layers': 3, 'weight_decay': 6.926160267996678e-10, 'dropout': 0.3612477775668376, 'n_units_l0': 94, 'n_units_l1': 197, 'n_units_l2': 72, 'optimizer': 'Adam', 'adam_learning_rate': 0.00679467641786644}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 68.0982 - mse: 68.0982 - val_loss: 36.1006 - val_mse: 36.1006\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 32.8688 - mse: 32.8688 - val_loss: 36.3652 - val_mse: 36.3652\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 30.6014 - mse: 30.6014 - val_loss: 34.6015 - val_mse: 34.6015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:01:09,301]\u001b[0m Trial 26 finished with value: 34.601479918938104 and parameters: {'n_layers': 2, 'weight_decay': 8.886823862078131e-10, 'dropout': 0.33632935059570634, 'n_units_l0': 89, 'n_units_l1': 214, 'optimizer': 'Adam', 'adam_learning_rate': 0.001602602289653997}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 49.8772 - mse: 49.8772 - val_loss: 29.1570 - val_mse: 29.1570\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 27.6979 - mse: 27.6979 - val_loss: 29.1173 - val_mse: 29.1173\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 25.7942 - mse: 25.7942 - val_loss: 30.0067 - val_mse: 30.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:01:19,796]\u001b[0m Trial 27 finished with value: 30.00670651274877 and parameters: {'n_layers': 3, 'weight_decay': 5.206079566231821e-09, 'dropout': 0.3647707874853365, 'n_units_l0': 94, 'n_units_l1': 120, 'n_units_l2': 69, 'optimizer': 'Adam', 'adam_learning_rate': 0.005781671232855504}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 700.5955 - mse: 700.5955 - val_loss: 704.1943 - val_mse: 704.1943\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 699.4062 - mse: 699.4062 - val_loss: 703.6353 - val_mse: 703.6353\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 698.7861 - mse: 698.7861 - val_loss: 703.3065 - val_mse: 703.3065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:01:32,081]\u001b[0m Trial 28 finished with value: 703.3066008926004 and parameters: {'n_layers': 4, 'weight_decay': 3.0870632309400095e-10, 'dropout': 0.29940717923314875, 'n_units_l0': 77, 'n_units_l1': 177, 'n_units_l2': 32, 'n_units_l3': 33, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 1.5460359877546164e-05, 'rmsprop_decay': 0.9889890813122181, 'rmsprop_momentum': 0.023156502810137904}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 9s - loss: nan - mse: inf - val_loss: nan - val_mse: 427400536394143235938361278464.0000\n",
      "Epoch 2/3\n",
      "57/57 - 8s - loss: nan - mse: 23879080578346785030413484032.0000 - val_loss: nan - val_mse: 177292467658880450560.0000\n",
      "Epoch 3/3\n",
      "57/57 - 8s - loss: nan - mse: 9905422189308411904.0000 - val_loss: nan - val_mse: 73543434240.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:01:57,729]\u001b[0m Trial 29 finished with value: 73543427644.2916 and parameters: {'n_layers': 5, 'weight_decay': 6.669935007973927e-10, 'dropout': 0.39024414604228347, 'n_units_l0': 37, 'n_units_l1': 145, 'n_units_l2': 53, 'n_units_l3': 142, 'n_units_l4': 256, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.08631186468037616, 'sgd_opt_momentum': 2.3566982169933773e-05}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 77.2916 - mse: 77.2916 - val_loss: 36.2850 - val_mse: 36.2850\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 32.6905 - mse: 32.6905 - val_loss: 32.7966 - val_mse: 32.7966\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 29.6801 - mse: 29.6801 - val_loss: 30.3249 - val_mse: 30.3249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:02:04,420]\u001b[0m Trial 30 finished with value: 30.3248667127996 and parameters: {'n_layers': 2, 'weight_decay': 3.214996349809071e-08, 'dropout': 0.3531796706333548, 'n_units_l0': 54, 'n_units_l1': 213, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.0003959502675922957, 'sgd_opt_momentum': 0.000272368752504295}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 75.4580 - mse: 75.2477 - val_loss: 29.9096 - val_mse: 29.6385\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 27.7547 - mse: 27.4890 - val_loss: 28.1515 - val_mse: 27.8924\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 27.5278 - mse: 27.2713 - val_loss: 30.4531 - val_mse: 30.2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:02:15,601]\u001b[0m Trial 31 finished with value: 30.2012452520069 and parameters: {'n_layers': 3, 'weight_decay': 8.236215925923027e-05, 'dropout': 0.4497630091538812, 'n_units_l0': 125, 'n_units_l1': 106, 'n_units_l2': 83, 'optimizer': 'Adam', 'adam_learning_rate': 0.008275073200806215}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 7s - loss: 10212.8564 - mse: 10212.8008 - val_loss: 31.1855 - val_mse: 31.1069\n",
      "Epoch 2/3\n",
      "57/57 - 6s - loss: 29.9391 - mse: 29.8604 - val_loss: 28.5634 - val_mse: 28.4851\n",
      "Epoch 3/3\n",
      "57/57 - 6s - loss: 29.6176 - mse: 29.5396 - val_loss: 31.4317 - val_mse: 31.3541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:02:35,015]\u001b[0m Trial 32 finished with value: 31.354117370617622 and parameters: {'n_layers': 3, 'weight_decay': 5.831606164067599e-07, 'dropout': 0.4207014807104092, 'n_units_l0': 144, 'n_units_l1': 156, 'n_units_l2': 154, 'optimizer': 'Adam', 'adam_learning_rate': 0.028952419425028388}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 62.0491 - mse: 62.0491 - val_loss: 31.6142 - val_mse: 31.6142\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 27.8127 - mse: 27.8127 - val_loss: 27.4352 - val_mse: 27.4352\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 25.4045 - mse: 25.4045 - val_loss: 27.3875 - val_mse: 27.3875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:02:47,680]\u001b[0m Trial 33 finished with value: 27.38748546944826 and parameters: {'n_layers': 3, 'weight_decay': 4.8387693570486794e-09, 'dropout': 0.43349559269263743, 'n_units_l0': 109, 'n_units_l1': 121, 'n_units_l2': 103, 'optimizer': 'Adam', 'adam_learning_rate': 0.0023446936828748206}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 89.9061 - mse: 89.9061 - val_loss: 38.1311 - val_mse: 38.1311\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 35.8590 - mse: 35.8590 - val_loss: 34.0164 - val_mse: 34.0164\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 32.1974 - mse: 32.1974 - val_loss: 32.6218 - val_mse: 32.6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:03:03,051]\u001b[0m Trial 34 finished with value: 32.62177002859262 and parameters: {'n_layers': 3, 'weight_decay': 6.454203794349295e-09, 'dropout': 0.43431341198035994, 'n_units_l0': 101, 'n_units_l1': 113, 'n_units_l2': 203, 'optimizer': 'Adam', 'adam_learning_rate': 0.00032363747736007843}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 79.4618 - mse: 79.4618 - val_loss: 32.3770 - val_mse: 32.3770\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 31.8994 - mse: 31.8994 - val_loss: 30.1279 - val_mse: 30.1279\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 30.7070 - mse: 30.7070 - val_loss: 28.7828 - val_mse: 28.7828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:03:13,149]\u001b[0m Trial 35 finished with value: 28.78283474140013 and parameters: {'n_layers': 3, 'weight_decay': 3.126807675793763e-09, 'dropout': 0.3940257263553661, 'n_units_l0': 111, 'n_units_l1': 77, 'n_units_l2': 130, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.00039317865777194303, 'sgd_opt_momentum': 0.0003701559733518888}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 62.9822 - mse: 62.9822 - val_loss: 87.9662 - val_mse: 87.9662\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 28.5628 - mse: 28.5628 - val_loss: 63.1174 - val_mse: 63.1174\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 28.1707 - mse: 28.1707 - val_loss: 43.8264 - val_mse: 43.8264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:03:30,655]\u001b[0m Trial 36 finished with value: 43.82641135211147 and parameters: {'n_layers': 4, 'weight_decay': 4.927240546212767e-10, 'dropout': 0.4362677282256932, 'n_units_l0': 86, 'n_units_l1': 127, 'n_units_l2': 72, 'n_units_l3': 249, 'optimizer': 'Adam', 'adam_learning_rate': 0.002463984405705493}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 80.7871 - mse: 80.7871 - val_loss: 36.3005 - val_mse: 36.3005\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 32.7357 - mse: 32.7356 - val_loss: 31.1941 - val_mse: 31.1941\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 28.5360 - mse: 28.5360 - val_loss: 30.3931 - val_mse: 30.3931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:03:38,047]\u001b[0m Trial 37 finished with value: 30.393067882682377 and parameters: {'n_layers': 3, 'weight_decay': 1.0633708031456913e-07, 'dropout': 0.3225718526790159, 'n_units_l0': 63, 'n_units_l1': 100, 'n_units_l2': 48, 'optimizer': 'Adam', 'adam_learning_rate': 0.0011712743825901524}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 7s - loss: 650.2635 - mse: 650.2635 - val_loss: 567.7005 - val_mse: 567.7005\n",
      "Epoch 2/3\n",
      "57/57 - 6s - loss: 372.9629 - mse: 372.9629 - val_loss: 167.5465 - val_mse: 167.5465\n",
      "Epoch 3/3\n",
      "57/57 - 6s - loss: 67.9424 - mse: 67.9424 - val_loss: 45.8873 - val_mse: 45.8873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:03:58,260]\u001b[0m Trial 38 finished with value: 45.88728652695702 and parameters: {'n_layers': 4, 'weight_decay': 1.1052151804919244e-08, 'dropout': 0.36212392756207273, 'n_units_l0': 122, 'n_units_l1': 207, 'n_units_l2': 98, 'n_units_l3': 59, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 1.0521502434471018e-05, 'sgd_opt_momentum': 0.0815326847765571}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 10s - loss: 73.4633 - mse: 73.4633 - val_loss: 36.8772 - val_mse: 36.8772\n",
      "Epoch 2/3\n",
      "57/57 - 10s - loss: 33.1511 - mse: 33.1511 - val_loss: 32.4914 - val_mse: 32.4914\n",
      "Epoch 3/3\n",
      "57/57 - 10s - loss: 28.7187 - mse: 28.7187 - val_loss: 30.2807 - val_mse: 30.2807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:04:28,837]\u001b[0m Trial 39 finished with value: 30.280688318533233 and parameters: {'n_layers': 3, 'weight_decay': 2.051228346892341e-09, 'dropout': 0.4686010798861611, 'n_units_l0': 101, 'n_units_l1': 243, 'n_units_l2': 202, 'optimizer': 'Adam', 'adam_learning_rate': 0.0004500107003161877}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 634.1060 - mse: 634.1060 - val_loss: 626.9202 - val_mse: 626.9202\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 618.9454 - mse: 618.9454 - val_loss: 620.2316 - val_mse: 620.2316\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 613.7224 - mse: 613.7224 - val_loss: 616.2992 - val_mse: 616.2992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:04:33,892]\u001b[0m Trial 40 finished with value: 616.2992068222093 and parameters: {'n_layers': 2, 'weight_decay': 3.5729749102183427e-08, 'dropout': 0.23808694032906164, 'n_units_l0': 81, 'n_units_l1': 78, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 2.499258215047499e-05, 'rmsprop_decay': 0.8590654319729996, 'rmsprop_momentum': 1.010274755543365e-05}. Best is trial 18 with value: 27.320157399363325.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 115.8088 - mse: 115.8073 - val_loss: 32.9373 - val_mse: 32.9356\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 30.6055 - mse: 30.6038 - val_loss: 27.7738 - val_mse: 27.7721\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 27.0843 - mse: 27.0825 - val_loss: 26.8725 - val_mse: 26.8706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:04:42,846]\u001b[0m Trial 41 finished with value: 26.870570073617866 and parameters: {'n_layers': 3, 'weight_decay': 1.3659002173249076e-06, 'dropout': 0.47570913680149285, 'n_units_l0': 171, 'n_units_l1': 57, 'n_units_l2': 110, 'optimizer': 'Adam', 'adam_learning_rate': 0.005669993306937853}. Best is trial 41 with value: 26.870570073617866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 124.6594 - mse: 124.6578 - val_loss: 32.8126 - val_mse: 32.8107\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 30.4587 - mse: 30.4567 - val_loss: 28.3821 - val_mse: 28.3802\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 27.1182 - mse: 27.1162 - val_loss: 27.2622 - val_mse: 27.2602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:04:52,823]\u001b[0m Trial 42 finished with value: 27.260155925955676 and parameters: {'n_layers': 3, 'weight_decay': 1.7727564849112096e-06, 'dropout': 0.4218460760659712, 'n_units_l0': 181, 'n_units_l1': 61, 'n_units_l2': 131, 'optimizer': 'Adam', 'adam_learning_rate': 0.004618343559799091}. Best is trial 41 with value: 26.870570073617866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 73.7626 - mse: 73.7620 - val_loss: 32.8691 - val_mse: 32.8686\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 30.3697 - mse: 30.3692 - val_loss: 28.6236 - val_mse: 28.6231\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 26.9624 - mse: 26.9618 - val_loss: 28.4448 - val_mse: 28.4442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:05:02,334]\u001b[0m Trial 43 finished with value: 28.444232333160976 and parameters: {'n_layers': 3, 'weight_decay': 1.2401645812752596e-06, 'dropout': 0.4261810305315894, 'n_units_l0': 219, 'n_units_l1': 53, 'n_units_l2': 124, 'optimizer': 'Adam', 'adam_learning_rate': 0.002190820693599112}. Best is trial 41 with value: 26.870570073617866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 86.5787 - mse: 86.5738 - val_loss: 31.9204 - val_mse: 31.9145\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 29.2114 - mse: 29.2052 - val_loss: 28.7853 - val_mse: 28.7788\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 27.2335 - mse: 27.2268 - val_loss: 27.7349 - val_mse: 27.7280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:05:13,704]\u001b[0m Trial 44 finished with value: 27.728038587070735 and parameters: {'n_layers': 3, 'weight_decay': 5.422804387481036e-06, 'dropout': 0.47515799813583615, 'n_units_l0': 185, 'n_units_l1': 57, 'n_units_l2': 136, 'optimizer': 'Adam', 'adam_learning_rate': 0.004619752779895117}. Best is trial 41 with value: 26.870570073617866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 9s - loss: 142.4165 - mse: 142.3664 - val_loss: 57.7757 - val_mse: 57.7135\n",
      "Epoch 2/3\n",
      "57/57 - 7s - loss: 30.2008 - mse: 30.1379 - val_loss: 31.8549 - val_mse: 31.7914\n",
      "Epoch 3/3\n",
      "57/57 - 7s - loss: 27.7732 - mse: 27.7093 - val_loss: 31.3446 - val_mse: 31.2802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:05:36,937]\u001b[0m Trial 45 finished with value: 31.280173227118095 and parameters: {'n_layers': 4, 'weight_decay': 2.6509447574295266e-05, 'dropout': 0.4472849842402826, 'n_units_l0': 175, 'n_units_l1': 69, 'n_units_l2': 151, 'n_units_l3': 165, 'optimizer': 'Adam', 'adam_learning_rate': 0.0036185096960016337}. Best is trial 41 with value: 26.870570073617866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 180.9755 - mse: 180.9753 - val_loss: 115.1359 - val_mse: 115.1357\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 92.3275 - mse: 92.3274 - val_loss: 83.1739 - val_mse: 83.1737\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 71.2819 - mse: 71.2818 - val_loss: 67.6538 - val_mse: 67.6537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:05:45,194]\u001b[0m Trial 46 finished with value: 67.65368574550378 and parameters: {'n_layers': 3, 'weight_decay': 3.564664736387314e-07, 'dropout': 0.4068409824793045, 'n_units_l0': 148, 'n_units_l1': 54, 'n_units_l2': 117, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.0004398845569650868, 'rmsprop_decay': 0.9879013220885003, 'rmsprop_momentum': 0.09026363949982959}. Best is trial 41 with value: 26.870570073617866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 209.3959 - mse: 209.3869 - val_loss: 28.5081 - val_mse: 28.4958\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 31.1498 - mse: 31.1373 - val_loss: 28.4174 - val_mse: 28.4049\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 30.0498 - mse: 30.0374 - val_loss: 28.9326 - val_mse: 28.9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:05:56,548]\u001b[0m Trial 47 finished with value: 28.92011840657127 and parameters: {'n_layers': 3, 'weight_decay': 8.971733263496368e-07, 'dropout': 0.4763324213642964, 'n_units_l0': 136, 'n_units_l1': 64, 'n_units_l2': 95, 'optimizer': 'Adam', 'adam_learning_rate': 0.018753765197880787}. Best is trial 41 with value: 26.870570073617866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 74.6241 - mse: 74.6230 - val_loss: 34.0972 - val_mse: 34.0961\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 30.4491 - mse: 30.4481 - val_loss: 30.0592 - val_mse: 30.0581\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 26.9143 - mse: 26.9132 - val_loss: 28.5459 - val_mse: 28.5448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:06:05,837]\u001b[0m Trial 48 finished with value: 28.54475723094708 and parameters: {'n_layers': 3, 'weight_decay': 2.0721142989065447e-06, 'dropout': 0.20404863166005796, 'n_units_l0': 225, 'n_units_l1': 42, 'n_units_l2': 187, 'optimizer': 'Adam', 'adam_learning_rate': 0.001976782507816719}. Best is trial 41 with value: 26.870570073617866.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 7s - loss: 123747.1328 - mse: 123746.1641 - val_loss: 53.3990 - val_mse: 52.0993\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 35.5533 - mse: 34.2734 - val_loss: 112.8389 - val_mse: 111.5860\n",
      "Epoch 3/3\n",
      "57/57 - 6s - loss: 35.6298 - mse: 34.4026 - val_loss: 37.7122 - val_mse: 36.5111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:06:24,530]\u001b[0m Trial 49 finished with value: 36.511093165590886 and parameters: {'n_layers': 4, 'weight_decay': 4.97311861178295e-06, 'dropout': 0.4561375002183141, 'n_units_l0': 194, 'n_units_l1': 84, 'n_units_l2': 145, 'n_units_l3': 63, 'optimizer': 'Adam', 'adam_learning_rate': 0.06056414222147113}. Best is trial 41 with value: 26.870570073617866.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Mencari hyperparameters terbaik.\n",
    "try:\n",
    "    study = optuna.create_study(sampler = TPESampler(seed = seed), direction = 'minimize')\n",
    "    study.optimize(objective, n_trials = 50)\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c08ff00c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:06:24.807441Z",
     "iopub.status.busy": "2021-11-04T11:06:24.804154Z",
     "iopub.status.idle": "2021-11-04T11:06:24.811091Z",
     "shell.execute_reply": "2021-11-04T11:06:24.810547Z",
     "shell.execute_reply.started": "2021-11-04T10:25:54.753997Z"
    },
    "papermill": {
     "duration": 0.142386,
     "end_time": "2021-11-04T11:06:24.811237",
     "exception": false,
     "start_time": "2021-11-04T11:06:24.668851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 3,\n",
       " 'weight_decay': 1.3659002173249076e-06,\n",
       " 'dropout': 0.47570913680149285,\n",
       " 'n_units_l0': 171,\n",
       " 'n_units_l1': 57,\n",
       " 'n_units_l2': 110,\n",
       " 'optimizer': 'Adam',\n",
       " 'adam_learning_rate': 0.005669993306937853}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan parameter-parameter terbaik.\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "665c3377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:06:25.089454Z",
     "iopub.status.busy": "2021-11-04T11:06:25.088393Z",
     "iopub.status.idle": "2021-11-04T11:06:25.097446Z",
     "shell.execute_reply": "2021-11-04T11:06:25.097948Z",
     "shell.execute_reply.started": "2021-11-04T10:26:02.784876Z"
    },
    "papermill": {
     "duration": 0.152023,
     "end_time": "2021-11-04T11:06:25.098134",
     "exception": false,
     "start_time": "2021-11-04T11:06:24.946111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Membangun model.\n",
    "def prepare_model():\n",
    "    model = Sequential(name = 'Sequential')\n",
    "    n_layers = study.best_params['n_layers']\n",
    "    for i in range(n_layers-1):\n",
    "        num_hidden = study.best_params['n_units_l{}'.format(i)]\n",
    "        if i:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                            name = 'Dense_{}'.format(i)))\n",
    "            model.add(Dropout(study.best_params['dropout'],\n",
    "                              name = 'Dropout_{}'.format(i)))\n",
    "        else:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                            input_shape = (X_train.shape[1], 1),\n",
    "                            name = 'Dense_{}'.format(i)))\n",
    "    model.add(Flatten(name = 'Flatten'))\n",
    "    num_hidden = study.best_params['n_units_l{}'.format(n_layers-1)]\n",
    "    model.add(Dense(num_hidden,\n",
    "                    activation = 'relu',\n",
    "                    kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                    name = 'Dense_{}'.format(n_layers-1)))\n",
    "    model.add(Dense(1,\n",
    "                    activation = 'linear',\n",
    "                    kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                    name = 'Final_Dense'))\n",
    "    \n",
    "    # Mendefinisikan optimizer.\n",
    "    kwargs = {}\n",
    "    optimizer_selected = study.best_params['optimizer']\n",
    "    if optimizer_selected == 'RMSprop':\n",
    "        kwargs['learning_rate'] = study.best_params['rmsprop_learning_rate']\n",
    "        kwargs['decay'] = study.best_params['rmsprop_decay']\n",
    "        kwargs['momentum'] = study.best_params['rmsprop_momentum']\n",
    "    elif optimizer_selected == 'Adam':\n",
    "        kwargs['learning_rate'] = study.best_params['adam_learning_rate']\n",
    "    elif optimizer_selected == 'SGD':\n",
    "        kwargs['learning_rate'] = study.best_params['sgd_opt_learning_rate']\n",
    "        kwargs['momentum'] = study.best_params['sgd_opt_momentum']    \n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "    \n",
    "    # Mengkompilasi model.\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = 'mean_squared_error',\n",
    "                  metrics = ['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ce4f5f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:06:25.367852Z",
     "iopub.status.busy": "2021-11-04T11:06:25.366877Z",
     "iopub.status.idle": "2021-11-04T11:06:25.453965Z",
     "shell.execute_reply": "2021-11-04T11:06:25.453379Z",
     "shell.execute_reply.started": "2021-11-04T10:26:07.607163Z"
    },
    "papermill": {
     "duration": 0.223058,
     "end_time": "2021-11-04T11:06:25.454129",
     "exception": false,
     "start_time": "2021-11-04T11:06:25.231071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_0 (Dense)              (None, 269, 171)          342       \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 269, 57)           9804      \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 269, 57)           0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 15333)             0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 110)               1686740   \n",
      "_________________________________________________________________\n",
      "Final_Dense (Dense)          (None, 1)                 111       \n",
      "=================================================================\n",
      "Total params: 1,696,997\n",
      "Trainable params: 1,696,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan ringkasan dari model.\n",
    "model = prepare_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50c4251b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:06:25.723981Z",
     "iopub.status.busy": "2021-11-04T11:06:25.723007Z",
     "iopub.status.idle": "2021-11-04T11:06:25.726501Z",
     "shell.execute_reply": "2021-11-04T11:06:25.727020Z",
     "shell.execute_reply.started": "2021-11-04T10:26:14.472587Z"
    },
    "papermill": {
     "duration": 0.139882,
     "end_time": "2021-11-04T11:06:25.727200",
     "exception": false,
     "start_time": "2021-11-04T11:06:25.587318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menetapkan batasan untuk berhenti melanjutkan epoch lebih awal.\n",
    "earlystop = EarlyStopping(patience = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "349cde2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:06:26.001365Z",
     "iopub.status.busy": "2021-11-04T11:06:26.000346Z",
     "iopub.status.idle": "2021-11-04T11:06:26.004845Z",
     "shell.execute_reply": "2021-11-04T11:06:26.005400Z",
     "shell.execute_reply.started": "2021-11-04T10:26:17.623786Z"
    },
    "papermill": {
     "duration": 0.145564,
     "end_time": "2021-11-04T11:06:26.005567",
     "exception": false,
     "start_time": "2021-11-04T11:06:25.860003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menetapkan batasan untuk learning rate.\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_mse', \n",
    "                                            patience = 8,\n",
    "                                            verbose = 1,\n",
    "                                            factor = 0.5,\n",
    "                                            mode = 'min',\n",
    "                                            min_lr = 1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97943874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:06:26.276442Z",
     "iopub.status.busy": "2021-11-04T11:06:26.275432Z",
     "iopub.status.idle": "2021-11-04T11:06:26.281247Z",
     "shell.execute_reply": "2021-11-04T11:06:26.281739Z",
     "shell.execute_reply.started": "2021-11-04T10:26:20.705731Z"
    },
    "papermill": {
     "duration": 0.143485,
     "end_time": "2021-11-04T11:06:26.281913",
     "exception": false,
     "start_time": "2021-11-04T11:06:26.138428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Membentuk kelas guna menyimpan output prediksi validasi dan testing untuk setiap epoch.\n",
    "class Metrics(Callback):\n",
    "    def __init__(self, valid_data, test_data):\n",
    "        super().__init__()\n",
    "        self.valid_data = valid_data\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_valid_pred = self.model.predict(self.valid_data)\n",
    "        y_test_pred = self.model.predict(self.test_data)\n",
    "        pd.DataFrame(y_valid_pred).to_csv('valid_preds_{}.csv'.format(epoch), index = False)\n",
    "        pd.DataFrame(y_test_pred).to_csv('test_preds_{}.csv'.format(epoch), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22efe6c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:06:26.560185Z",
     "iopub.status.busy": "2021-11-04T11:06:26.550984Z",
     "iopub.status.idle": "2021-11-04T11:08:35.050516Z",
     "shell.execute_reply": "2021-11-04T11:08:35.049894Z",
     "shell.execute_reply.started": "2021-11-04T10:26:23.335319Z"
    },
    "papermill": {
     "duration": 128.634914,
     "end_time": "2021-11-04T11:08:35.050706",
     "exception": false,
     "start_time": "2021-11-04T11:06:26.415792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "57/57 - 3s - loss: 115.8088 - mse: 115.8073 - val_loss: 32.9373 - val_mse: 32.9356\n",
      "Epoch 2/128\n",
      "57/57 - 3s - loss: 30.6055 - mse: 30.6038 - val_loss: 27.7738 - val_mse: 27.7721\n",
      "Epoch 3/128\n",
      "57/57 - 2s - loss: 27.0843 - mse: 27.0825 - val_loss: 26.8725 - val_mse: 26.8706\n",
      "Epoch 4/128\n",
      "57/57 - 2s - loss: 27.0472 - mse: 27.0453 - val_loss: 27.1188 - val_mse: 27.1169\n",
      "Epoch 5/128\n",
      "57/57 - 2s - loss: 25.9658 - mse: 25.9638 - val_loss: 26.8734 - val_mse: 26.8714\n",
      "Epoch 6/128\n",
      "57/57 - 3s - loss: 26.7764 - mse: 26.7744 - val_loss: 27.2178 - val_mse: 27.2157\n",
      "Epoch 7/128\n",
      "57/57 - 2s - loss: 25.3944 - mse: 25.3923 - val_loss: 27.3749 - val_mse: 27.3728\n",
      "Epoch 8/128\n",
      "57/57 - 2s - loss: 25.2438 - mse: 25.2417 - val_loss: 27.4447 - val_mse: 27.4425\n",
      "Epoch 9/128\n",
      "57/57 - 3s - loss: 25.3083 - mse: 25.3061 - val_loss: 27.6841 - val_mse: 27.6818\n",
      "Epoch 10/128\n",
      "57/57 - 3s - loss: 24.1495 - mse: 24.1472 - val_loss: 28.0772 - val_mse: 28.0749\n",
      "Epoch 11/128\n",
      "57/57 - 2s - loss: 25.4735 - mse: 25.4712 - val_loss: 30.8631 - val_mse: 30.8608\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.002834996674209833.\n",
      "Epoch 12/128\n",
      "57/57 - 2s - loss: 23.4590 - mse: 23.4567 - val_loss: 27.8183 - val_mse: 27.8159\n",
      "Epoch 13/128\n",
      "57/57 - 3s - loss: 23.4940 - mse: 23.4916 - val_loss: 29.0406 - val_mse: 29.0382\n",
      "Epoch 14/128\n",
      "57/57 - 3s - loss: 23.5730 - mse: 23.5705 - val_loss: 27.8919 - val_mse: 27.8895\n",
      "Epoch 15/128\n",
      "57/57 - 2s - loss: 23.1731 - mse: 23.1707 - val_loss: 28.2983 - val_mse: 28.2958\n",
      "Epoch 16/128\n",
      "57/57 - 2s - loss: 22.7535 - mse: 22.7510 - val_loss: 28.2351 - val_mse: 28.2326\n",
      "Epoch 17/128\n",
      "57/57 - 3s - loss: 22.7790 - mse: 22.7765 - val_loss: 31.3160 - val_mse: 31.3134\n",
      "Epoch 18/128\n",
      "57/57 - 2s - loss: 22.1138 - mse: 22.1113 - val_loss: 28.6755 - val_mse: 28.6729\n",
      "Epoch 19/128\n",
      "57/57 - 2s - loss: 23.3151 - mse: 23.3125 - val_loss: 31.0432 - val_mse: 31.0406\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0014174983371049166.\n",
      "Epoch 20/128\n",
      "57/57 - 3s - loss: 22.5781 - mse: 22.5754 - val_loss: 28.1511 - val_mse: 28.1485\n",
      "Epoch 21/128\n",
      "57/57 - 3s - loss: 21.8710 - mse: 21.8683 - val_loss: 28.3568 - val_mse: 28.3542\n",
      "Epoch 22/128\n",
      "57/57 - 2s - loss: 21.8604 - mse: 21.8577 - val_loss: 28.5761 - val_mse: 28.5734\n",
      "Epoch 23/128\n",
      "57/57 - 2s - loss: 21.6100 - mse: 21.6073 - val_loss: 28.6634 - val_mse: 28.6607\n",
      "Epoch 24/128\n",
      "57/57 - 2s - loss: 22.1408 - mse: 22.1380 - val_loss: 28.9030 - val_mse: 28.9003\n",
      "Epoch 25/128\n",
      "57/57 - 3s - loss: 21.7212 - mse: 21.7184 - val_loss: 28.7341 - val_mse: 28.7313\n",
      "Epoch 26/128\n",
      "57/57 - 2s - loss: 20.9572 - mse: 20.9544 - val_loss: 29.3091 - val_mse: 29.3062\n",
      "Epoch 27/128\n",
      "57/57 - 3s - loss: 21.7708 - mse: 21.7680 - val_loss: 28.7062 - val_mse: 28.7033\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0007087491685524583.\n",
      "Epoch 28/128\n",
      "57/57 - 3s - loss: 20.8540 - mse: 20.8511 - val_loss: 28.9603 - val_mse: 28.9574\n",
      "Epoch 29/128\n",
      "57/57 - 2s - loss: 20.3502 - mse: 20.3473 - val_loss: 28.9590 - val_mse: 28.9561\n",
      "Epoch 30/128\n",
      "57/57 - 2s - loss: 20.4532 - mse: 20.4503 - val_loss: 29.1119 - val_mse: 29.1090\n",
      "Epoch 31/128\n",
      "57/57 - 3s - loss: 20.6677 - mse: 20.6648 - val_loss: 29.4016 - val_mse: 29.3987\n",
      "Epoch 32/128\n",
      "57/57 - 3s - loss: 20.5054 - mse: 20.5025 - val_loss: 29.2492 - val_mse: 29.2463\n",
      "Epoch 33/128\n",
      "57/57 - 2s - loss: 20.0772 - mse: 20.0743 - val_loss: 29.3950 - val_mse: 29.3920\n",
      "Epoch 34/128\n",
      "57/57 - 3s - loss: 20.5011 - mse: 20.4981 - val_loss: 29.3522 - val_mse: 29.3492\n",
      "Epoch 35/128\n",
      "57/57 - 2s - loss: 20.3045 - mse: 20.3015 - val_loss: 29.5301 - val_mse: 29.5271\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00035437458427622914.\n",
      "Epoch 36/128\n",
      "57/57 - 3s - loss: 19.6196 - mse: 19.6166 - val_loss: 29.2369 - val_mse: 29.2339\n",
      "Epoch 37/128\n",
      "57/57 - 3s - loss: 19.8445 - mse: 19.8415 - val_loss: 29.3005 - val_mse: 29.2975\n",
      "Epoch 38/128\n",
      "57/57 - 2s - loss: 19.7524 - mse: 19.7494 - val_loss: 29.3295 - val_mse: 29.3264\n",
      "Epoch 39/128\n",
      "57/57 - 2s - loss: 19.2828 - mse: 19.2798 - val_loss: 29.4239 - val_mse: 29.4208\n",
      "Epoch 40/128\n",
      "57/57 - 3s - loss: 19.1941 - mse: 19.1911 - val_loss: 29.2905 - val_mse: 29.2875\n",
      "Epoch 41/128\n",
      "57/57 - 2s - loss: 19.4303 - mse: 19.4273 - val_loss: 29.3470 - val_mse: 29.3439\n",
      "Epoch 42/128\n",
      "57/57 - 3s - loss: 19.1144 - mse: 19.1113 - val_loss: 29.3938 - val_mse: 29.3908\n",
      "Epoch 43/128\n",
      "57/57 - 3s - loss: 19.8624 - mse: 19.8593 - val_loss: 29.4958 - val_mse: 29.4928\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00017718729213811457.\n"
     ]
    }
   ],
   "source": [
    "# Melakukan fitting model.\n",
    "set_seed()\n",
    "model = prepare_model()\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                    verbose = 2,\n",
    "                    steps_per_epoch = X_train.shape[0] // batch_size,\n",
    "                    callbacks = [earlystop,\n",
    "                                 learning_rate_reduction,\n",
    "                                 Metrics(X_valid,\n",
    "                                         X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dfe89fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:08:35.380391Z",
     "iopub.status.busy": "2021-11-04T11:08:35.379692Z",
     "iopub.status.idle": "2021-11-04T11:08:36.626869Z",
     "shell.execute_reply": "2021-11-04T11:08:36.627388Z",
     "shell.execute_reply.started": "2021-11-04T08:32:50.263585Z"
    },
    "papermill": {
     "duration": 1.416414,
     "end_time": "2021-11-04T11:08:36.627565",
     "exception": false,
     "start_time": "2021-11-04T11:08:35.211151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Melakukan visualisasi nilai MSE pada data training dan testing.\n",
    "fig, ax = plt.subplots(1, 1, figsize = (12, 12))\n",
    "ax.plot(history.history['mse'], color='b', label = 'training MSE')\n",
    "ax.plot(history.history['val_mse'], color='r', label = 'validation MSE')\n",
    "ax.set_xticks(np.arange(1, epochs, 1))\n",
    "legend = plt.legend(loc = 'best', shadow = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2921fb64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:08:36.955913Z",
     "iopub.status.busy": "2021-11-04T11:08:36.955122Z",
     "iopub.status.idle": "2021-11-04T11:08:36.980811Z",
     "shell.execute_reply": "2021-11-04T11:08:36.981344Z",
     "shell.execute_reply.started": "2021-11-04T05:26:23.068789Z"
    },
    "papermill": {
     "duration": 0.19107,
     "end_time": "2021-11-04T11:08:36.981509",
     "exception": false,
     "start_time": "2021-11-04T11:08:36.790439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>27.084307</td>\n",
       "      <td>27.082504</td>\n",
       "      <td>26.872469</td>\n",
       "      <td>26.870573</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>25.965786</td>\n",
       "      <td>25.963829</td>\n",
       "      <td>26.873373</td>\n",
       "      <td>26.871393</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>27.047228</td>\n",
       "      <td>27.045303</td>\n",
       "      <td>27.118832</td>\n",
       "      <td>27.116888</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>26.776402</td>\n",
       "      <td>26.774364</td>\n",
       "      <td>27.217836</td>\n",
       "      <td>27.215731</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>25.394421</td>\n",
       "      <td>25.392298</td>\n",
       "      <td>27.374947</td>\n",
       "      <td>27.372801</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>25.243849</td>\n",
       "      <td>25.241674</td>\n",
       "      <td>27.444736</td>\n",
       "      <td>27.442547</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>25.308283</td>\n",
       "      <td>25.306061</td>\n",
       "      <td>27.684078</td>\n",
       "      <td>27.681829</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>30.605490</td>\n",
       "      <td>30.603769</td>\n",
       "      <td>27.773800</td>\n",
       "      <td>27.772064</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>23.459036</td>\n",
       "      <td>23.456652</td>\n",
       "      <td>27.818270</td>\n",
       "      <td>27.815872</td>\n",
       "      <td>0.002835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>23.572966</td>\n",
       "      <td>23.570528</td>\n",
       "      <td>27.891909</td>\n",
       "      <td>27.889462</td>\n",
       "      <td>0.002835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>24.149492</td>\n",
       "      <td>24.147213</td>\n",
       "      <td>28.077223</td>\n",
       "      <td>28.074915</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>22.578062</td>\n",
       "      <td>22.575418</td>\n",
       "      <td>28.151125</td>\n",
       "      <td>28.148472</td>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>22.753454</td>\n",
       "      <td>22.750957</td>\n",
       "      <td>28.235136</td>\n",
       "      <td>28.232626</td>\n",
       "      <td>0.002835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>23.173113</td>\n",
       "      <td>23.170652</td>\n",
       "      <td>28.298306</td>\n",
       "      <td>28.295826</td>\n",
       "      <td>0.002835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>21.870977</td>\n",
       "      <td>21.868311</td>\n",
       "      <td>28.356829</td>\n",
       "      <td>28.354153</td>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21</td>\n",
       "      <td>21.860374</td>\n",
       "      <td>21.857679</td>\n",
       "      <td>28.576132</td>\n",
       "      <td>28.573425</td>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22</td>\n",
       "      <td>21.610043</td>\n",
       "      <td>21.607327</td>\n",
       "      <td>28.663445</td>\n",
       "      <td>28.660715</td>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>22.113850</td>\n",
       "      <td>22.111286</td>\n",
       "      <td>28.675468</td>\n",
       "      <td>28.672888</td>\n",
       "      <td>0.002835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>21.770823</td>\n",
       "      <td>21.767996</td>\n",
       "      <td>28.706175</td>\n",
       "      <td>28.703323</td>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24</td>\n",
       "      <td>21.721209</td>\n",
       "      <td>21.718443</td>\n",
       "      <td>28.734055</td>\n",
       "      <td>28.731260</td>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23</td>\n",
       "      <td>22.140781</td>\n",
       "      <td>22.138041</td>\n",
       "      <td>28.903038</td>\n",
       "      <td>28.900282</td>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>28</td>\n",
       "      <td>20.350199</td>\n",
       "      <td>20.347322</td>\n",
       "      <td>28.959000</td>\n",
       "      <td>28.956116</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27</td>\n",
       "      <td>20.854008</td>\n",
       "      <td>20.851149</td>\n",
       "      <td>28.960287</td>\n",
       "      <td>28.957418</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>23.493969</td>\n",
       "      <td>23.491564</td>\n",
       "      <td>29.040571</td>\n",
       "      <td>29.038155</td>\n",
       "      <td>0.002835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29</td>\n",
       "      <td>20.453239</td>\n",
       "      <td>20.450346</td>\n",
       "      <td>29.111906</td>\n",
       "      <td>29.109007</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>35</td>\n",
       "      <td>19.619566</td>\n",
       "      <td>19.616568</td>\n",
       "      <td>29.236853</td>\n",
       "      <td>29.233852</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>31</td>\n",
       "      <td>20.505396</td>\n",
       "      <td>20.502464</td>\n",
       "      <td>29.249233</td>\n",
       "      <td>29.246298</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39</td>\n",
       "      <td>19.194111</td>\n",
       "      <td>19.191084</td>\n",
       "      <td>29.290506</td>\n",
       "      <td>29.287472</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>36</td>\n",
       "      <td>19.844473</td>\n",
       "      <td>19.841467</td>\n",
       "      <td>29.300541</td>\n",
       "      <td>29.297529</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>25</td>\n",
       "      <td>20.957191</td>\n",
       "      <td>20.954390</td>\n",
       "      <td>29.309055</td>\n",
       "      <td>29.306240</td>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>37</td>\n",
       "      <td>19.752380</td>\n",
       "      <td>19.749363</td>\n",
       "      <td>29.329451</td>\n",
       "      <td>29.326435</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>40</td>\n",
       "      <td>19.430300</td>\n",
       "      <td>19.427256</td>\n",
       "      <td>29.346972</td>\n",
       "      <td>29.343927</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>20.501057</td>\n",
       "      <td>20.498093</td>\n",
       "      <td>29.352169</td>\n",
       "      <td>29.349195</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>41</td>\n",
       "      <td>19.114365</td>\n",
       "      <td>19.111315</td>\n",
       "      <td>29.393824</td>\n",
       "      <td>29.390774</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>32</td>\n",
       "      <td>20.077219</td>\n",
       "      <td>20.074274</td>\n",
       "      <td>29.394968</td>\n",
       "      <td>29.392012</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30</td>\n",
       "      <td>20.667721</td>\n",
       "      <td>20.664814</td>\n",
       "      <td>29.401642</td>\n",
       "      <td>29.398726</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38</td>\n",
       "      <td>19.282770</td>\n",
       "      <td>19.279753</td>\n",
       "      <td>29.423870</td>\n",
       "      <td>29.420839</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>42</td>\n",
       "      <td>19.862354</td>\n",
       "      <td>19.859301</td>\n",
       "      <td>29.495810</td>\n",
       "      <td>29.492750</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>34</td>\n",
       "      <td>20.304518</td>\n",
       "      <td>20.301540</td>\n",
       "      <td>29.530106</td>\n",
       "      <td>29.527117</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>25.473511</td>\n",
       "      <td>25.471170</td>\n",
       "      <td>30.863129</td>\n",
       "      <td>30.860765</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>18</td>\n",
       "      <td>23.315130</td>\n",
       "      <td>23.312527</td>\n",
       "      <td>31.043184</td>\n",
       "      <td>31.040554</td>\n",
       "      <td>0.002835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>16</td>\n",
       "      <td>22.779024</td>\n",
       "      <td>22.776493</td>\n",
       "      <td>31.315964</td>\n",
       "      <td>31.313425</td>\n",
       "      <td>0.002835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>115.808754</td>\n",
       "      <td>115.807320</td>\n",
       "      <td>32.937298</td>\n",
       "      <td>32.935593</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch        loss         mse   val_loss    val_mse        lr\n",
       "0       2   27.084307   27.082504  26.872469  26.870573  0.005670\n",
       "1       4   25.965786   25.963829  26.873373  26.871393  0.005670\n",
       "2       3   27.047228   27.045303  27.118832  27.116888  0.005670\n",
       "3       5   26.776402   26.774364  27.217836  27.215731  0.005670\n",
       "4       6   25.394421   25.392298  27.374947  27.372801  0.005670\n",
       "5       7   25.243849   25.241674  27.444736  27.442547  0.005670\n",
       "6       8   25.308283   25.306061  27.684078  27.681829  0.005670\n",
       "7       1   30.605490   30.603769  27.773800  27.772064  0.005670\n",
       "8      11   23.459036   23.456652  27.818270  27.815872  0.002835\n",
       "9      13   23.572966   23.570528  27.891909  27.889462  0.002835\n",
       "10      9   24.149492   24.147213  28.077223  28.074915  0.005670\n",
       "11     19   22.578062   22.575418  28.151125  28.148472  0.001417\n",
       "12     15   22.753454   22.750957  28.235136  28.232626  0.002835\n",
       "13     14   23.173113   23.170652  28.298306  28.295826  0.002835\n",
       "14     20   21.870977   21.868311  28.356829  28.354153  0.001417\n",
       "15     21   21.860374   21.857679  28.576132  28.573425  0.001417\n",
       "16     22   21.610043   21.607327  28.663445  28.660715  0.001417\n",
       "17     17   22.113850   22.111286  28.675468  28.672888  0.002835\n",
       "18     26   21.770823   21.767996  28.706175  28.703323  0.001417\n",
       "19     24   21.721209   21.718443  28.734055  28.731260  0.001417\n",
       "20     23   22.140781   22.138041  28.903038  28.900282  0.001417\n",
       "21     28   20.350199   20.347322  28.959000  28.956116  0.000709\n",
       "22     27   20.854008   20.851149  28.960287  28.957418  0.000709\n",
       "23     12   23.493969   23.491564  29.040571  29.038155  0.002835\n",
       "24     29   20.453239   20.450346  29.111906  29.109007  0.000709\n",
       "25     35   19.619566   19.616568  29.236853  29.233852  0.000354\n",
       "26     31   20.505396   20.502464  29.249233  29.246298  0.000709\n",
       "27     39   19.194111   19.191084  29.290506  29.287472  0.000354\n",
       "28     36   19.844473   19.841467  29.300541  29.297529  0.000354\n",
       "29     25   20.957191   20.954390  29.309055  29.306240  0.001417\n",
       "30     37   19.752380   19.749363  29.329451  29.326435  0.000354\n",
       "31     40   19.430300   19.427256  29.346972  29.343927  0.000354\n",
       "32     33   20.501057   20.498093  29.352169  29.349195  0.000709\n",
       "33     41   19.114365   19.111315  29.393824  29.390774  0.000354\n",
       "34     32   20.077219   20.074274  29.394968  29.392012  0.000709\n",
       "35     30   20.667721   20.664814  29.401642  29.398726  0.000709\n",
       "36     38   19.282770   19.279753  29.423870  29.420839  0.000354\n",
       "37     42   19.862354   19.859301  29.495810  29.492750  0.000354\n",
       "38     34   20.304518   20.301540  29.530106  29.527117  0.000709\n",
       "39     10   25.473511   25.471170  30.863129  30.860765  0.005670\n",
       "40     18   23.315130   23.312527  31.043184  31.040554  0.002835\n",
       "41     16   22.779024   22.776493  31.315964  31.313425  0.002835\n",
       "42      0  115.808754  115.807320  32.937298  32.935593  0.005670"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menyusun rekam jejak model berdasarkan nilai MSE pada setiap epoch, diurutkan dari yang terbaik.\n",
    "history_df = pd.DataFrame(history.history).sort_values('val_mse').reset_index()\n",
    "history_df.rename(columns = {'index': 'epoch'}, inplace = True)\n",
    "history_df.to_csv('history_{}.csv'.format(codename), index = False)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15dfb39f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:08:37.316297Z",
     "iopub.status.busy": "2021-11-04T11:08:37.309829Z",
     "iopub.status.idle": "2021-11-04T11:08:37.577149Z",
     "shell.execute_reply": "2021-11-04T11:08:37.577729Z"
    },
    "papermill": {
     "duration": 0.432791,
     "end_time": "2021-11-04T11:08:37.577921",
     "exception": false,
     "start_time": "2021-11-04T11:08:37.145130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyimpan nilai prediksi validasi dan testing diurutkan berdasarkan nilai validasi MSE terbaik.\n",
    "best_valid_preds = pd.DataFrame()\n",
    "best_test_preds = pd.DataFrame()\n",
    "\n",
    "for temp_index in list(history_df.iloc[:, 0]):\n",
    "    temp_df_valid = pd.read_csv('./valid_preds_{}.csv'.format(temp_index))\n",
    "    temp_df_test = pd.read_csv('./test_preds_{}.csv'.format(temp_index))\n",
    "    best_valid_preds = pd.concat([best_valid_preds, temp_df_valid], axis = 1, ignore_index = True)\n",
    "    best_test_preds = pd.concat([best_test_preds, temp_df_test], axis = 1, ignore_index = True)\n",
    "\n",
    "best_valid_preds.to_csv('valid_preds_{}.csv'.format(codename), index = False)\n",
    "best_test_preds.to_csv('test_preds_{}.csv'.format(codename), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5153620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:08:37.911499Z",
     "iopub.status.busy": "2021-11-04T11:08:37.910495Z",
     "iopub.status.idle": "2021-11-04T11:08:37.915514Z",
     "shell.execute_reply": "2021-11-04T11:08:37.916361Z"
    },
    "papermill": {
     "duration": 0.175236,
     "end_time": "2021-11-04T11:08:37.916537",
     "exception": false,
     "start_time": "2021-11-04T11:08:37.741301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Membuang file yang sudah tidak diperlukan.\n",
    "for temp_index in list(history_df.iloc[:, 0]):\n",
    "    os.remove('./valid_preds_{}.csv'.format(temp_index))\n",
    "    os.remove('./test_preds_{}.csv'.format(temp_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82fffcfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:08:38.245149Z",
     "iopub.status.busy": "2021-11-04T11:08:38.244170Z",
     "iopub.status.idle": "2021-11-04T11:08:38.278130Z",
     "shell.execute_reply": "2021-11-04T11:08:38.278764Z"
    },
    "papermill": {
     "duration": 0.200073,
     "end_time": "2021-11-04T11:08:38.278935",
     "exception": false,
     "start_time": "2021-11-04T11:08:38.078862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.289328</td>\n",
       "      <td>27.847775</td>\n",
       "      <td>27.951270</td>\n",
       "      <td>28.136000</td>\n",
       "      <td>27.585934</td>\n",
       "      <td>27.379730</td>\n",
       "      <td>27.542408</td>\n",
       "      <td>24.855246</td>\n",
       "      <td>29.138363</td>\n",
       "      <td>29.524760</td>\n",
       "      <td>...</td>\n",
       "      <td>29.898180</td>\n",
       "      <td>30.451815</td>\n",
       "      <td>29.303316</td>\n",
       "      <td>30.234250</td>\n",
       "      <td>29.513197</td>\n",
       "      <td>30.564970</td>\n",
       "      <td>27.346231</td>\n",
       "      <td>27.905235</td>\n",
       "      <td>27.629097</td>\n",
       "      <td>20.717447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.656046</td>\n",
       "      <td>28.869492</td>\n",
       "      <td>29.239060</td>\n",
       "      <td>28.963808</td>\n",
       "      <td>27.378138</td>\n",
       "      <td>27.484016</td>\n",
       "      <td>26.900196</td>\n",
       "      <td>27.597216</td>\n",
       "      <td>27.704662</td>\n",
       "      <td>27.925634</td>\n",
       "      <td>...</td>\n",
       "      <td>27.768934</td>\n",
       "      <td>28.515894</td>\n",
       "      <td>27.350450</td>\n",
       "      <td>28.300050</td>\n",
       "      <td>27.596363</td>\n",
       "      <td>28.492510</td>\n",
       "      <td>26.153399</td>\n",
       "      <td>26.366524</td>\n",
       "      <td>25.869251</td>\n",
       "      <td>27.557161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.551928</td>\n",
       "      <td>26.869795</td>\n",
       "      <td>27.071793</td>\n",
       "      <td>27.786594</td>\n",
       "      <td>26.962480</td>\n",
       "      <td>26.690990</td>\n",
       "      <td>25.387175</td>\n",
       "      <td>25.968920</td>\n",
       "      <td>25.939672</td>\n",
       "      <td>26.254816</td>\n",
       "      <td>...</td>\n",
       "      <td>25.681047</td>\n",
       "      <td>26.450285</td>\n",
       "      <td>25.021520</td>\n",
       "      <td>25.854540</td>\n",
       "      <td>25.568254</td>\n",
       "      <td>26.442984</td>\n",
       "      <td>23.933693</td>\n",
       "      <td>24.186968</td>\n",
       "      <td>24.420372</td>\n",
       "      <td>26.572643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.991003</td>\n",
       "      <td>25.108965</td>\n",
       "      <td>25.568897</td>\n",
       "      <td>25.750336</td>\n",
       "      <td>23.865599</td>\n",
       "      <td>24.358380</td>\n",
       "      <td>23.784033</td>\n",
       "      <td>23.740498</td>\n",
       "      <td>24.689926</td>\n",
       "      <td>24.262910</td>\n",
       "      <td>...</td>\n",
       "      <td>23.507385</td>\n",
       "      <td>23.983870</td>\n",
       "      <td>22.911276</td>\n",
       "      <td>23.691158</td>\n",
       "      <td>23.155167</td>\n",
       "      <td>24.103544</td>\n",
       "      <td>22.530704</td>\n",
       "      <td>21.906345</td>\n",
       "      <td>22.432419</td>\n",
       "      <td>23.045027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.630373</td>\n",
       "      <td>26.467386</td>\n",
       "      <td>27.139978</td>\n",
       "      <td>26.548597</td>\n",
       "      <td>25.542145</td>\n",
       "      <td>25.478910</td>\n",
       "      <td>25.706015</td>\n",
       "      <td>24.386986</td>\n",
       "      <td>25.960735</td>\n",
       "      <td>26.119684</td>\n",
       "      <td>...</td>\n",
       "      <td>26.534510</td>\n",
       "      <td>26.860804</td>\n",
       "      <td>25.727669</td>\n",
       "      <td>26.776579</td>\n",
       "      <td>26.394485</td>\n",
       "      <td>26.698217</td>\n",
       "      <td>24.330880</td>\n",
       "      <td>24.453123</td>\n",
       "      <td>24.296871</td>\n",
       "      <td>20.531654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>25.166170</td>\n",
       "      <td>24.130749</td>\n",
       "      <td>24.985142</td>\n",
       "      <td>24.144693</td>\n",
       "      <td>23.506044</td>\n",
       "      <td>23.164230</td>\n",
       "      <td>22.961088</td>\n",
       "      <td>25.345892</td>\n",
       "      <td>22.802425</td>\n",
       "      <td>22.946135</td>\n",
       "      <td>...</td>\n",
       "      <td>23.689325</td>\n",
       "      <td>23.912598</td>\n",
       "      <td>22.596054</td>\n",
       "      <td>23.757298</td>\n",
       "      <td>23.270433</td>\n",
       "      <td>24.250517</td>\n",
       "      <td>21.094738</td>\n",
       "      <td>21.274591</td>\n",
       "      <td>21.425194</td>\n",
       "      <td>26.611322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>25.378536</td>\n",
       "      <td>25.481209</td>\n",
       "      <td>26.057112</td>\n",
       "      <td>26.082670</td>\n",
       "      <td>24.690557</td>\n",
       "      <td>24.821490</td>\n",
       "      <td>24.962730</td>\n",
       "      <td>25.055498</td>\n",
       "      <td>25.328115</td>\n",
       "      <td>24.925694</td>\n",
       "      <td>...</td>\n",
       "      <td>25.085830</td>\n",
       "      <td>25.472582</td>\n",
       "      <td>24.151384</td>\n",
       "      <td>24.780073</td>\n",
       "      <td>24.772223</td>\n",
       "      <td>25.252588</td>\n",
       "      <td>23.850443</td>\n",
       "      <td>22.963486</td>\n",
       "      <td>22.967741</td>\n",
       "      <td>24.123014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>26.824987</td>\n",
       "      <td>27.642612</td>\n",
       "      <td>27.861296</td>\n",
       "      <td>28.468212</td>\n",
       "      <td>26.654413</td>\n",
       "      <td>26.467669</td>\n",
       "      <td>27.253555</td>\n",
       "      <td>25.827322</td>\n",
       "      <td>28.114298</td>\n",
       "      <td>27.701921</td>\n",
       "      <td>...</td>\n",
       "      <td>28.552933</td>\n",
       "      <td>29.192257</td>\n",
       "      <td>27.836695</td>\n",
       "      <td>28.735086</td>\n",
       "      <td>28.377605</td>\n",
       "      <td>28.949272</td>\n",
       "      <td>26.546366</td>\n",
       "      <td>26.287746</td>\n",
       "      <td>25.903399</td>\n",
       "      <td>22.902197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>25.516218</td>\n",
       "      <td>25.345661</td>\n",
       "      <td>25.905684</td>\n",
       "      <td>25.626260</td>\n",
       "      <td>24.210764</td>\n",
       "      <td>24.764332</td>\n",
       "      <td>24.279436</td>\n",
       "      <td>24.671322</td>\n",
       "      <td>25.783610</td>\n",
       "      <td>26.216950</td>\n",
       "      <td>...</td>\n",
       "      <td>27.568962</td>\n",
       "      <td>27.905691</td>\n",
       "      <td>26.556534</td>\n",
       "      <td>27.840190</td>\n",
       "      <td>27.402216</td>\n",
       "      <td>27.921920</td>\n",
       "      <td>23.861290</td>\n",
       "      <td>24.545803</td>\n",
       "      <td>24.443888</td>\n",
       "      <td>25.816624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>24.807440</td>\n",
       "      <td>25.522856</td>\n",
       "      <td>26.029610</td>\n",
       "      <td>26.251940</td>\n",
       "      <td>25.351690</td>\n",
       "      <td>25.621084</td>\n",
       "      <td>25.610178</td>\n",
       "      <td>23.952736</td>\n",
       "      <td>26.198189</td>\n",
       "      <td>26.296686</td>\n",
       "      <td>...</td>\n",
       "      <td>26.699091</td>\n",
       "      <td>27.393917</td>\n",
       "      <td>26.147090</td>\n",
       "      <td>27.015570</td>\n",
       "      <td>26.349272</td>\n",
       "      <td>27.497612</td>\n",
       "      <td>24.809519</td>\n",
       "      <td>24.359688</td>\n",
       "      <td>24.407297</td>\n",
       "      <td>21.847874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5   \\\n",
       "0    26.289328  27.847775  27.951270  28.136000  27.585934  27.379730   \n",
       "1    28.656046  28.869492  29.239060  28.963808  27.378138  27.484016   \n",
       "2    26.551928  26.869795  27.071793  27.786594  26.962480  26.690990   \n",
       "3    24.991003  25.108965  25.568897  25.750336  23.865599  24.358380   \n",
       "4    25.630373  26.467386  27.139978  26.548597  25.542145  25.478910   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "456  25.166170  24.130749  24.985142  24.144693  23.506044  23.164230   \n",
       "457  25.378536  25.481209  26.057112  26.082670  24.690557  24.821490   \n",
       "458  26.824987  27.642612  27.861296  28.468212  26.654413  26.467669   \n",
       "459  25.516218  25.345661  25.905684  25.626260  24.210764  24.764332   \n",
       "460  24.807440  25.522856  26.029610  26.251940  25.351690  25.621084   \n",
       "\n",
       "            6          7          8          9   ...         33         34  \\\n",
       "0    27.542408  24.855246  29.138363  29.524760  ...  29.898180  30.451815   \n",
       "1    26.900196  27.597216  27.704662  27.925634  ...  27.768934  28.515894   \n",
       "2    25.387175  25.968920  25.939672  26.254816  ...  25.681047  26.450285   \n",
       "3    23.784033  23.740498  24.689926  24.262910  ...  23.507385  23.983870   \n",
       "4    25.706015  24.386986  25.960735  26.119684  ...  26.534510  26.860804   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "456  22.961088  25.345892  22.802425  22.946135  ...  23.689325  23.912598   \n",
       "457  24.962730  25.055498  25.328115  24.925694  ...  25.085830  25.472582   \n",
       "458  27.253555  25.827322  28.114298  27.701921  ...  28.552933  29.192257   \n",
       "459  24.279436  24.671322  25.783610  26.216950  ...  27.568962  27.905691   \n",
       "460  25.610178  23.952736  26.198189  26.296686  ...  26.699091  27.393917   \n",
       "\n",
       "            35         36         37         38         39         40  \\\n",
       "0    29.303316  30.234250  29.513197  30.564970  27.346231  27.905235   \n",
       "1    27.350450  28.300050  27.596363  28.492510  26.153399  26.366524   \n",
       "2    25.021520  25.854540  25.568254  26.442984  23.933693  24.186968   \n",
       "3    22.911276  23.691158  23.155167  24.103544  22.530704  21.906345   \n",
       "4    25.727669  26.776579  26.394485  26.698217  24.330880  24.453123   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "456  22.596054  23.757298  23.270433  24.250517  21.094738  21.274591   \n",
       "457  24.151384  24.780073  24.772223  25.252588  23.850443  22.963486   \n",
       "458  27.836695  28.735086  28.377605  28.949272  26.546366  26.287746   \n",
       "459  26.556534  27.840190  27.402216  27.921920  23.861290  24.545803   \n",
       "460  26.147090  27.015570  26.349272  27.497612  24.809519  24.359688   \n",
       "\n",
       "            41         42  \n",
       "0    27.629097  20.717447  \n",
       "1    25.869251  27.557161  \n",
       "2    24.420372  26.572643  \n",
       "3    22.432419  23.045027  \n",
       "4    24.296871  20.531654  \n",
       "..         ...        ...  \n",
       "456  21.425194  26.611322  \n",
       "457  22.967741  24.123014  \n",
       "458  25.903399  22.902197  \n",
       "459  24.443888  25.816624  \n",
       "460  24.407297  21.847874  \n",
       "\n",
       "[461 rows x 43 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan prediksi data validasi diurutkan berdasarkan nilai validasi MSE terbaik.\n",
    "best_valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2073ab4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:08:38.611700Z",
     "iopub.status.busy": "2021-11-04T11:08:38.610713Z",
     "iopub.status.idle": "2021-11-04T11:08:38.645290Z",
     "shell.execute_reply": "2021-11-04T11:08:38.645799Z"
    },
    "papermill": {
     "duration": 0.203628,
     "end_time": "2021-11-04T11:08:38.645969",
     "exception": false,
     "start_time": "2021-11-04T11:08:38.442341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.763248</td>\n",
       "      <td>25.472006</td>\n",
       "      <td>25.895120</td>\n",
       "      <td>25.504951</td>\n",
       "      <td>25.378044</td>\n",
       "      <td>24.939062</td>\n",
       "      <td>24.189066</td>\n",
       "      <td>24.356873</td>\n",
       "      <td>24.779787</td>\n",
       "      <td>25.207314</td>\n",
       "      <td>...</td>\n",
       "      <td>23.884264</td>\n",
       "      <td>24.675434</td>\n",
       "      <td>23.367365</td>\n",
       "      <td>24.083204</td>\n",
       "      <td>23.456833</td>\n",
       "      <td>24.571740</td>\n",
       "      <td>22.773201</td>\n",
       "      <td>22.838780</td>\n",
       "      <td>23.287376</td>\n",
       "      <td>25.940700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.542997</td>\n",
       "      <td>28.268023</td>\n",
       "      <td>28.266886</td>\n",
       "      <td>27.982456</td>\n",
       "      <td>27.620564</td>\n",
       "      <td>27.364193</td>\n",
       "      <td>28.217050</td>\n",
       "      <td>26.803938</td>\n",
       "      <td>28.180912</td>\n",
       "      <td>28.558092</td>\n",
       "      <td>...</td>\n",
       "      <td>28.818031</td>\n",
       "      <td>29.468788</td>\n",
       "      <td>28.275314</td>\n",
       "      <td>29.179426</td>\n",
       "      <td>28.378897</td>\n",
       "      <td>29.565613</td>\n",
       "      <td>26.933538</td>\n",
       "      <td>27.316801</td>\n",
       "      <td>26.472404</td>\n",
       "      <td>26.259075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.609253</td>\n",
       "      <td>26.727201</td>\n",
       "      <td>27.622810</td>\n",
       "      <td>27.220633</td>\n",
       "      <td>26.190790</td>\n",
       "      <td>26.491024</td>\n",
       "      <td>25.919535</td>\n",
       "      <td>25.269215</td>\n",
       "      <td>26.973705</td>\n",
       "      <td>27.675621</td>\n",
       "      <td>...</td>\n",
       "      <td>28.405407</td>\n",
       "      <td>28.791490</td>\n",
       "      <td>27.497458</td>\n",
       "      <td>28.443201</td>\n",
       "      <td>27.942884</td>\n",
       "      <td>28.846746</td>\n",
       "      <td>24.905685</td>\n",
       "      <td>25.685677</td>\n",
       "      <td>25.712965</td>\n",
       "      <td>25.727130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.960245</td>\n",
       "      <td>25.758175</td>\n",
       "      <td>26.150414</td>\n",
       "      <td>25.934990</td>\n",
       "      <td>25.548695</td>\n",
       "      <td>26.108290</td>\n",
       "      <td>25.814043</td>\n",
       "      <td>25.055452</td>\n",
       "      <td>26.825954</td>\n",
       "      <td>27.122200</td>\n",
       "      <td>...</td>\n",
       "      <td>27.548962</td>\n",
       "      <td>27.874758</td>\n",
       "      <td>26.574425</td>\n",
       "      <td>27.681950</td>\n",
       "      <td>27.160301</td>\n",
       "      <td>28.041866</td>\n",
       "      <td>25.015230</td>\n",
       "      <td>25.505830</td>\n",
       "      <td>24.948660</td>\n",
       "      <td>26.269940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.320919</td>\n",
       "      <td>27.492573</td>\n",
       "      <td>27.863260</td>\n",
       "      <td>27.305971</td>\n",
       "      <td>26.619366</td>\n",
       "      <td>26.409615</td>\n",
       "      <td>26.616655</td>\n",
       "      <td>25.321264</td>\n",
       "      <td>27.016960</td>\n",
       "      <td>27.535034</td>\n",
       "      <td>...</td>\n",
       "      <td>25.952717</td>\n",
       "      <td>26.879803</td>\n",
       "      <td>25.636047</td>\n",
       "      <td>26.181154</td>\n",
       "      <td>25.495443</td>\n",
       "      <td>27.070890</td>\n",
       "      <td>25.669330</td>\n",
       "      <td>24.846035</td>\n",
       "      <td>25.210688</td>\n",
       "      <td>22.389183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>28.779148</td>\n",
       "      <td>28.451363</td>\n",
       "      <td>28.809536</td>\n",
       "      <td>28.565220</td>\n",
       "      <td>27.751923</td>\n",
       "      <td>27.028337</td>\n",
       "      <td>27.844486</td>\n",
       "      <td>27.561398</td>\n",
       "      <td>28.859830</td>\n",
       "      <td>29.255660</td>\n",
       "      <td>...</td>\n",
       "      <td>30.935585</td>\n",
       "      <td>31.069098</td>\n",
       "      <td>29.764563</td>\n",
       "      <td>31.193352</td>\n",
       "      <td>30.725512</td>\n",
       "      <td>31.252403</td>\n",
       "      <td>27.059568</td>\n",
       "      <td>28.342500</td>\n",
       "      <td>27.202517</td>\n",
       "      <td>30.654710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>27.000145</td>\n",
       "      <td>27.031580</td>\n",
       "      <td>28.154526</td>\n",
       "      <td>28.894787</td>\n",
       "      <td>27.790730</td>\n",
       "      <td>28.620840</td>\n",
       "      <td>27.898886</td>\n",
       "      <td>26.466496</td>\n",
       "      <td>28.976814</td>\n",
       "      <td>29.069150</td>\n",
       "      <td>...</td>\n",
       "      <td>29.697126</td>\n",
       "      <td>30.061451</td>\n",
       "      <td>28.783115</td>\n",
       "      <td>29.920883</td>\n",
       "      <td>29.306305</td>\n",
       "      <td>30.477110</td>\n",
       "      <td>26.427086</td>\n",
       "      <td>27.289360</td>\n",
       "      <td>27.308756</td>\n",
       "      <td>28.204500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>25.223616</td>\n",
       "      <td>26.354345</td>\n",
       "      <td>26.283224</td>\n",
       "      <td>26.307161</td>\n",
       "      <td>26.158798</td>\n",
       "      <td>26.660583</td>\n",
       "      <td>26.854836</td>\n",
       "      <td>24.817406</td>\n",
       "      <td>27.694683</td>\n",
       "      <td>27.669258</td>\n",
       "      <td>...</td>\n",
       "      <td>28.432547</td>\n",
       "      <td>28.803694</td>\n",
       "      <td>27.627964</td>\n",
       "      <td>28.688486</td>\n",
       "      <td>27.999102</td>\n",
       "      <td>28.833914</td>\n",
       "      <td>26.188139</td>\n",
       "      <td>26.043678</td>\n",
       "      <td>25.938444</td>\n",
       "      <td>21.877134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>24.625957</td>\n",
       "      <td>24.648960</td>\n",
       "      <td>25.397041</td>\n",
       "      <td>25.531140</td>\n",
       "      <td>24.522270</td>\n",
       "      <td>24.123915</td>\n",
       "      <td>23.677595</td>\n",
       "      <td>24.341074</td>\n",
       "      <td>24.449500</td>\n",
       "      <td>24.630047</td>\n",
       "      <td>...</td>\n",
       "      <td>21.673666</td>\n",
       "      <td>22.851734</td>\n",
       "      <td>22.015278</td>\n",
       "      <td>22.168465</td>\n",
       "      <td>21.150808</td>\n",
       "      <td>22.589926</td>\n",
       "      <td>22.896797</td>\n",
       "      <td>22.140429</td>\n",
       "      <td>22.697466</td>\n",
       "      <td>24.551931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>25.300568</td>\n",
       "      <td>24.702103</td>\n",
       "      <td>25.530714</td>\n",
       "      <td>25.238935</td>\n",
       "      <td>23.657007</td>\n",
       "      <td>24.287530</td>\n",
       "      <td>23.636210</td>\n",
       "      <td>25.096247</td>\n",
       "      <td>24.160234</td>\n",
       "      <td>23.824865</td>\n",
       "      <td>...</td>\n",
       "      <td>23.316870</td>\n",
       "      <td>23.863968</td>\n",
       "      <td>22.689320</td>\n",
       "      <td>23.516878</td>\n",
       "      <td>22.981924</td>\n",
       "      <td>23.853500</td>\n",
       "      <td>22.527483</td>\n",
       "      <td>21.843655</td>\n",
       "      <td>21.997015</td>\n",
       "      <td>23.563103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5   \\\n",
       "0    24.763248  25.472006  25.895120  25.504951  25.378044  24.939062   \n",
       "1    27.542997  28.268023  28.266886  27.982456  27.620564  27.364193   \n",
       "2    26.609253  26.727201  27.622810  27.220633  26.190790  26.491024   \n",
       "3    25.960245  25.758175  26.150414  25.934990  25.548695  26.108290   \n",
       "4    26.320919  27.492573  27.863260  27.305971  26.619366  26.409615   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "985  28.779148  28.451363  28.809536  28.565220  27.751923  27.028337   \n",
       "986  27.000145  27.031580  28.154526  28.894787  27.790730  28.620840   \n",
       "987  25.223616  26.354345  26.283224  26.307161  26.158798  26.660583   \n",
       "988  24.625957  24.648960  25.397041  25.531140  24.522270  24.123915   \n",
       "989  25.300568  24.702103  25.530714  25.238935  23.657007  24.287530   \n",
       "\n",
       "            6          7          8          9   ...         33         34  \\\n",
       "0    24.189066  24.356873  24.779787  25.207314  ...  23.884264  24.675434   \n",
       "1    28.217050  26.803938  28.180912  28.558092  ...  28.818031  29.468788   \n",
       "2    25.919535  25.269215  26.973705  27.675621  ...  28.405407  28.791490   \n",
       "3    25.814043  25.055452  26.825954  27.122200  ...  27.548962  27.874758   \n",
       "4    26.616655  25.321264  27.016960  27.535034  ...  25.952717  26.879803   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "985  27.844486  27.561398  28.859830  29.255660  ...  30.935585  31.069098   \n",
       "986  27.898886  26.466496  28.976814  29.069150  ...  29.697126  30.061451   \n",
       "987  26.854836  24.817406  27.694683  27.669258  ...  28.432547  28.803694   \n",
       "988  23.677595  24.341074  24.449500  24.630047  ...  21.673666  22.851734   \n",
       "989  23.636210  25.096247  24.160234  23.824865  ...  23.316870  23.863968   \n",
       "\n",
       "            35         36         37         38         39         40  \\\n",
       "0    23.367365  24.083204  23.456833  24.571740  22.773201  22.838780   \n",
       "1    28.275314  29.179426  28.378897  29.565613  26.933538  27.316801   \n",
       "2    27.497458  28.443201  27.942884  28.846746  24.905685  25.685677   \n",
       "3    26.574425  27.681950  27.160301  28.041866  25.015230  25.505830   \n",
       "4    25.636047  26.181154  25.495443  27.070890  25.669330  24.846035   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "985  29.764563  31.193352  30.725512  31.252403  27.059568  28.342500   \n",
       "986  28.783115  29.920883  29.306305  30.477110  26.427086  27.289360   \n",
       "987  27.627964  28.688486  27.999102  28.833914  26.188139  26.043678   \n",
       "988  22.015278  22.168465  21.150808  22.589926  22.896797  22.140429   \n",
       "989  22.689320  23.516878  22.981924  23.853500  22.527483  21.843655   \n",
       "\n",
       "            41         42  \n",
       "0    23.287376  25.940700  \n",
       "1    26.472404  26.259075  \n",
       "2    25.712965  25.727130  \n",
       "3    24.948660  26.269940  \n",
       "4    25.210688  22.389183  \n",
       "..         ...        ...  \n",
       "985  27.202517  30.654710  \n",
       "986  27.308756  28.204500  \n",
       "987  25.938444  21.877134  \n",
       "988  22.697466  24.551931  \n",
       "989  21.997015  23.563103  \n",
       "\n",
       "[990 rows x 43 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan prediksi data testing diurutkan berdasarkan nilai validasi MSE terbaik.\n",
    "best_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21bb8dbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:08:38.980499Z",
     "iopub.status.busy": "2021-11-04T11:08:38.979447Z",
     "iopub.status.idle": "2021-11-04T11:08:38.985915Z",
     "shell.execute_reply": "2021-11-04T11:08:38.986563Z"
    },
    "papermill": {
     "duration": 0.17576,
     "end_time": "2021-11-04T11:08:38.986755",
     "exception": false,
     "start_time": "2021-11-04T11:08:38.810995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nilai MSE pada data validasi:  26.87057023827122\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan nilai MSE terbaik pada data validasi.\n",
    "error = MSE(y_valid, best_valid_preds[0])\n",
    "print('nilai MSE pada data validasi: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c55c82d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:08:39.322461Z",
     "iopub.status.busy": "2021-11-04T11:08:39.321411Z",
     "iopub.status.idle": "2021-11-04T11:08:39.326986Z",
     "shell.execute_reply": "2021-11-04T11:08:39.327573Z"
    },
    "papermill": {
     "duration": 0.173468,
     "end_time": "2021-11-04T11:08:39.327763",
     "exception": false,
     "start_time": "2021-11-04T11:08:39.154295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total execution time: 0:15:44.045241\n"
     ]
    }
   ],
   "source": [
    "# Mencatat waktu berakhirnya keseluruhan program model dan prediksi data.\n",
    "global_end_time = time.time()\n",
    "\n",
    "# Menampilkan waktu eksekusi dari keseluruhan program model dan prediksi data.\n",
    "total_execution_time = datetime.timedelta(seconds = global_end_time - global_start_time)\n",
    "print(\"total execution time: %s\" % (total_execution_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 964.443827,
   "end_time": "2021-11-04T11:08:42.475613",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-04T10:52:38.031786",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
