{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85287c6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:40.792144Z",
     "iopub.status.busy": "2021-11-04T11:15:40.790355Z",
     "iopub.status.idle": "2021-11-04T11:15:48.140908Z",
     "shell.execute_reply": "2021-11-04T11:15:48.141524Z",
     "shell.execute_reply.started": "2021-11-04T10:48:34.207266Z"
    },
    "papermill": {
     "duration": 7.375787,
     "end_time": "2021-11-04T11:15:48.141848",
     "exception": false,
     "start_time": "2021-11-04T11:15:40.766061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Melakukan impor libraries yang diperlukan untuk membangun model dan prediksi data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "333fdb9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:48.180452Z",
     "iopub.status.busy": "2021-11-04T11:15:48.179531Z",
     "iopub.status.idle": "2021-11-04T11:15:48.182856Z",
     "shell.execute_reply": "2021-11-04T11:15:48.183264Z",
     "shell.execute_reply.started": "2021-11-04T04:01:49.258697Z"
    },
    "papermill": {
     "duration": 0.023506,
     "end_time": "2021-11-04T11:15:48.183421",
     "exception": false,
     "start_time": "2021-11-04T11:15:48.159915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mencatat waktu dimulainya keseluruhan program model dan prediksi data.\n",
    "global_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "032e1c70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:48.221073Z",
     "iopub.status.busy": "2021-11-04T11:15:48.220154Z",
     "iopub.status.idle": "2021-11-04T11:15:48.224631Z",
     "shell.execute_reply": "2021-11-04T11:15:48.225199Z",
     "shell.execute_reply.started": "2021-11-04T10:04:54.282612Z"
    },
    "papermill": {
     "duration": 0.025071,
     "end_time": "2021-11-04T11:15:48.225359",
     "exception": false,
     "start_time": "2021-11-04T11:15:48.200288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menetapkan nilai seed untuk reproduksi model.\n",
    "seed = 2021\n",
    "def set_seed(seed = seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = str(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5891ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:48.263029Z",
     "iopub.status.busy": "2021-11-04T11:15:48.262138Z",
     "iopub.status.idle": "2021-11-04T11:15:48.265724Z",
     "shell.execute_reply": "2021-11-04T11:15:48.266255Z",
     "shell.execute_reply.started": "2021-11-04T10:04:57.579289Z"
    },
    "papermill": {
     "duration": 0.024106,
     "end_time": "2021-11-04T11:15:48.266410",
     "exception": false,
     "start_time": "2021-11-04T11:15:48.242304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menentukan indeks fold, kode penamaan program, banyak epoch, dan ukuran batch.\n",
    "fold_index = 4\n",
    "codename = '1_04_01_{}'.format(fold_index)\n",
    "epochs = 128\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb24cdee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:48.303601Z",
     "iopub.status.busy": "2021-11-04T11:15:48.302736Z",
     "iopub.status.idle": "2021-11-04T11:16:40.767957Z",
     "shell.execute_reply": "2021-11-04T11:16:40.766980Z",
     "shell.execute_reply.started": "2021-11-04T10:05:01.137768Z"
    },
    "papermill": {
     "duration": 52.485194,
     "end_time": "2021-11-04T11:16:40.768343",
     "exception": false,
     "start_time": "2021-11-04T11:15:48.283149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyusun data training.\n",
    "df_train = pd.read_csv('../input/bdc-sd2021-train-tabular-data/train_gray.csv')\n",
    "fake_train = pd.DataFrame(np.array(df_train).reshape((2305, 128, 128))[:, :, ::-1].reshape((2305, 128*128)))\n",
    "fake_train.columns = df_train.columns\n",
    "df_train = pd.concat([df_train, fake_train], ignore_index = True)\n",
    "del fake_train\n",
    "\n",
    "# Menyusun data testing.\n",
    "df_test = pd.read_csv('../input/bdc-sd2021-test-tabular-data/test_gray.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d79ed16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:16:40.811683Z",
     "iopub.status.busy": "2021-11-04T11:16:40.811001Z",
     "iopub.status.idle": "2021-11-04T11:16:41.374155Z",
     "shell.execute_reply": "2021-11-04T11:16:41.374624Z",
     "shell.execute_reply.started": "2021-11-04T10:06:09.166332Z"
    },
    "papermill": {
     "duration": 0.586049,
     "end_time": "2021-11-04T11:16:41.374788",
     "exception": false,
     "start_time": "2021-11-04T11:16:40.788739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16374</th>\n",
       "      <th>16375</th>\n",
       "      <th>16376</th>\n",
       "      <th>16377</th>\n",
       "      <th>16378</th>\n",
       "      <th>16379</th>\n",
       "      <th>16380</th>\n",
       "      <th>16381</th>\n",
       "      <th>16382</th>\n",
       "      <th>16383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.183857</td>\n",
       "      <td>0.139013</td>\n",
       "      <td>0.098655</td>\n",
       "      <td>0.116592</td>\n",
       "      <td>0.121076</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.116592</td>\n",
       "      <td>0.094170</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>0.076233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242152</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.121076</td>\n",
       "      <td>0.134529</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.174888</td>\n",
       "      <td>0.152466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.827411</td>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.827411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319797</td>\n",
       "      <td>0.294416</td>\n",
       "      <td>0.253807</td>\n",
       "      <td>0.208122</td>\n",
       "      <td>0.147208</td>\n",
       "      <td>0.116751</td>\n",
       "      <td>0.096447</td>\n",
       "      <td>0.065990</td>\n",
       "      <td>0.055838</td>\n",
       "      <td>0.040609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.559091</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.486364</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.368182</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.154167</td>\n",
       "      <td>0.154167</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.893023</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.804651</td>\n",
       "      <td>0.879070</td>\n",
       "      <td>0.869767</td>\n",
       "      <td>0.637209</td>\n",
       "      <td>0.479070</td>\n",
       "      <td>0.269767</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106977</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.018605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.356828</td>\n",
       "      <td>0.370044</td>\n",
       "      <td>0.396476</td>\n",
       "      <td>0.409692</td>\n",
       "      <td>0.396476</td>\n",
       "      <td>0.422907</td>\n",
       "      <td>0.471366</td>\n",
       "      <td>0.515419</td>\n",
       "      <td>0.480176</td>\n",
       "      <td>0.436123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.039648</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.035242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.306977</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.339535</td>\n",
       "      <td>0.330233</td>\n",
       "      <td>0.320930</td>\n",
       "      <td>0.367442</td>\n",
       "      <td>0.367442</td>\n",
       "      <td>0.316279</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>0.339535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060465</td>\n",
       "      <td>0.074419</td>\n",
       "      <td>0.065116</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.083721</td>\n",
       "      <td>0.065116</td>\n",
       "      <td>0.055814</td>\n",
       "      <td>0.097674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>0.157258</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.137097</td>\n",
       "      <td>0.108871</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.068548</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.060484</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100806</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.044355</td>\n",
       "      <td>0.044355</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.052419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4610 rows × 16384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.183857  0.139013  0.098655  0.116592  0.121076  0.103139  0.116592   \n",
       "1     0.857868  0.857868  0.857868  0.857868  0.857868  0.857868  0.842640   \n",
       "2     0.018182  0.013636  0.013636  0.018182  0.018182  0.018182  0.018182   \n",
       "3     0.162500  0.162500  0.154167  0.154167  0.166667  0.187500  0.216667   \n",
       "4     0.893023  0.860465  0.804651  0.879070  0.869767  0.637209  0.479070   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4605  0.090476  0.076190  0.095238  0.114286  0.090476  0.109524  0.076190   \n",
       "4606  0.356828  0.370044  0.396476  0.409692  0.396476  0.422907  0.471366   \n",
       "4607  0.306977  0.279070  0.339535  0.330233  0.320930  0.367442  0.367442   \n",
       "4608  0.145000  0.240000  0.290000  0.295000  0.230000  0.170000  0.185000   \n",
       "4609  0.157258  0.161290  0.137097  0.108871  0.112903  0.096774  0.068548   \n",
       "\n",
       "             7         8         9  ...     16374     16375     16376  \\\n",
       "0     0.094170  0.089686  0.076233  ...  0.242152  0.089686  0.103139   \n",
       "1     0.827411  0.842640  0.827411  ...  0.319797  0.294416  0.253807   \n",
       "2     0.018182  0.013636  0.018182  ...  0.568182  0.559091  0.536364   \n",
       "3     0.254167  0.233333  0.183333  ...  0.666667  0.675000  0.745833   \n",
       "4     0.269767  0.186047  0.186047  ...  0.106977  0.032558  0.027907   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4605  0.061905  0.052381  0.076190  ...  0.157143  0.114286  0.133333   \n",
       "4606  0.515419  0.480176  0.436123  ...  0.030837  0.035242  0.030837   \n",
       "4607  0.316279  0.283721  0.339535  ...  0.060465  0.074419  0.065116   \n",
       "4608  0.200000  0.200000  0.230000  ...  0.015000  0.015000  0.015000   \n",
       "4609  0.072581  0.060484  0.072581  ...  0.100806  0.064516  0.044355   \n",
       "\n",
       "         16377     16378     16379     16380     16381     16382     16383  \n",
       "0     0.121076  0.134529  0.156951  0.156951  0.156951  0.174888  0.152466  \n",
       "1     0.208122  0.147208  0.116751  0.096447  0.065990  0.055838  0.040609  \n",
       "2     0.518182  0.486364  0.436364  0.368182  0.254545  0.113636  0.045455  \n",
       "3     0.887500  0.908333  0.900000  0.916667  0.945833  0.966667  0.966667  \n",
       "4     0.018605  0.004651  0.000000  0.000000  0.004651  0.009302  0.018605  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4605  0.047619  0.061905  0.061905  0.052381  0.042857  0.042857  0.042857  \n",
       "4606  0.026432  0.022026  0.017621  0.039648  0.026432  0.017621  0.035242  \n",
       "4607  0.051163  0.051163  0.046512  0.083721  0.065116  0.055814  0.097674  \n",
       "4608  0.015000  0.015000  0.015000  0.015000  0.010000  0.010000  0.010000  \n",
       "4609  0.044355  0.040323  0.032258  0.020161  0.012097  0.016129  0.052419  \n",
       "\n",
       "[4610 rows x 16384 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan normalisasi pada data training.\n",
    "scaler = MinMaxScaler(copy = False)\n",
    "scaler.fit_transform(df_train.T)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b080e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:16:41.414536Z",
     "iopub.status.busy": "2021-11-04T11:16:41.413593Z",
     "iopub.status.idle": "2021-11-04T11:16:41.559596Z",
     "shell.execute_reply": "2021-11-04T11:16:41.559099Z",
     "shell.execute_reply.started": "2021-11-04T10:06:14.713247Z"
    },
    "papermill": {
     "duration": 0.166635,
     "end_time": "2021-11-04T11:16:41.559773",
     "exception": false,
     "start_time": "2021-11-04T11:16:41.393138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16374</th>\n",
       "      <th>16375</th>\n",
       "      <th>16376</th>\n",
       "      <th>16377</th>\n",
       "      <th>16378</th>\n",
       "      <th>16379</th>\n",
       "      <th>16380</th>\n",
       "      <th>16381</th>\n",
       "      <th>16382</th>\n",
       "      <th>16383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347619</td>\n",
       "      <td>0.361905</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.257143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417355</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.471074</td>\n",
       "      <td>0.508264</td>\n",
       "      <td>0.475207</td>\n",
       "      <td>0.541322</td>\n",
       "      <td>0.644628</td>\n",
       "      <td>0.611570</td>\n",
       "      <td>0.512397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.531120</td>\n",
       "      <td>0.493776</td>\n",
       "      <td>0.485477</td>\n",
       "      <td>0.427386</td>\n",
       "      <td>0.402490</td>\n",
       "      <td>0.356846</td>\n",
       "      <td>0.340249</td>\n",
       "      <td>0.356846</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.340249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190871</td>\n",
       "      <td>0.112033</td>\n",
       "      <td>0.062241</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.053942</td>\n",
       "      <td>0.045643</td>\n",
       "      <td>0.053942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.763736</td>\n",
       "      <td>0.763736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>0.906593</td>\n",
       "      <td>0.879121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.248677</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.248677</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>0.608466</td>\n",
       "      <td>0.608466</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.566138</td>\n",
       "      <td>0.502646</td>\n",
       "      <td>0.470899</td>\n",
       "      <td>0.449735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.844898</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.963265</td>\n",
       "      <td>0.987755</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.722449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.848980</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.832653</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.820408</td>\n",
       "      <td>0.783673</td>\n",
       "      <td>0.767347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.077236</td>\n",
       "      <td>0.105691</td>\n",
       "      <td>0.117886</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.126016</td>\n",
       "      <td>0.069106</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.052846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186992</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.223577</td>\n",
       "      <td>0.239837</td>\n",
       "      <td>0.260163</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.321138</td>\n",
       "      <td>0.337398</td>\n",
       "      <td>0.357724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.037915</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.109244</td>\n",
       "      <td>0.155462</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.121849</td>\n",
       "      <td>0.113445</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>0.084034</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525210</td>\n",
       "      <td>0.281513</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.037815</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.042017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.156398</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.165877</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.127962</td>\n",
       "      <td>0.109005</td>\n",
       "      <td>0.118483</td>\n",
       "      <td>0.127962</td>\n",
       "      <td>0.123223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.127962</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.080569</td>\n",
       "      <td>0.142180</td>\n",
       "      <td>0.156398</td>\n",
       "      <td>0.132701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 16384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.095238  0.100000  0.100000  0.095238  0.095238  0.100000  0.109524   \n",
       "1    0.061983  0.061983  0.061983  0.061983  0.061983  0.061983  0.061983   \n",
       "2    0.531120  0.493776  0.485477  0.427386  0.402490  0.356846  0.340249   \n",
       "3    0.796703  0.796703  0.791209  0.791209  0.796703  0.818681  0.818681   \n",
       "4    0.222222  0.232804  0.232804  0.248677  0.253968  0.259259  0.248677   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "985  0.828571  0.844898  0.804082  0.824490  0.918367  0.963265  0.987755   \n",
       "986  0.048780  0.065041  0.077236  0.105691  0.117886  0.121951  0.126016   \n",
       "987  0.056872  0.056872  0.061611  0.061611  0.071090  0.056872  0.037915   \n",
       "988  0.109244  0.155462  0.168067  0.121849  0.113445  0.088235  0.079832   \n",
       "989  0.156398  0.146919  0.151659  0.165877  0.151659  0.127962  0.109005   \n",
       "\n",
       "            7         8         9  ...     16374     16375     16376  \\\n",
       "0    0.114286  0.119048  0.104762  ...  0.347619  0.361905  0.314286   \n",
       "1    0.061983  0.066116  0.066116  ...  0.417355  0.322314  0.285124   \n",
       "2    0.356846  0.336100  0.340249  ...  0.190871  0.112033  0.062241   \n",
       "3    0.785714  0.763736  0.763736  ...  0.961538  0.950549  0.950549   \n",
       "4    0.243386  0.243386  0.243386  ...  0.619048  0.613757  0.608466   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "985  0.959184  0.873469  0.722449  ...  0.857143  0.848980  0.828571   \n",
       "986  0.069106  0.060976  0.052846  ...  0.186992  0.207317  0.223577   \n",
       "987  0.023697  0.009479  0.018957  ...  0.900474  0.890995  0.895735   \n",
       "988  0.084034  0.079832  0.067227  ...  0.525210  0.281513  0.050420   \n",
       "989  0.118483  0.127962  0.123223  ...  0.146919  0.151659  0.146919   \n",
       "\n",
       "        16377     16378     16379     16380     16381     16382     16383  \n",
       "0    0.400000  0.419048  0.261905  0.233333  0.300000  0.266667  0.257143  \n",
       "1    0.471074  0.508264  0.475207  0.541322  0.644628  0.611570  0.512397  \n",
       "2    0.058091  0.074689  0.066390  0.058091  0.053942  0.045643  0.053942  \n",
       "3    0.945055  0.939560  0.928571  0.923077  0.917582  0.906593  0.879121  \n",
       "4    0.608466  0.613757  0.592593  0.566138  0.502646  0.470899  0.449735  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "985  0.832653  0.840816  0.840816  0.816327  0.820408  0.783673  0.767347  \n",
       "986  0.239837  0.260163  0.284553  0.304878  0.321138  0.337398  0.357724  \n",
       "987  0.900474  0.895735  0.895735  0.890995  0.890995  0.890995  0.890995  \n",
       "988  0.033613  0.037815  0.033613  0.033613  0.042017  0.042017  0.042017  \n",
       "989  0.127962  0.151659  0.071090  0.080569  0.142180  0.156398  0.132701  \n",
       "\n",
       "[990 rows x 16384 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan normalisasi pada data testing.\n",
    "scaler.fit_transform(df_test.T)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da52c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:16:41.600147Z",
     "iopub.status.busy": "2021-11-04T11:16:41.599205Z",
     "iopub.status.idle": "2021-11-04T11:16:41.631316Z",
     "shell.execute_reply": "2021-11-04T11:16:41.631791Z",
     "shell.execute_reply.started": "2021-11-04T10:06:18.909964Z"
    },
    "papermill": {
     "duration": 0.053909,
     "end_time": "2021-11-04T11:16:41.631976",
     "exception": false,
     "start_time": "2021-11-04T11:16:41.578067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usia</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4610 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      usia  fold\n",
       "0       27     3\n",
       "1       27     3\n",
       "2       27     3\n",
       "3       24     0\n",
       "4       24     0\n",
       "...    ...   ...\n",
       "4605    23     4\n",
       "4606    23     4\n",
       "4607    27     4\n",
       "4608    27     4\n",
       "4609    27     4\n",
       "\n",
       "[4610 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Memunculkan target prediksi.\n",
    "target_0 = pd.read_csv('../input/bdc-sd2021-data-tambahan/train_target_and_fold.csv')[['usia', 'fold']]\n",
    "target_1 = pd.concat([target_0 for iteration in range(2)], ignore_index = True)\n",
    "target_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a59e1e67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:16:41.675052Z",
     "iopub.status.busy": "2021-11-04T11:16:41.674072Z",
     "iopub.status.idle": "2021-11-04T11:16:41.749302Z",
     "shell.execute_reply": "2021-11-04T11:16:41.749730Z",
     "shell.execute_reply.started": "2021-11-04T10:06:23.078369Z"
    },
    "papermill": {
     "duration": 0.098097,
     "end_time": "2021-11-04T11:16:41.749898",
     "exception": false,
     "start_time": "2021-11-04T11:16:41.651801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_le</th>\n",
       "      <th>y_le</th>\n",
       "      <th>x_re</th>\n",
       "      <th>y_re</th>\n",
       "      <th>x_n</th>\n",
       "      <th>y_n</th>\n",
       "      <th>x_ml</th>\n",
       "      <th>y_ml</th>\n",
       "      <th>x_mr</th>\n",
       "      <th>y_mr</th>\n",
       "      <th>...</th>\n",
       "      <th>adj_n_ml</th>\n",
       "      <th>sym_le_mr</th>\n",
       "      <th>adj_le_mr</th>\n",
       "      <th>sym_re_mr</th>\n",
       "      <th>adj_re_mr</th>\n",
       "      <th>sym_n_mr</th>\n",
       "      <th>adj_n_mr</th>\n",
       "      <th>sym_ml_mr</th>\n",
       "      <th>adj_ml_mr</th>\n",
       "      <th>abs_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>0.698052</td>\n",
       "      <td>0.392694</td>\n",
       "      <td>0.405844</td>\n",
       "      <td>0.618721</td>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249515</td>\n",
       "      <td>0.615908</td>\n",
       "      <td>0.693416</td>\n",
       "      <td>0.314818</td>\n",
       "      <td>0.446237</td>\n",
       "      <td>0.339205</td>\n",
       "      <td>0.350364</td>\n",
       "      <td>0.539005</td>\n",
       "      <td>0.539049</td>\n",
       "      <td>0.061566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179724</td>\n",
       "      <td>0.397351</td>\n",
       "      <td>0.589862</td>\n",
       "      <td>0.403974</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.619205</td>\n",
       "      <td>0.202765</td>\n",
       "      <td>0.725166</td>\n",
       "      <td>0.635945</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171500</td>\n",
       "      <td>0.563722</td>\n",
       "      <td>0.648461</td>\n",
       "      <td>0.327759</td>\n",
       "      <td>0.453958</td>\n",
       "      <td>0.362484</td>\n",
       "      <td>0.377599</td>\n",
       "      <td>0.433192</td>\n",
       "      <td>0.433204</td>\n",
       "      <td>0.134023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195946</td>\n",
       "      <td>0.404878</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.404878</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.614634</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.682432</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239078</td>\n",
       "      <td>0.586077</td>\n",
       "      <td>0.664537</td>\n",
       "      <td>0.327457</td>\n",
       "      <td>0.453156</td>\n",
       "      <td>0.325814</td>\n",
       "      <td>0.344595</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.174672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266055</td>\n",
       "      <td>0.373239</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.373239</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.238532</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272772</td>\n",
       "      <td>0.565660</td>\n",
       "      <td>0.629561</td>\n",
       "      <td>0.331113</td>\n",
       "      <td>0.431290</td>\n",
       "      <td>0.323865</td>\n",
       "      <td>0.348745</td>\n",
       "      <td>0.486442</td>\n",
       "      <td>0.486585</td>\n",
       "      <td>0.121842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.244565</td>\n",
       "      <td>0.389764</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.393701</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.578740</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.696850</td>\n",
       "      <td>0.706522</td>\n",
       "      <td>0.712598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254682</td>\n",
       "      <td>0.563583</td>\n",
       "      <td>0.641880</td>\n",
       "      <td>0.319083</td>\n",
       "      <td>0.440352</td>\n",
       "      <td>0.322564</td>\n",
       "      <td>0.346806</td>\n",
       "      <td>0.489384</td>\n",
       "      <td>0.489613</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.362934</td>\n",
       "      <td>0.401146</td>\n",
       "      <td>0.803089</td>\n",
       "      <td>0.383954</td>\n",
       "      <td>0.660232</td>\n",
       "      <td>0.616046</td>\n",
       "      <td>0.389961</td>\n",
       "      <td>0.759312</td>\n",
       "      <td>0.737452</td>\n",
       "      <td>0.753582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327708</td>\n",
       "      <td>0.530242</td>\n",
       "      <td>0.629355</td>\n",
       "      <td>0.364131</td>\n",
       "      <td>0.487068</td>\n",
       "      <td>0.162752</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.347538</td>\n",
       "      <td>0.347576</td>\n",
       "      <td>0.540420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.386256</td>\n",
       "      <td>0.744108</td>\n",
       "      <td>0.398104</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.649289</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.772512</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.779621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274054</td>\n",
       "      <td>0.612584</td>\n",
       "      <td>0.719783</td>\n",
       "      <td>0.387194</td>\n",
       "      <td>0.549482</td>\n",
       "      <td>0.236635</td>\n",
       "      <td>0.267332</td>\n",
       "      <td>0.404103</td>\n",
       "      <td>0.404167</td>\n",
       "      <td>0.552494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.274869</td>\n",
       "      <td>0.400372</td>\n",
       "      <td>0.759162</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>0.523560</td>\n",
       "      <td>0.616387</td>\n",
       "      <td>0.324607</td>\n",
       "      <td>0.780261</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>0.780261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304386</td>\n",
       "      <td>0.562206</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.386895</td>\n",
       "      <td>0.539038</td>\n",
       "      <td>0.230645</td>\n",
       "      <td>0.281800</td>\n",
       "      <td>0.361257</td>\n",
       "      <td>0.361257</td>\n",
       "      <td>0.162489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>0.323887</td>\n",
       "      <td>0.405836</td>\n",
       "      <td>0.801619</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.668016</td>\n",
       "      <td>0.631300</td>\n",
       "      <td>0.425101</td>\n",
       "      <td>0.801061</td>\n",
       "      <td>0.785425</td>\n",
       "      <td>0.814324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370196</td>\n",
       "      <td>0.602490</td>\n",
       "      <td>0.749939</td>\n",
       "      <td>0.395557</td>\n",
       "      <td>0.603456</td>\n",
       "      <td>0.206407</td>\n",
       "      <td>0.284469</td>\n",
       "      <td>0.360568</td>\n",
       "      <td>0.360892</td>\n",
       "      <td>0.456213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>0.357488</td>\n",
       "      <td>0.393750</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>0.384375</td>\n",
       "      <td>0.632850</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>0.314010</td>\n",
       "      <td>0.753125</td>\n",
       "      <td>0.830918</td>\n",
       "      <td>0.753125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405912</td>\n",
       "      <td>0.600094</td>\n",
       "      <td>0.741007</td>\n",
       "      <td>0.362607</td>\n",
       "      <td>0.557652</td>\n",
       "      <td>0.256197</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.378831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4610 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x_le      y_le      x_re      y_re       x_n       y_n      x_ml  \\\n",
       "0     0.204545  0.390411  0.698052  0.392694  0.405844  0.618721  0.194805   \n",
       "1     0.179724  0.397351  0.589862  0.403974  0.290323  0.619205  0.202765   \n",
       "2     0.195946  0.404878  0.662162  0.404878  0.378378  0.614634  0.202703   \n",
       "3     0.266055  0.373239  0.715596  0.373239  0.440367  0.549296  0.238532   \n",
       "4     0.244565  0.389764  0.695652  0.393701  0.413043  0.578740  0.217391   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4605  0.362934  0.401146  0.803089  0.383954  0.660232  0.616046  0.389961   \n",
       "4606  0.232323  0.386256  0.744108  0.398104  0.515152  0.649289  0.313131   \n",
       "4607  0.274869  0.400372  0.759162  0.396648  0.523560  0.616387  0.324607   \n",
       "4608  0.323887  0.405836  0.801619  0.413793  0.668016  0.631300  0.425101   \n",
       "4609  0.357488  0.393750  0.879227  0.384375  0.632850  0.590625  0.314010   \n",
       "\n",
       "          y_ml      x_mr      y_mr  ...  adj_n_ml  sym_le_mr  adj_le_mr  \\\n",
       "0     0.712329  0.733766  0.705479  ...  0.249515   0.615908   0.693416   \n",
       "1     0.725166  0.635945  0.728477  ...  0.171500   0.563722   0.648461   \n",
       "2     0.731707  0.682432  0.731707  ...  0.239078   0.586077   0.664537   \n",
       "3     0.690141  0.724771  0.704225  ...  0.272772   0.565660   0.629561   \n",
       "4     0.696850  0.706522  0.712598  ...  0.254682   0.563583   0.641880   \n",
       "...        ...       ...       ...  ...       ...        ...        ...   \n",
       "4605  0.759312  0.737452  0.753582  ...  0.327708   0.530242   0.629355   \n",
       "4606  0.772512  0.717172  0.779621  ...  0.274054   0.612584   0.719783   \n",
       "4607  0.780261  0.685864  0.780261  ...  0.304386   0.562206   0.678031   \n",
       "4608  0.801061  0.785425  0.814324  ...  0.370196   0.602490   0.749939   \n",
       "4609  0.753125  0.830918  0.753125  ...  0.405912   0.600094   0.741007   \n",
       "\n",
       "      sym_re_mr  adj_re_mr  sym_n_mr  adj_n_mr  sym_ml_mr  adj_ml_mr  \\\n",
       "0      0.314818   0.446237  0.339205  0.350364   0.539005   0.539049   \n",
       "1      0.327759   0.453958  0.362484  0.377599   0.433192   0.433204   \n",
       "2      0.327457   0.453156  0.325814  0.344595   0.479730   0.479730   \n",
       "3      0.331113   0.431290  0.323865  0.348745   0.486442   0.486585   \n",
       "4      0.319083   0.440352  0.322564  0.346806   0.489384   0.489613   \n",
       "...         ...        ...       ...       ...        ...        ...   \n",
       "4605   0.364131   0.487068  0.162752  0.207921   0.347538   0.347576   \n",
       "4606   0.387194   0.549482  0.236635  0.267332   0.404103   0.404167   \n",
       "4607   0.386895   0.539038  0.230645  0.281800   0.361257   0.361257   \n",
       "4608   0.395557   0.603456  0.206407  0.284469   0.360568   0.360892   \n",
       "4609   0.362607   0.557652  0.256197  0.319900   0.516908   0.516908   \n",
       "\n",
       "      abs_angle  \n",
       "0      0.061566  \n",
       "1      0.134023  \n",
       "2      0.174672  \n",
       "3      0.121842  \n",
       "4      0.012195  \n",
       "...         ...  \n",
       "4605   0.540420  \n",
       "4606   0.552494  \n",
       "4607   0.162489  \n",
       "4608   0.456213  \n",
       "4609   0.378831  \n",
       "\n",
       "[4610 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan penambahan data training yang berkaitan dengan posisi relatif fitur pada wajah.\n",
    "df_train_1 = pd.read_csv('../input/bdc-sd2021-data-tambahan/train_facial_relative.csv')\n",
    "fake_train_1 = df_train_1.copy()\n",
    "fake_train_1['x_le'] = 1 - df_train_1['x_re']\n",
    "fake_train_1['x_re'] = 1 - df_train_1['x_le']\n",
    "fake_train_1['x_n'] = 1 - df_train_1['x_n']\n",
    "fake_train_1['x_ml'] = 1 - df_train_1['x_mr']\n",
    "fake_train_1['x_mr'] = 1 - df_train_1['x_ml']\n",
    "fake_train_1[['sym_le_n', 'adj_le_n', 'sym_re_n', 'adj_re_n']] = df_train_1[['sym_re_n', 'adj_re_n', 'sym_le_n', 'adj_le_n']]\n",
    "fake_train_1[['sym_le_ml', 'adj_le_ml', 'sym_re_mr', 'adj_re_mr']] = df_train_1[['sym_re_mr', 'adj_re_mr', 'sym_le_ml', 'adj_le_ml']]\n",
    "fake_train_1[['sym_le_mr', 'adj_le_mr', 'sym_re_ml', 'adj_re_ml']] = df_train_1[['sym_re_ml', 'adj_re_ml', 'sym_le_mr', 'adj_le_mr']]\n",
    "fake_train_1[['sym_n_ml', 'adj_n_ml', 'sym_n_mr', 'adj_n_mr']] = df_train_1[['sym_n_mr', 'adj_n_mr', 'sym_n_ml', 'adj_n_ml']]\n",
    "\n",
    "df_train_1 = pd.concat([df_train_1, fake_train_1], ignore_index = True)\n",
    "del fake_train_1\n",
    "\n",
    "df_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe68ede1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:16:41.792952Z",
     "iopub.status.busy": "2021-11-04T11:16:41.791878Z",
     "iopub.status.idle": "2021-11-04T11:16:41.836601Z",
     "shell.execute_reply": "2021-11-04T11:16:41.837048Z",
     "shell.execute_reply.started": "2021-11-04T10:06:27.057874Z"
    },
    "papermill": {
     "duration": 0.067803,
     "end_time": "2021-11-04T11:16:41.837211",
     "exception": false,
     "start_time": "2021-11-04T11:16:41.769408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_le</th>\n",
       "      <th>y_le</th>\n",
       "      <th>x_re</th>\n",
       "      <th>y_re</th>\n",
       "      <th>x_n</th>\n",
       "      <th>y_n</th>\n",
       "      <th>x_ml</th>\n",
       "      <th>y_ml</th>\n",
       "      <th>x_mr</th>\n",
       "      <th>y_mr</th>\n",
       "      <th>...</th>\n",
       "      <th>adj_n_ml</th>\n",
       "      <th>sym_le_mr</th>\n",
       "      <th>adj_le_mr</th>\n",
       "      <th>sym_re_mr</th>\n",
       "      <th>adj_re_mr</th>\n",
       "      <th>sym_n_mr</th>\n",
       "      <th>adj_n_mr</th>\n",
       "      <th>sym_ml_mr</th>\n",
       "      <th>adj_ml_mr</th>\n",
       "      <th>abs_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.291209</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.521978</td>\n",
       "      <td>0.516432</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.737089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338570</td>\n",
       "      <td>0.596852</td>\n",
       "      <td>0.645365</td>\n",
       "      <td>0.400006</td>\n",
       "      <td>0.467840</td>\n",
       "      <td>0.303782</td>\n",
       "      <td>0.332088</td>\n",
       "      <td>0.434091</td>\n",
       "      <td>0.434101</td>\n",
       "      <td>0.070471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.405128</td>\n",
       "      <td>0.753521</td>\n",
       "      <td>0.394872</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.625641</td>\n",
       "      <td>0.260563</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318229</td>\n",
       "      <td>0.554593</td>\n",
       "      <td>0.623428</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.429635</td>\n",
       "      <td>0.213573</td>\n",
       "      <td>0.227106</td>\n",
       "      <td>0.486159</td>\n",
       "      <td>0.486375</td>\n",
       "      <td>0.029403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214533</td>\n",
       "      <td>0.403023</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>0.397985</td>\n",
       "      <td>0.366782</td>\n",
       "      <td>0.612091</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.727960</td>\n",
       "      <td>0.692042</td>\n",
       "      <td>0.722922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206456</td>\n",
       "      <td>0.574761</td>\n",
       "      <td>0.648943</td>\n",
       "      <td>0.326426</td>\n",
       "      <td>0.447452</td>\n",
       "      <td>0.343624</td>\n",
       "      <td>0.359129</td>\n",
       "      <td>0.456775</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.022553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.365517</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.402062</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>0.597938</td>\n",
       "      <td>0.393103</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346547</td>\n",
       "      <td>0.537095</td>\n",
       "      <td>0.627927</td>\n",
       "      <td>0.356271</td>\n",
       "      <td>0.476312</td>\n",
       "      <td>0.194191</td>\n",
       "      <td>0.240590</td>\n",
       "      <td>0.365844</td>\n",
       "      <td>0.366102</td>\n",
       "      <td>0.064427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.381323</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.369650</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.603113</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.747082</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.735409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279993</td>\n",
       "      <td>0.575064</td>\n",
       "      <td>0.655712</td>\n",
       "      <td>0.366092</td>\n",
       "      <td>0.489833</td>\n",
       "      <td>0.255644</td>\n",
       "      <td>0.281443</td>\n",
       "      <td>0.422036</td>\n",
       "      <td>0.422164</td>\n",
       "      <td>0.044914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.356364</td>\n",
       "      <td>0.398892</td>\n",
       "      <td>0.821818</td>\n",
       "      <td>0.398892</td>\n",
       "      <td>0.650909</td>\n",
       "      <td>0.617729</td>\n",
       "      <td>0.374545</td>\n",
       "      <td>0.739612</td>\n",
       "      <td>0.785455</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319338</td>\n",
       "      <td>0.546195</td>\n",
       "      <td>0.617197</td>\n",
       "      <td>0.339901</td>\n",
       "      <td>0.445124</td>\n",
       "      <td>0.179696</td>\n",
       "      <td>0.206282</td>\n",
       "      <td>0.410918</td>\n",
       "      <td>0.410925</td>\n",
       "      <td>0.124355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.373016</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.563492</td>\n",
       "      <td>0.362637</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369237</td>\n",
       "      <td>0.602016</td>\n",
       "      <td>0.700027</td>\n",
       "      <td>0.381111</td>\n",
       "      <td>0.527587</td>\n",
       "      <td>0.251896</td>\n",
       "      <td>0.311010</td>\n",
       "      <td>0.385352</td>\n",
       "      <td>0.386026</td>\n",
       "      <td>0.047583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328573</td>\n",
       "      <td>0.573337</td>\n",
       "      <td>0.690348</td>\n",
       "      <td>0.364790</td>\n",
       "      <td>0.522544</td>\n",
       "      <td>0.259399</td>\n",
       "      <td>0.308120</td>\n",
       "      <td>0.449389</td>\n",
       "      <td>0.449509</td>\n",
       "      <td>0.031240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.338403</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.338403</td>\n",
       "      <td>0.319048</td>\n",
       "      <td>0.593156</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.779468</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.779468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261948</td>\n",
       "      <td>0.605120</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.444751</td>\n",
       "      <td>0.555329</td>\n",
       "      <td>0.302327</td>\n",
       "      <td>0.333367</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.020199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.280255</td>\n",
       "      <td>0.414596</td>\n",
       "      <td>0.787686</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.556263</td>\n",
       "      <td>0.639752</td>\n",
       "      <td>0.280255</td>\n",
       "      <td>0.729814</td>\n",
       "      <td>0.755839</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302233</td>\n",
       "      <td>0.573150</td>\n",
       "      <td>0.646119</td>\n",
       "      <td>0.323002</td>\n",
       "      <td>0.440643</td>\n",
       "      <td>0.220912</td>\n",
       "      <td>0.237915</td>\n",
       "      <td>0.475607</td>\n",
       "      <td>0.475627</td>\n",
       "      <td>0.145516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_le      y_le      x_re      y_re       x_n       y_n      x_ml  \\\n",
       "0    0.291209  0.333333  0.758242  0.338028  0.521978  0.516432  0.296703   \n",
       "1    0.281690  0.405128  0.753521  0.394872  0.549296  0.625641  0.260563   \n",
       "2    0.214533  0.403023  0.660900  0.397985  0.366782  0.612091  0.235294   \n",
       "3    0.365517  0.391753  0.779310  0.402062  0.648276  0.597938  0.393103   \n",
       "4    0.265625  0.381323  0.734375  0.369650  0.500000  0.603113  0.296875   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "985  0.356364  0.398892  0.821818  0.398892  0.650909  0.617729  0.374545   \n",
       "986  0.274725  0.380952  0.758242  0.373016  0.582418  0.563492  0.362637   \n",
       "987  0.289855  0.373737  0.753623  0.383838  0.521739  0.585859  0.275362   \n",
       "988  0.142857  0.338403  0.614286  0.338403  0.319048  0.593156  0.200000   \n",
       "989  0.280255  0.414596  0.787686  0.413043  0.556263  0.639752  0.280255   \n",
       "\n",
       "         y_ml      x_mr      y_mr  ...  adj_n_ml  sym_le_mr  adj_le_mr  \\\n",
       "0    0.732394  0.730769  0.737089  ...  0.338570   0.596852   0.645365   \n",
       "1    0.723077  0.746479  0.707692  ...  0.318229   0.554593   0.623428   \n",
       "2    0.727960  0.692042  0.722922  ...  0.206456   0.574761   0.648943   \n",
       "3    0.773196  0.758621  0.757732  ...  0.346547   0.537095   0.627927   \n",
       "4    0.747082  0.718750  0.735409  ...  0.279993   0.575064   0.655712   \n",
       "..        ...       ...       ...  ...       ...        ...        ...   \n",
       "985  0.739612  0.785455  0.736842  ...  0.319338   0.546195   0.617197   \n",
       "986  0.777778  0.747253  0.753968  ...  0.369237   0.602016   0.700027   \n",
       "987  0.737374  0.724638  0.747475  ...  0.328573   0.573337   0.690348   \n",
       "988  0.779468  0.557143  0.779468  ...  0.261948   0.605120   0.690476   \n",
       "989  0.729814  0.755839  0.734472  ...  0.302233   0.573150   0.646119   \n",
       "\n",
       "     sym_re_mr  adj_re_mr  sym_n_mr  adj_n_mr  sym_ml_mr  adj_ml_mr  abs_angle  \n",
       "0     0.400006   0.467840  0.303782  0.332088   0.434091   0.434101   0.070471  \n",
       "1     0.312900   0.429635  0.213573  0.227106   0.486159   0.486375   0.029403  \n",
       "2     0.326426   0.447452  0.343624  0.359129   0.456775   0.456800   0.022553  \n",
       "3     0.356271   0.476312  0.194191  0.240590   0.365844   0.366102   0.064427  \n",
       "4     0.366092   0.489833  0.255644  0.281443   0.422036   0.422164   0.044914  \n",
       "..         ...        ...       ...       ...        ...        ...        ...  \n",
       "985   0.339901   0.445124  0.179696  0.206282   0.410918   0.410925   0.124355  \n",
       "986   0.381111   0.527587  0.251896  0.311010   0.385352   0.386026   0.047583  \n",
       "987   0.364790   0.522544  0.259399  0.308120   0.449389   0.449509   0.031240  \n",
       "988   0.444751   0.555329  0.302327  0.333367   0.357143   0.357143   0.020199  \n",
       "989   0.323002   0.440643  0.220912  0.237915   0.475607   0.475627   0.145516  \n",
       "\n",
       "[990 rows x 37 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan penambahan data testing yang berkaitan dengan posisi relatif fitur pada wajah.\n",
    "df_test_1 = pd.read_csv('../input/bdc-sd2021-data-tambahan/test_facial_relative.csv')\n",
    "df_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "405ca4df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:16:41.888484Z",
     "iopub.status.busy": "2021-11-04T11:16:41.887884Z",
     "iopub.status.idle": "2021-11-04T11:17:37.770975Z",
     "shell.execute_reply": "2021-11-04T11:17:37.771788Z",
     "shell.execute_reply.started": "2021-11-04T10:10:05.524524Z"
    },
    "papermill": {
     "duration": 55.914504,
     "end_time": "2021-11-04T11:17:37.772098",
     "exception": false,
     "start_time": "2021-11-04T11:16:41.857594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyusun indeks untuk data training dan melakukan shuffle.\n",
    "train_index = list(target_1[target_1['fold'] != fold_index].index)\n",
    "random.seed(seed)\n",
    "random.shuffle(train_index)\n",
    "\n",
    "# Menyusun indeks untuk data validasi.\n",
    "valid_index = list(target_0[target_0['fold'] == fold_index].index)\n",
    "\n",
    "# Memisahkan data validasi dari data training, serta menginisiasi data testing.\n",
    "X_train = df_train.iloc[train_index]\n",
    "X_valid = df_train.iloc[valid_index]\n",
    "X_test = df_test.copy()\n",
    "\n",
    "X_train_1 = df_train_1.iloc[train_index]\n",
    "X_valid_1 = df_train_1.iloc[valid_index]\n",
    "X_test_1 = df_test_1.copy()\n",
    "\n",
    "# Melakukan reduksi dimensi dengan menggunakan PCA.\n",
    "pca = PCA(0.95)\n",
    "X_train = pd.DataFrame(pca.fit_transform(X_train))\n",
    "X_valid = pd.DataFrame(pca.transform(X_valid))\n",
    "X_test = pd.DataFrame(pca.transform(X_test))\n",
    "\n",
    "pca = PCA(0.95)\n",
    "X_train_1 = pd.DataFrame(pca.fit_transform(X_train_1))\n",
    "X_valid_1 = pd.DataFrame(pca.transform(X_valid_1))\n",
    "X_test_1 = pd.DataFrame(pca.transform(X_test_1))\n",
    "\n",
    "# Menggabungkan informasi pada data training, validasi, dan testing.\n",
    "X_train = pd.concat([X_train, X_train_1], axis = 1, ignore_index = True)\n",
    "X_valid = pd.concat([X_valid, X_valid_1], axis = 1, ignore_index = True)\n",
    "X_test = pd.concat([X_test, X_test_1], axis = 1, ignore_index = True)\n",
    "del X_train_1, X_valid_1, X_test_1\n",
    "\n",
    "# Mengubah ukuran data agar sesuai dengan input yang diharapkan oleh model.\n",
    "X_train = X_train.values.reshape(-1, X_train.shape[1], 1).astype('float64')\n",
    "X_valid = X_valid.values.reshape(-1, X_valid.shape[1], 1).astype('float64')\n",
    "X_test = X_test.values.reshape(-1, X_test.shape[1], 1).astype('float64')\n",
    "\n",
    "# Memisahkan target validasi dari target training.\n",
    "y_train = target_1.iloc[train_index, 0].astype('int64')\n",
    "y_valid = target_0.iloc[valid_index, 0].astype('int64')\n",
    "\n",
    "# Membuang informasi yang sudah tidak diperlukan lagi.\n",
    "del df_train, df_test, df_train_1, df_test_1, pca, target_0, target_1, train_index, valid_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de91d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:17:37.864867Z",
     "iopub.status.busy": "2021-11-04T11:17:37.864129Z",
     "iopub.status.idle": "2021-11-04T11:17:37.870283Z",
     "shell.execute_reply": "2021-11-04T11:17:37.870851Z",
     "shell.execute_reply.started": "2021-11-04T10:34:04.234056Z"
    },
    "papermill": {
     "duration": 0.058888,
     "end_time": "2021-11-04T11:17:37.871010",
     "exception": false,
     "start_time": "2021-11-04T11:17:37.812122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mendefinisikan fungsi untuk mencari parameter terbaik dengan nilai error terkecil.\n",
    "def create_model(trial):\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 5)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-10, 1e-3, log = True)\n",
    "    dropout = trial.suggest_float('dropout', 0.2, 0.5, log = True)\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers-1):\n",
    "        num_hidden = trial.suggest_int('n_units_l{}'.format(i), 32, 256, log = True)\n",
    "        if i:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "            model.add(Dropout(dropout))\n",
    "        else:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(weight_decay),\n",
    "                            input_shape = (X_train.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    num_hidden = trial.suggest_int('n_units_l{}'.format(n_layers-1), 32, 256, log = True)\n",
    "    model.add(Dense(num_hidden,\n",
    "                    activation = 'relu',\n",
    "                    kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "    model.add(Dense(1,\n",
    "                    activation = 'linear',\n",
    "                    kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "    return model\n",
    "\n",
    "def create_optimizer(trial):\n",
    "    kwargs = {}\n",
    "    optimizer_options = ['RMSprop', 'Adam', 'SGD']\n",
    "    optimizer_selected = trial.suggest_categorical('optimizer', optimizer_options)\n",
    "    if optimizer_selected == 'RMSprop':\n",
    "        kwargs['learning_rate'] = trial.suggest_float(\n",
    "            'rmsprop_learning_rate', 1e-5, 1e-1, log=True)\n",
    "        kwargs['decay'] = trial.suggest_float('rmsprop_decay', 0.85, 0.99)\n",
    "        kwargs['momentum'] = trial.suggest_float('rmsprop_momentum', 1e-5, 1e-1, log = True)\n",
    "    elif optimizer_selected == 'Adam':\n",
    "        kwargs['learning_rate'] = trial.suggest_float('adam_learning_rate', 1e-5, 1e-1, log = True)\n",
    "    elif optimizer_selected == 'SGD':\n",
    "        kwargs['learning_rate'] = trial.suggest_float(\n",
    "            'sgd_opt_learning_rate', 1e-5, 1e-1, log=True)\n",
    "        kwargs['momentum'] = trial.suggest_float('sgd_opt_momentum', 1e-5, 1e-1, log = True)\n",
    "    \n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "    return optimizer\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    optimizer = create_optimizer(trial)\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = 'mean_squared_error',\n",
    "                  metrics = ['mse'])\n",
    "    set_seed()\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs = 3,\n",
    "                        validation_data = (X_valid, y_valid),\n",
    "                        verbose = 2,\n",
    "                        steps_per_epoch = X_train.shape[0] // batch_size)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    try:\n",
    "        mse = MSE(y_valid, y_valid_pred)\n",
    "    except ValueError:\n",
    "        mse = 1e+32\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16095587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:17:37.914664Z",
     "iopub.status.busy": "2021-11-04T11:17:37.913421Z",
     "iopub.status.idle": "2021-11-04T11:27:15.859506Z",
     "shell.execute_reply": "2021-11-04T11:27:15.858971Z"
    },
    "papermill": {
     "duration": 577.968853,
     "end_time": "2021-11-04T11:27:15.859745",
     "exception": false,
     "start_time": "2021-11-04T11:17:37.890892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:17:37,917]\u001b[0m A new study created in memory with name: no-name-a699da5d-093c-42c1-b1d9-40097259c2af\u001b[0m\n",
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   KMP_WARNINGS=0\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_ENABLE_TASK_THROTTLING=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=4\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=false\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=1\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "   OMP_NUM_THREADS: value is not defined\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2021-11-04 11:17:37.974726: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-11-04 11:17:38.258101: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 633.0663 - mse: 633.0626 - val_loss: 423.2720 - val_mse: 423.2684\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 120.2883 - mse: 120.2846 - val_loss: 38.1303 - val_mse: 38.1266\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 39.3495 - mse: 39.3459 - val_loss: 36.5853 - val_mse: 36.5817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:17:52,156]\u001b[0m Trial 0 finished with value: 36.581661718924174 and parameters: {'n_layers': 4, 'weight_decay': 1.3601459990500093e-05, 'dropout': 0.22715517141780636, 'n_units_l0': 61, 'n_units_l1': 255, 'n_units_l2': 41, 'n_units_l3': 46, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 2.4410551066709827e-05, 'sgd_opt_momentum': 1.7150829926878746e-05}. Best is trial 0 with value: 36.581661718924174.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 9s - loss: 251.9698 - mse: 251.9687 - val_loss: 38.7188 - val_mse: 38.7177\n",
      "Epoch 2/3\n",
      "57/57 - 8s - loss: 36.3567 - mse: 36.3555 - val_loss: 34.3333 - val_mse: 34.3322\n",
      "Epoch 3/3\n",
      "57/57 - 8s - loss: 33.6728 - mse: 33.6717 - val_loss: 33.7200 - val_mse: 33.7189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:18:18,520]\u001b[0m Trial 1 finished with value: 33.718889093820216 and parameters: {'n_layers': 5, 'weight_decay': 2.069674778352553e-06, 'dropout': 0.2165227444547113, 'n_units_l0': 102, 'n_units_l1': 115, 'n_units_l2': 238, 'n_units_l3': 105, 'n_units_l4': 69, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 6.0309245793449296e-05, 'sgd_opt_momentum': 0.0021618027516387694}. Best is trial 1 with value: 33.718889093820216.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 76.3069 - mse: 76.3067 - val_loss: 32.4126 - val_mse: 32.4124\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 31.0909 - mse: 31.0907 - val_loss: 28.0694 - val_mse: 28.0692\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 27.6167 - mse: 27.6165 - val_loss: 26.3750 - val_mse: 26.3748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:18:25,148]\u001b[0m Trial 2 finished with value: 26.374758439445124 and parameters: {'n_layers': 3, 'weight_decay': 4.2140608469491625e-07, 'dropout': 0.425181023662834, 'n_units_l0': 146, 'n_units_l1': 36, 'n_units_l2': 129, 'optimizer': 'Adam', 'adam_learning_rate': 0.0029509089780652155}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 7s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 3/3\n",
      "57/57 - 6s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:18:43,621]\u001b[0m Trial 3 finished with value: 1e+32 and parameters: {'n_layers': 4, 'weight_decay': 1.280797128821542e-08, 'dropout': 0.4445600696908863, 'n_units_l0': 108, 'n_units_l1': 247, 'n_units_l2': 80, 'n_units_l3': 41, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.006855869932485577, 'sgd_opt_momentum': 0.03652763447965056}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 156.4897 - mse: 156.4890 - val_loss: 34.5119 - val_mse: 34.5111\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 35.3158 - mse: 35.3151 - val_loss: 35.4509 - val_mse: 35.4502\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 32.8426 - mse: 32.8419 - val_loss: 34.4051 - val_mse: 34.4044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:18:53,018]\u001b[0m Trial 4 finished with value: 34.404367085396274 and parameters: {'n_layers': 4, 'weight_decay': 2.869521426120942e-06, 'dropout': 0.2736582989224417, 'n_units_l0': 177, 'n_units_l1': 60, 'n_units_l2': 60, 'n_units_l3': 48, 'optimizer': 'Adam', 'adam_learning_rate': 0.0003587550277569686}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: nan - mse: 419666629454752382976.0000 - val_loss: nan - val_mse: 648533602065186816.0000\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: nan - mse: 211725102960607232.0000 - val_loss: nan - val_mse: 32312136331952128.0000\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: nan - mse: 10548864880738304.0000 - val_loss: nan - val_mse: 1609901784694784.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:19:06,409]\u001b[0m Trial 5 finished with value: 1609901508388816.8 and parameters: {'n_layers': 4, 'weight_decay': 8.671491605192508e-05, 'dropout': 0.2120474687506201, 'n_units_l0': 75, 'n_units_l1': 63, 'n_units_l2': 143, 'n_units_l3': 85, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.012820573397259222, 'sgd_opt_momentum': 0.01219735525440408}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 1s - loss: 97.0365 - mse: 97.0363 - val_loss: 54.1349 - val_mse: 54.1347\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 47.3804 - mse: 47.3802 - val_loss: 44.6320 - val_mse: 44.6317\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 42.8413 - mse: 42.8411 - val_loss: 42.2050 - val_mse: 42.2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:19:09,590]\u001b[0m Trial 6 finished with value: 42.204781424136364 and parameters: {'n_layers': 2, 'weight_decay': 1.4490033299339797e-06, 'dropout': 0.4134236878013778, 'n_units_l0': 56, 'n_units_l1': 69, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.0004666904757351211, 'rmsprop_decay': 0.894925822839254, 'rmsprop_momentum': 0.000308450498248823}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 77616.0156 - mse: 77616.0078 - val_loss: 136.9178 - val_mse: 136.8997\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 149.6192 - mse: 149.6012 - val_loss: 81.4131 - val_mse: 81.3951\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 97.8162 - mse: 97.7982 - val_loss: 63.0253 - val_mse: 63.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:19:20,293]\u001b[0m Trial 7 finished with value: 63.007279737831354 and parameters: {'n_layers': 3, 'weight_decay': 5.713328696681321e-06, 'dropout': 0.3407865362809055, 'n_units_l0': 241, 'n_units_l1': 75, 'n_units_l2': 63, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.019638650422524002, 'rmsprop_decay': 0.9279674621367233, 'rmsprop_momentum': 0.007481765717358807}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 622727.6875 - mse: 622727.6875 - val_loss: 202.0018 - val_mse: 202.0011\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 111.8049 - mse: 111.8041 - val_loss: 475.3471 - val_mse: 475.3464\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 50.5679 - mse: 50.5672 - val_loss: 488.6379 - val_mse: 488.6372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:19:35,501]\u001b[0m Trial 8 finished with value: 488.6372295429754 and parameters: {'n_layers': 5, 'weight_decay': 2.9653117862224153e-07, 'dropout': 0.3197493177048565, 'n_units_l0': 123, 'n_units_l1': 65, 'n_units_l2': 116, 'n_units_l3': 83, 'n_units_l4': 41, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.019054962911205356, 'rmsprop_decay': 0.874518227528278, 'rmsprop_momentum': 8.371297680962848e-05}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 10s - loss: 3528.1794 - mse: 3528.1575 - val_loss: 50.9783 - val_mse: 50.9565\n",
      "Epoch 2/3\n",
      "57/57 - 8s - loss: 47.0429 - mse: 47.0211 - val_loss: 53.0614 - val_mse: 53.0397\n",
      "Epoch 3/3\n",
      "57/57 - 8s - loss: 43.2505 - mse: 43.2287 - val_loss: 54.3623 - val_mse: 54.3406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:02,309]\u001b[0m Trial 9 finished with value: 54.34057723670597 and parameters: {'n_layers': 4, 'weight_decay': 1.0556840099451229e-05, 'dropout': 0.22909938508654398, 'n_units_l0': 72, 'n_units_l1': 170, 'n_units_l2': 172, 'n_units_l3': 167, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.005553572385099785, 'rmsprop_decay': 0.9526963318618572, 'rmsprop_momentum': 3.908613352528237e-05}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 1s - loss: 2651.7964 - mse: 2651.7959 - val_loss: 645.8014 - val_mse: 645.8004\n",
      "Epoch 2/3\n",
      "57/57 - 0s - loss: 593.9340 - mse: 593.9332 - val_loss: 530.5504 - val_mse: 530.5494\n",
      "Epoch 3/3\n",
      "57/57 - 0s - loss: 478.9574 - mse: 478.9565 - val_loss: 419.4459 - val_mse: 419.4449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:04,540]\u001b[0m Trial 10 finished with value: 419.4448749969969 and parameters: {'n_layers': 2, 'weight_decay': 1.5303673965817338e-08, 'dropout': 0.36337622618058174, 'n_units_l0': 37, 'n_units_l1': 38, 'optimizer': 'Adam', 'adam_learning_rate': 0.07687620678695332}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 17s - loss: 1741.5437 - mse: 1730.6243 - val_loss: 708.3187 - val_mse: 695.5170\n",
      "Epoch 2/3\n",
      "57/57 - 15s - loss: 621.5485 - mse: 610.1604 - val_loss: 50.0997 - val_mse: 39.9072\n",
      "Epoch 3/3\n",
      "57/57 - 15s - loss: 51.1550 - mse: 41.7234 - val_loss: 36.7664 - val_mse: 28.0641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:51,946]\u001b[0m Trial 11 finished with value: 28.064075186117652 and parameters: {'n_layers': 5, 'weight_decay': 0.0008338016434700748, 'dropout': 0.4953827096246268, 'n_units_l0': 141, 'n_units_l1': 121, 'n_units_l2': 253, 'n_units_l3': 245, 'n_units_l4': 142, 'optimizer': 'Adam', 'adam_learning_rate': 0.008983185806335612}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 69.0866 - mse: 67.7805 - val_loss: 29.9669 - val_mse: 28.5090\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 30.5986 - mse: 29.3141 - val_loss: 27.5928 - val_mse: 26.4545\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 28.6677 - mse: 27.6209 - val_loss: 27.4053 - val_mse: 26.4304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:59,982]\u001b[0m Trial 12 finished with value: 26.430374796768394 and parameters: {'n_layers': 3, 'weight_decay': 0.000695990869779388, 'dropout': 0.4909028434074908, 'n_units_l0': 158, 'n_units_l1': 35, 'n_units_l2': 249, 'optimizer': 'Adam', 'adam_learning_rate': 0.00755110127673275}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 84.2675 - mse: 84.2675 - val_loss: 35.1400 - val_mse: 35.1400\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 30.7250 - mse: 30.7250 - val_loss: 27.3384 - val_mse: 27.3384\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 27.7823 - mse: 27.7823 - val_loss: 27.6865 - val_mse: 27.6865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:07,211]\u001b[0m Trial 13 finished with value: 27.686546985339973 and parameters: {'n_layers': 3, 'weight_decay': 2.2300489272818375e-10, 'dropout': 0.40489818215472173, 'n_units_l0': 200, 'n_units_l1': 32, 'n_units_l2': 165, 'optimizer': 'Adam', 'adam_learning_rate': 0.002256391950997491}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 576.9658 - mse: 576.7397 - val_loss: 404.4454 - val_mse: 404.2225\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 228.4543 - mse: 228.2314 - val_loss: 85.0826 - val_mse: 84.8588\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 46.5541 - mse: 46.3298 - val_loss: 37.2993 - val_mse: 37.0760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:14,641]\u001b[0m Trial 14 finished with value: 37.075993382273175 and parameters: {'n_layers': 3, 'weight_decay': 0.0008460518118904421, 'dropout': 0.49891172563768604, 'n_units_l0': 155, 'n_units_l1': 44, 'n_units_l2': 101, 'optimizer': 'Adam', 'adam_learning_rate': 3.9698593450778636e-05}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 798.9248 - mse: 798.9248 - val_loss: 685.8885 - val_mse: 685.8885\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 677.7903 - mse: 677.7903 - val_loss: 660.4584 - val_mse: 660.4584\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 652.3948 - mse: 652.3948 - val_loss: 635.3107 - val_mse: 635.3107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:22,038]\u001b[0m Trial 15 finished with value: 635.3107436694863 and parameters: {'n_layers': 2, 'weight_decay': 1.2523296495552792e-10, 'dropout': 0.28322315406943344, 'n_units_l0': 253, 'n_units_l1': 44, 'optimizer': 'Adam', 'adam_learning_rate': 0.009265002534502789}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 114.9969 - mse: 114.9969 - val_loss: 35.8719 - val_mse: 35.8719\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 35.3110 - mse: 35.3109 - val_loss: 32.2432 - val_mse: 32.2432\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 30.9225 - mse: 30.9224 - val_loss: 28.8977 - val_mse: 28.8976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:29,173]\u001b[0m Trial 16 finished with value: 28.897634844047957 and parameters: {'n_layers': 3, 'weight_decay': 7.827150280044339e-08, 'dropout': 0.4453922187570523, 'n_units_l0': 184, 'n_units_l1': 32, 'n_units_l2': 174, 'optimizer': 'Adam', 'adam_learning_rate': 0.0006915371023089415}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 396.0681 - mse: 396.0680 - val_loss: 28.9750 - val_mse: 28.9750\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 30.0115 - mse: 30.0115 - val_loss: 27.5041 - val_mse: 27.5041\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 28.8732 - mse: 28.8732 - val_loss: 27.6855 - val_mse: 27.6855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:36,447]\u001b[0m Trial 17 finished with value: 27.685455142604326 and parameters: {'n_layers': 3, 'weight_decay': 1.2647114680295807e-09, 'dropout': 0.3722776920199142, 'n_units_l0': 126, 'n_units_l1': 51, 'n_units_l2': 125, 'optimizer': 'Adam', 'adam_learning_rate': 0.023137522991638158}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 65.4740 - mse: 65.4502 - val_loss: 35.1333 - val_mse: 35.1063\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 32.6411 - mse: 32.6134 - val_loss: 32.4848 - val_mse: 32.4564\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 29.7336 - mse: 29.7039 - val_loss: 32.8713 - val_mse: 32.8399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:41,719]\u001b[0m Trial 18 finished with value: 32.839933610532434 and parameters: {'n_layers': 2, 'weight_decay': 7.176689341498653e-05, 'dropout': 0.4493640425555687, 'n_units_l0': 89, 'n_units_l1': 92, 'optimizer': 'Adam', 'adam_learning_rate': 0.0020196915085595973}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 271.8172 - mse: 271.7674 - val_loss: 40.3287 - val_mse: 40.2797\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 40.0191 - mse: 39.9715 - val_loss: 37.2018 - val_mse: 37.1554\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 37.4909 - mse: 37.4453 - val_loss: 36.0915 - val_mse: 36.0465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:50,764]\u001b[0m Trial 19 finished with value: 36.04652190349973 and parameters: {'n_layers': 3, 'weight_decay': 0.00010665309719852067, 'dropout': 0.39658396716973743, 'n_units_l0': 146, 'n_units_l1': 49, 'n_units_l2': 203, 'optimizer': 'Adam', 'adam_learning_rate': 8.228683129434993e-05}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 60.7788 - mse: 60.7787 - val_loss: 34.3058 - val_mse: 34.3057\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 31.1681 - mse: 31.1680 - val_loss: 31.7325 - val_mse: 31.7324\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 26.1496 - mse: 26.1495 - val_loss: 27.9846 - val_mse: 27.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:57,374]\u001b[0m Trial 20 finished with value: 27.984441651073162 and parameters: {'n_layers': 2, 'weight_decay': 9.352375626608931e-08, 'dropout': 0.4679109144591078, 'n_units_l0': 210, 'n_units_l1': 38, 'optimizer': 'Adam', 'adam_learning_rate': 0.0046721409164871205}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 13633.0684 - mse: 13633.0674 - val_loss: 44.0804 - val_mse: 44.0802\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 29.8921 - mse: 29.8918 - val_loss: 26.7929 - val_mse: 26.7927\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 28.4866 - mse: 28.4864 - val_loss: 26.5889 - val_mse: 26.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:04,973]\u001b[0m Trial 21 finished with value: 26.588649877896827 and parameters: {'n_layers': 3, 'weight_decay': 1.557530282906504e-09, 'dropout': 0.36546046278136546, 'n_units_l0': 121, 'n_units_l1': 52, 'n_units_l2': 126, 'optimizer': 'Adam', 'adam_learning_rate': 0.05338672411053631}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 120882.6953 - mse: 120882.6953 - val_loss: 31.6508 - val_mse: 31.6501\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 31.7980 - mse: 31.7973 - val_loss: 28.5658 - val_mse: 28.5651\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 31.4077 - mse: 31.4071 - val_loss: 28.7813 - val_mse: 28.7807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:11,487]\u001b[0m Trial 22 finished with value: 28.780681187876112 and parameters: {'n_layers': 3, 'weight_decay': 2.9898984405395263e-09, 'dropout': 0.37138675358403056, 'n_units_l0': 157, 'n_units_l1': 38, 'n_units_l2': 96, 'optimizer': 'Adam', 'adam_learning_rate': 0.08947015920208075}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 241.2900 - mse: 241.2900 - val_loss: 27.5606 - val_mse: 27.5606\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 29.2475 - mse: 29.2474 - val_loss: 28.0363 - val_mse: 28.0363\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 29.5412 - mse: 29.5412 - val_loss: 27.9300 - val_mse: 27.9300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:17,610]\u001b[0m Trial 23 finished with value: 27.93001644485068 and parameters: {'n_layers': 3, 'weight_decay': 1.9071651958728947e-09, 'dropout': 0.4060961192919428, 'n_units_l0': 106, 'n_units_l1': 52, 'n_units_l2': 74, 'optimizer': 'Adam', 'adam_learning_rate': 0.02628636982215726}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 104.7585 - mse: 104.7526 - val_loss: 30.2980 - val_mse: 30.2902\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 29.7921 - mse: 29.7842 - val_loss: 26.4524 - val_mse: 26.4445\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 27.4160 - mse: 27.4081 - val_loss: 28.0287 - val_mse: 28.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:23,744]\u001b[0m Trial 24 finished with value: 28.020800108362987 and parameters: {'n_layers': 3, 'weight_decay': 5.03827677134389e-07, 'dropout': 0.3027471822665216, 'n_units_l0': 132, 'n_units_l1': 32, 'n_units_l2': 143, 'optimizer': 'Adam', 'adam_learning_rate': 0.024618914068465895}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 164.1904 - mse: 164.1904 - val_loss: 38.7381 - val_mse: 38.7381\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 35.9266 - mse: 35.9266 - val_loss: 42.1463 - val_mse: 42.1463\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 33.6409 - mse: 33.6409 - val_loss: 39.2060 - val_mse: 39.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:35,290]\u001b[0m Trial 25 finished with value: 39.2060288422084 and parameters: {'n_layers': 4, 'weight_decay': 1.470122435251432e-08, 'dropout': 0.34275171306050045, 'n_units_l0': 88, 'n_units_l1': 39, 'n_units_l2': 38, 'n_units_l3': 134, 'optimizer': 'Adam', 'adam_learning_rate': 0.0003333092743992524}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 67.8741 - mse: 67.8741 - val_loss: 30.3893 - val_mse: 30.3893\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 30.9548 - mse: 30.9548 - val_loss: 27.0868 - val_mse: 27.0868\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 26.2790 - mse: 26.2790 - val_loss: 26.4395 - val_mse: 26.4395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:44,980]\u001b[0m Trial 26 finished with value: 26.439539842449836 and parameters: {'n_layers': 3, 'weight_decay': 4.857220089692218e-10, 'dropout': 0.4242911742392825, 'n_units_l0': 116, 'n_units_l1': 87, 'n_units_l2': 118, 'optimizer': 'Adam', 'adam_learning_rate': 0.006659120362460368}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 84.7537 - mse: 84.7143 - val_loss: 38.2184 - val_mse: 38.1681\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 34.7380 - mse: 34.6876 - val_loss: 33.6550 - val_mse: 33.6044\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 30.4190 - mse: 30.3681 - val_loss: 32.9440 - val_mse: 32.8924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:52,847]\u001b[0m Trial 27 finished with value: 32.89235415802133 and parameters: {'n_layers': 2, 'weight_decay': 3.152315930407568e-05, 'dropout': 0.4249009765950843, 'n_units_l0': 164, 'n_units_l1': 85, 'optimizer': 'Adam', 'adam_learning_rate': 0.004354018666651356}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 7s - loss: 668.7691 - mse: 668.6030 - val_loss: 657.5712 - val_mse: 657.4050\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 659.4049 - mse: 659.2386 - val_loss: 653.4814 - val_mse: 653.3152\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 656.3730 - mse: 656.2067 - val_loss: 651.0964 - val_mse: 650.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:10,524]\u001b[0m Trial 28 finished with value: 650.9302033204244 and parameters: {'n_layers': 3, 'weight_decay': 0.00033996469375134706, 'dropout': 0.4758491627346887, 'n_units_l0': 34, 'n_units_l1': 158, 'n_units_l2': 216, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 1.010747326723815e-05, 'rmsprop_decay': 0.9677635539876915, 'rmsprop_momentum': 0.09792461029873681}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: nan - mse: 60528424588517925860407532194889728.0000 - val_loss: nan - val_mse: 78607396445831654799310848.0000\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: nan - mse: 4391836569635412860993536.0000 - val_loss: nan - val_mse: 32607492642963456.0000\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: nan - mse: 1821797620121600.0000 - val_loss: nan - val_mse: 13525365.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:26,217]\u001b[0m Trial 29 finished with value: 13525364.65596945 and parameters: {'n_layers': 4, 'weight_decay': 1.307987371528035e-07, 'dropout': 0.43665240435954916, 'n_units_l0': 52, 'n_units_l1': 110, 'n_units_l2': 194, 'n_units_l3': 32, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.08631186468037616, 'sgd_opt_momentum': 2.3566982169933773e-05}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 72.9975 - mse: 72.9975 - val_loss: 35.7940 - val_mse: 35.7940\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 34.0120 - mse: 34.0120 - val_loss: 31.3286 - val_mse: 31.3286\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 31.0612 - mse: 31.0612 - val_loss: 29.1356 - val_mse: 29.1356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:40,517]\u001b[0m Trial 30 finished with value: 29.13559041461362 and parameters: {'n_layers': 2, 'weight_decay': 4.5670912929896083e-10, 'dropout': 0.46993192602228695, 'n_units_l0': 215, 'n_units_l1': 153, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.0003959502675922957, 'sgd_opt_momentum': 0.000272368752504295}. Best is trial 2 with value: 26.374758439445124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 76.0293 - mse: 76.0293 - val_loss: 35.0460 - val_mse: 35.0460\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 28.9482 - mse: 28.9482 - val_loss: 25.7465 - val_mse: 25.7465\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 25.8438 - mse: 25.8438 - val_loss: 26.2318 - val_mse: 26.2318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:48,035]\u001b[0m Trial 31 finished with value: 26.231802294586906 and parameters: {'n_layers': 3, 'weight_decay': 5.669834146823962e-10, 'dropout': 0.39240857882334235, 'n_units_l0': 115, 'n_units_l1': 55, 'n_units_l2': 116, 'optimizer': 'Adam', 'adam_learning_rate': 0.009717723426427008}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 61.1241 - mse: 61.1241 - val_loss: 27.6384 - val_mse: 27.6384\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 27.8255 - mse: 27.8255 - val_loss: 26.6828 - val_mse: 26.6828\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 25.5621 - mse: 25.5621 - val_loss: 26.9436 - val_mse: 26.9436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:59,357]\u001b[0m Trial 32 finished with value: 26.9435505969055 and parameters: {'n_layers': 3, 'weight_decay': 5.581384104066554e-09, 'dropout': 0.38567224680201134, 'n_units_l0': 98, 'n_units_l1': 59, 'n_units_l2': 110, 'optimizer': 'Adam', 'adam_learning_rate': 0.009494338135034364}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 81.3663 - mse: 81.3663 - val_loss: 35.0937 - val_mse: 35.0937\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 31.5977 - mse: 31.5977 - val_loss: 27.9626 - val_mse: 27.9626\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 28.0749 - mse: 28.0749 - val_loss: 27.7383 - val_mse: 27.7383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:24:05,831]\u001b[0m Trial 33 finished with value: 27.738288374064943 and parameters: {'n_layers': 3, 'weight_decay': 4.2671133364188066e-10, 'dropout': 0.42935784141833955, 'n_units_l0': 119, 'n_units_l1': 44, 'n_units_l2': 88, 'optimizer': 'Adam', 'adam_learning_rate': 0.001976749222508456}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 86.3639 - mse: 86.3639 - val_loss: 35.1081 - val_mse: 35.1081\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 31.0266 - mse: 31.0266 - val_loss: 27.3680 - val_mse: 27.3680\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 27.7523 - mse: 27.7523 - val_loss: 26.8864 - val_mse: 26.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:24:14,847]\u001b[0m Trial 34 finished with value: 26.886379402878774 and parameters: {'n_layers': 3, 'weight_decay': 5.187368305744276e-10, 'dropout': 0.4655227914607626, 'n_units_l0': 78, 'n_units_l1': 80, 'n_units_l2': 151, 'optimizer': 'Adam', 'adam_learning_rate': 0.0037160857052506604}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 8s - loss: 172.0108 - mse: 172.0108 - val_loss: 72.6538 - val_mse: 72.6537\n",
      "Epoch 2/3\n",
      "57/57 - 7s - loss: 51.8079 - mse: 51.8079 - val_loss: 33.8209 - val_mse: 33.8209\n",
      "Epoch 3/3\n",
      "57/57 - 7s - loss: 37.6792 - mse: 37.6791 - val_loss: 27.3657 - val_mse: 27.3657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:24:37,795]\u001b[0m Trial 35 finished with value: 27.36565557222244 and parameters: {'n_layers': 4, 'weight_decay': 4.9840095968703475e-08, 'dropout': 0.34589469667628986, 'n_units_l0': 107, 'n_units_l1': 102, 'n_units_l2': 134, 'n_units_l3': 246, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.0007228525825965658, 'sgd_opt_momentum': 0.0003701279620216436}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 83.9886 - mse: 83.9886 - val_loss: 32.5249 - val_mse: 32.5249\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 28.7380 - mse: 28.7380 - val_loss: 27.6827 - val_mse: 27.6827\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 27.4832 - mse: 27.4832 - val_loss: 26.7721 - val_mse: 26.7721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:24:50,509]\u001b[0m Trial 36 finished with value: 26.772104175630833 and parameters: {'n_layers': 4, 'weight_decay': 1.0963450390565562e-10, 'dropout': 0.24836751441050584, 'n_units_l0': 174, 'n_units_l1': 57, 'n_units_l2': 106, 'n_units_l3': 67, 'optimizer': 'Adam', 'adam_learning_rate': 0.010035986792807379}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 615.5801 - mse: 615.5798 - val_loss: 474.7839 - val_mse: 474.7837\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 272.6410 - mse: 272.6407 - val_loss: 90.2864 - val_mse: 90.2861\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 54.9779 - mse: 54.9777 - val_loss: 44.7909 - val_mse: 44.7907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:25:01,507]\u001b[0m Trial 37 finished with value: 44.790662255369945 and parameters: {'n_layers': 3, 'weight_decay': 1.0480435309419643e-06, 'dropout': 0.4200821239188948, 'n_units_l0': 138, 'n_units_l1': 134, 'n_units_l2': 45, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 1.233524185497482e-05, 'sgd_opt_momentum': 0.08448435474832919}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 86.2380 - mse: 86.2380 - val_loss: 35.7732 - val_mse: 35.7732\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 35.5127 - mse: 35.5127 - val_loss: 33.6998 - val_mse: 33.6998\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 30.6593 - mse: 30.6593 - val_loss: 29.6916 - val_mse: 29.6916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:25:09,894]\u001b[0m Trial 38 finished with value: 29.691578778857767 and parameters: {'n_layers': 3, 'weight_decay': 7.98685832184553e-09, 'dropout': 0.3961245879203476, 'n_units_l0': 97, 'n_units_l1': 75, 'n_units_l2': 86, 'optimizer': 'Adam', 'adam_learning_rate': 0.0008633685723583657}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 8s - loss: 562.3768 - mse: 562.3748 - val_loss: 552.8574 - val_mse: 552.8553\n",
      "Epoch 2/3\n",
      "57/57 - 7s - loss: 521.5815 - mse: 521.5795 - val_loss: 536.0745 - val_mse: 536.0724\n",
      "Epoch 3/3\n",
      "57/57 - 7s - loss: 507.0649 - mse: 507.0628 - val_loss: 526.0151 - val_mse: 526.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:25:32,856]\u001b[0m Trial 39 finished with value: 526.0129929115963 and parameters: {'n_layers': 4, 'weight_decay': 3.2209098430817448e-06, 'dropout': 0.32009686895969724, 'n_units_l0': 188, 'n_units_l1': 215, 'n_units_l2': 70, 'n_units_l3': 164, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.00010080925561256527, 'rmsprop_decay': 0.8517654853975509, 'rmsprop_momentum': 0.003245358928063939}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 775.8857 - mse: 775.7927 - val_loss: 672.4548 - val_mse: 672.3309\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 656.4357 - mse: 656.3124 - val_loss: 631.1585 - val_mse: 631.0364\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 615.6754 - mse: 615.5546 - val_loss: 591.2788 - val_mse: 591.1592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:25:36,650]\u001b[0m Trial 40 finished with value: 591.1590987603962 and parameters: {'n_layers': 2, 'weight_decay': 1.9459095315422118e-05, 'dropout': 0.44920755197022133, 'n_units_l0': 115, 'n_units_l1': 36, 'optimizer': 'Adam', 'adam_learning_rate': 0.015305109794922457}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 11634.4033 - mse: 11634.4033 - val_loss: 28.8473 - val_mse: 28.8472\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 29.7825 - mse: 29.7824 - val_loss: 28.8951 - val_mse: 28.8950\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 29.0200 - mse: 29.0199 - val_loss: 27.3405 - val_mse: 27.3404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:25:43,419]\u001b[0m Trial 41 finished with value: 27.340366797276648 and parameters: {'n_layers': 3, 'weight_decay': 1.0917398108152148e-09, 'dropout': 0.35710818807019673, 'n_units_l0': 115, 'n_units_l1': 43, 'n_units_l2': 124, 'optimizer': 'Adam', 'adam_learning_rate': 0.05130313306383856}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 1364.4055 - mse: 1364.4042 - val_loss: 28.3893 - val_mse: 28.3878\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 33.7963 - mse: 33.7948 - val_loss: 37.3394 - val_mse: 37.3379\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 29.7534 - mse: 29.7519 - val_loss: 30.5899 - val_mse: 30.5884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:25:50,408]\u001b[0m Trial 42 finished with value: 30.58835040114824 and parameters: {'n_layers': 3, 'weight_decay': 2.870880067279692e-08, 'dropout': 0.3918283185580805, 'n_units_l0': 128, 'n_units_l1': 55, 'n_units_l2': 120, 'optimizer': 'Adam', 'adam_learning_rate': 0.03475892955953372}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 64.8779 - mse: 64.8779 - val_loss: 33.5641 - val_mse: 33.5641\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 29.6850 - mse: 29.6850 - val_loss: 26.4130 - val_mse: 26.4130\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 26.3061 - mse: 26.3061 - val_loss: 26.5475 - val_mse: 26.5475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:25:57,048]\u001b[0m Trial 43 finished with value: 26.547512028248942 and parameters: {'n_layers': 3, 'weight_decay': 3.780496043247199e-09, 'dropout': 0.3762691463596687, 'n_units_l0': 82, 'n_units_l1': 47, 'n_units_l2': 157, 'optimizer': 'Adam', 'adam_learning_rate': 0.0054113754885735275}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 51.4345 - mse: 51.4345 - val_loss: 26.4616 - val_mse: 26.4616\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 29.6407 - mse: 29.6407 - val_loss: 26.0840 - val_mse: 26.0839\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 25.9938 - mse: 25.9938 - val_loss: 26.4369 - val_mse: 26.4369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:26:07,185]\u001b[0m Trial 44 finished with value: 26.436898949702567 and parameters: {'n_layers': 3, 'weight_decay': 2.055027190890343e-10, 'dropout': 0.3811528811552959, 'n_units_l0': 80, 'n_units_l1': 67, 'n_units_l2': 227, 'optimizer': 'Adam', 'adam_learning_rate': 0.005185795302063984}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 672.3350 - mse: 672.3350 - val_loss: 664.0618 - val_mse: 664.0618\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 665.0843 - mse: 665.0843 - val_loss: 660.9805 - val_mse: 660.9805\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 663.1457 - mse: 663.1457 - val_loss: 659.1763 - val_mse: 659.1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:26:17,622]\u001b[0m Trial 45 finished with value: 659.1763679443379 and parameters: {'n_layers': 3, 'weight_decay': 2.7031170639922136e-10, 'dropout': 0.4148474170408513, 'n_units_l0': 67, 'n_units_l1': 67, 'n_units_l2': 234, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 1.5538685316501728e-05, 'rmsprop_decay': 0.9855114842909731, 'rmsprop_momentum': 1.2186222842948267e-05}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 8s - loss: 74.8785 - mse: 74.8785 - val_loss: 144.2990 - val_mse: 144.2990\n",
      "Epoch 2/3\n",
      "57/57 - 6s - loss: 31.9383 - mse: 31.9383 - val_loss: 69.8528 - val_mse: 69.8528\n",
      "Epoch 3/3\n",
      "57/57 - 7s - loss: 29.3975 - mse: 29.3975 - val_loss: 45.4831 - val_mse: 45.4831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:26:39,270]\u001b[0m Trial 46 finished with value: 45.483063990299144 and parameters: {'n_layers': 5, 'weight_decay': 7.082744441576851e-10, 'dropout': 0.4906658942007749, 'n_units_l0': 59, 'n_units_l1': 93, 'n_units_l2': 188, 'n_units_l3': 64, 'n_units_l4': 251, 'optimizer': 'Adam', 'adam_learning_rate': 0.001436209820033756}. Best is trial 31 with value: 26.231802294586906.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 56.0777 - mse: 56.0773 - val_loss: 29.1317 - val_mse: 29.1313\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 30.2561 - mse: 30.2557 - val_loss: 29.1177 - val_mse: 29.1173\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 27.4156 - mse: 27.4152 - val_loss: 26.1905 - val_mse: 26.1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:26:50,893]\u001b[0m Trial 47 finished with value: 26.190037321726315 and parameters: {'n_layers': 3, 'weight_decay': 2.3968298159249706e-07, 'dropout': 0.438412734336377, 'n_units_l0': 68, 'n_units_l1': 63, 'n_units_l2': 229, 'optimizer': 'Adam', 'adam_learning_rate': 0.003604078166325823}. Best is trial 47 with value: 26.190037321726315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 8s - loss: 51.2022 - mse: 51.2016 - val_loss: 101.0460 - val_mse: 101.0453\n",
      "Epoch 2/3\n",
      "57/57 - 7s - loss: 30.1201 - mse: 30.1194 - val_loss: 35.8865 - val_mse: 35.8858\n",
      "Epoch 3/3\n",
      "57/57 - 7s - loss: 27.5123 - mse: 27.5115 - val_loss: 52.0173 - val_mse: 52.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:27:12,866]\u001b[0m Trial 48 finished with value: 52.01648160647834 and parameters: {'n_layers': 4, 'weight_decay': 2.750433929157063e-07, 'dropout': 0.4618672963769672, 'n_units_l0': 52, 'n_units_l1': 72, 'n_units_l2': 226, 'n_units_l3': 125, 'optimizer': 'Adam', 'adam_learning_rate': 0.0031233875887170205}. Best is trial 47 with value: 26.190037321726315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 1s - loss: 176304246751232.0000 - mse: 7314265.5000 - val_loss: 186158730444800.0000 - val_mse: 27.6764\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 186146298527744.0000 - mse: 28.2218 - val_loss: 186133296185344.0000 - val_mse: 27.7245\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 186120914599936.0000 - mse: 28.1683 - val_loss: 186107895480320.0000 - val_mse: 27.6834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:27:15,853]\u001b[0m Trial 49 finished with value: 27.683396255857236 and parameters: {'n_layers': 2, 'weight_decay': 6.042352274772378e-06, 'dropout': 0.44060323982014427, 'n_units_l0': 41, 'n_units_l1': 62, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.09898465032079191, 'sgd_opt_momentum': 0.0035228822684071318}. Best is trial 47 with value: 26.190037321726315.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Mencari hyperparameters terbaik.\n",
    "try:\n",
    "    study = optuna.create_study(sampler = TPESampler(seed = seed), direction = 'minimize')\n",
    "    study.optimize(objective, n_trials = 50)\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af141600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:27:16.064001Z",
     "iopub.status.busy": "2021-11-04T11:27:16.063293Z",
     "iopub.status.idle": "2021-11-04T11:27:16.068335Z",
     "shell.execute_reply": "2021-11-04T11:27:16.068833Z",
     "shell.execute_reply.started": "2021-11-04T10:25:54.753997Z"
    },
    "papermill": {
     "duration": 0.109675,
     "end_time": "2021-11-04T11:27:16.069004",
     "exception": false,
     "start_time": "2021-11-04T11:27:15.959329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 3,\n",
       " 'weight_decay': 2.3968298159249706e-07,\n",
       " 'dropout': 0.438412734336377,\n",
       " 'n_units_l0': 68,\n",
       " 'n_units_l1': 63,\n",
       " 'n_units_l2': 229,\n",
       " 'optimizer': 'Adam',\n",
       " 'adam_learning_rate': 0.003604078166325823}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan parameter-parameter terbaik.\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf0967b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:27:16.273942Z",
     "iopub.status.busy": "2021-11-04T11:27:16.273243Z",
     "iopub.status.idle": "2021-11-04T11:27:16.284426Z",
     "shell.execute_reply": "2021-11-04T11:27:16.284913Z",
     "shell.execute_reply.started": "2021-11-04T10:26:02.784876Z"
    },
    "papermill": {
     "duration": 0.114916,
     "end_time": "2021-11-04T11:27:16.285096",
     "exception": false,
     "start_time": "2021-11-04T11:27:16.170180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Membangun model.\n",
    "def prepare_model():\n",
    "    model = Sequential(name = 'Sequential')\n",
    "    n_layers = study.best_params['n_layers']\n",
    "    for i in range(n_layers-1):\n",
    "        num_hidden = study.best_params['n_units_l{}'.format(i)]\n",
    "        if i:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                            name = 'Dense_{}'.format(i)))\n",
    "            model.add(Dropout(study.best_params['dropout'],\n",
    "                              name = 'Dropout_{}'.format(i)))\n",
    "        else:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                            input_shape = (X_train.shape[1], 1),\n",
    "                            name = 'Dense_{}'.format(i)))\n",
    "    model.add(Flatten(name = 'Flatten'))\n",
    "    num_hidden = study.best_params['n_units_l{}'.format(n_layers-1)]\n",
    "    model.add(Dense(num_hidden,\n",
    "                    activation = 'relu',\n",
    "                    kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                    name = 'Dense_{}'.format(n_layers-1)))\n",
    "    model.add(Dense(1,\n",
    "                    activation = 'linear',\n",
    "                    kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                    name = 'Final_Dense'))\n",
    "    \n",
    "    # Mendefinisikan optimizer.\n",
    "    kwargs = {}\n",
    "    optimizer_selected = study.best_params['optimizer']\n",
    "    if optimizer_selected == 'RMSprop':\n",
    "        kwargs['learning_rate'] = study.best_params['rmsprop_learning_rate']\n",
    "        kwargs['decay'] = study.best_params['rmsprop_decay']\n",
    "        kwargs['momentum'] = study.best_params['rmsprop_momentum']\n",
    "    elif optimizer_selected == 'Adam':\n",
    "        kwargs['learning_rate'] = study.best_params['adam_learning_rate']\n",
    "    elif optimizer_selected == 'SGD':\n",
    "        kwargs['learning_rate'] = study.best_params['sgd_opt_learning_rate']\n",
    "        kwargs['momentum'] = study.best_params['sgd_opt_momentum']    \n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "    \n",
    "    # Mengkompilasi model.\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = 'mean_squared_error',\n",
    "                  metrics = ['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d297767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:27:16.520907Z",
     "iopub.status.busy": "2021-11-04T11:27:16.518369Z",
     "iopub.status.idle": "2021-11-04T11:27:16.609757Z",
     "shell.execute_reply": "2021-11-04T11:27:16.610258Z",
     "shell.execute_reply.started": "2021-11-04T10:26:07.607163Z"
    },
    "papermill": {
     "duration": 0.205716,
     "end_time": "2021-11-04T11:27:16.610458",
     "exception": false,
     "start_time": "2021-11-04T11:27:16.404742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_0 (Dense)              (None, 268, 68)           136       \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 268, 63)           4347      \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 268, 63)           0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 16884)             0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 229)               3866665   \n",
      "_________________________________________________________________\n",
      "Final_Dense (Dense)          (None, 1)                 230       \n",
      "=================================================================\n",
      "Total params: 3,871,378\n",
      "Trainable params: 3,871,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan ringkasan dari model.\n",
    "model = prepare_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32b322c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:27:16.824238Z",
     "iopub.status.busy": "2021-11-04T11:27:16.823576Z",
     "iopub.status.idle": "2021-11-04T11:27:16.826626Z",
     "shell.execute_reply": "2021-11-04T11:27:16.826096Z",
     "shell.execute_reply.started": "2021-11-04T10:26:14.472587Z"
    },
    "papermill": {
     "duration": 0.111679,
     "end_time": "2021-11-04T11:27:16.826769",
     "exception": false,
     "start_time": "2021-11-04T11:27:16.715090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menetapkan batasan untuk berhenti melanjutkan epoch lebih awal.\n",
    "earlystop = EarlyStopping(patience = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9d4034f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:27:17.030326Z",
     "iopub.status.busy": "2021-11-04T11:27:17.029739Z",
     "iopub.status.idle": "2021-11-04T11:27:17.033837Z",
     "shell.execute_reply": "2021-11-04T11:27:17.034273Z",
     "shell.execute_reply.started": "2021-11-04T10:26:17.623786Z"
    },
    "papermill": {
     "duration": 0.107438,
     "end_time": "2021-11-04T11:27:17.034431",
     "exception": false,
     "start_time": "2021-11-04T11:27:16.926993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menetapkan batasan untuk learning rate.\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_mse', \n",
    "                                            patience = 8,\n",
    "                                            verbose = 1,\n",
    "                                            factor = 0.5,\n",
    "                                            mode = 'min',\n",
    "                                            min_lr = 1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21e44fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:27:17.237539Z",
     "iopub.status.busy": "2021-11-04T11:27:17.236981Z",
     "iopub.status.idle": "2021-11-04T11:27:17.241909Z",
     "shell.execute_reply": "2021-11-04T11:27:17.242416Z",
     "shell.execute_reply.started": "2021-11-04T10:26:20.705731Z"
    },
    "papermill": {
     "duration": 0.108148,
     "end_time": "2021-11-04T11:27:17.242572",
     "exception": false,
     "start_time": "2021-11-04T11:27:17.134424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Membentuk kelas guna menyimpan output prediksi validasi dan testing untuk setiap epoch.\n",
    "class Metrics(Callback):\n",
    "    def __init__(self, valid_data, test_data):\n",
    "        super().__init__()\n",
    "        self.valid_data = valid_data\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_valid_pred = self.model.predict(self.valid_data)\n",
    "        y_test_pred = self.model.predict(self.test_data)\n",
    "        pd.DataFrame(y_valid_pred).to_csv('valid_preds_{}.csv'.format(epoch), index = False)\n",
    "        pd.DataFrame(y_test_pred).to_csv('test_preds_{}.csv'.format(epoch), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4bde104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:27:17.455473Z",
     "iopub.status.busy": "2021-11-04T11:27:17.454820Z",
     "iopub.status.idle": "2021-11-04T11:29:33.302337Z",
     "shell.execute_reply": "2021-11-04T11:29:33.301314Z",
     "shell.execute_reply.started": "2021-11-04T10:26:23.335319Z"
    },
    "papermill": {
     "duration": 135.95997,
     "end_time": "2021-11-04T11:29:33.302500",
     "exception": false,
     "start_time": "2021-11-04T11:27:17.342530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "57/57 - 4s - loss: 56.0777 - mse: 56.0773 - val_loss: 29.1317 - val_mse: 29.1313\n",
      "Epoch 2/128\n",
      "57/57 - 3s - loss: 30.2561 - mse: 30.2557 - val_loss: 29.1177 - val_mse: 29.1173\n",
      "Epoch 3/128\n",
      "57/57 - 3s - loss: 27.4156 - mse: 27.4152 - val_loss: 26.1905 - val_mse: 26.1900\n",
      "Epoch 4/128\n",
      "57/57 - 3s - loss: 25.9821 - mse: 25.9817 - val_loss: 26.5295 - val_mse: 26.5291\n",
      "Epoch 5/128\n",
      "57/57 - 3s - loss: 24.7580 - mse: 24.7575 - val_loss: 27.0642 - val_mse: 27.0638\n",
      "Epoch 6/128\n",
      "57/57 - 3s - loss: 23.9771 - mse: 23.9766 - val_loss: 27.5445 - val_mse: 27.5440\n",
      "Epoch 7/128\n",
      "57/57 - 3s - loss: 25.3398 - mse: 25.3392 - val_loss: 28.7197 - val_mse: 28.7191\n",
      "Epoch 8/128\n",
      "57/57 - 3s - loss: 22.5871 - mse: 22.5865 - val_loss: 27.2680 - val_mse: 27.2674\n",
      "Epoch 9/128\n",
      "57/57 - 3s - loss: 23.0922 - mse: 23.0916 - val_loss: 27.2858 - val_mse: 27.2852\n",
      "Epoch 10/128\n",
      "57/57 - 3s - loss: 22.7935 - mse: 22.7928 - val_loss: 27.9354 - val_mse: 27.9347\n",
      "Epoch 11/128\n",
      "57/57 - 3s - loss: 22.2966 - mse: 22.2958 - val_loss: 27.8745 - val_mse: 27.8737\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0018020390998572111.\n",
      "Epoch 12/128\n",
      "57/57 - 3s - loss: 21.4467 - mse: 21.4459 - val_loss: 28.0542 - val_mse: 28.0534\n",
      "Epoch 13/128\n",
      "57/57 - 3s - loss: 20.7676 - mse: 20.7668 - val_loss: 30.2086 - val_mse: 30.2078\n",
      "Epoch 14/128\n",
      "57/57 - 3s - loss: 19.9276 - mse: 19.9268 - val_loss: 30.0124 - val_mse: 30.0115\n",
      "Epoch 15/128\n",
      "57/57 - 3s - loss: 19.8206 - mse: 19.8197 - val_loss: 28.2251 - val_mse: 28.2241\n",
      "Epoch 16/128\n",
      "57/57 - 3s - loss: 18.7489 - mse: 18.7479 - val_loss: 28.3189 - val_mse: 28.3179\n",
      "Epoch 17/128\n",
      "57/57 - 3s - loss: 17.8873 - mse: 17.8863 - val_loss: 28.9156 - val_mse: 28.9146\n",
      "Epoch 18/128\n",
      "57/57 - 3s - loss: 17.3475 - mse: 17.3465 - val_loss: 29.3324 - val_mse: 29.3313\n",
      "Epoch 19/128\n",
      "57/57 - 3s - loss: 16.1288 - mse: 16.1277 - val_loss: 29.3593 - val_mse: 29.3582\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0009010195499286056.\n",
      "Epoch 20/128\n",
      "57/57 - 3s - loss: 15.1896 - mse: 15.1885 - val_loss: 29.4505 - val_mse: 29.4494\n",
      "Epoch 21/128\n",
      "57/57 - 3s - loss: 14.8323 - mse: 14.8311 - val_loss: 30.0120 - val_mse: 30.0109\n",
      "Epoch 22/128\n",
      "57/57 - 3s - loss: 14.1451 - mse: 14.1439 - val_loss: 29.3408 - val_mse: 29.3396\n",
      "Epoch 23/128\n",
      "57/57 - 3s - loss: 14.1990 - mse: 14.1978 - val_loss: 30.2446 - val_mse: 30.2435\n",
      "Epoch 24/128\n",
      "57/57 - 3s - loss: 13.8866 - mse: 13.8854 - val_loss: 29.3248 - val_mse: 29.3236\n",
      "Epoch 25/128\n",
      "57/57 - 3s - loss: 13.0181 - mse: 13.0169 - val_loss: 29.4554 - val_mse: 29.4542\n",
      "Epoch 26/128\n",
      "57/57 - 3s - loss: 12.5154 - mse: 12.5142 - val_loss: 30.7791 - val_mse: 30.7778\n",
      "Epoch 27/128\n",
      "57/57 - 3s - loss: 12.0537 - mse: 12.0524 - val_loss: 30.1076 - val_mse: 30.1064\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0004505097749643028.\n",
      "Epoch 28/128\n",
      "57/57 - 3s - loss: 11.3318 - mse: 11.3306 - val_loss: 30.2324 - val_mse: 30.2312\n",
      "Epoch 29/128\n",
      "57/57 - 3s - loss: 11.0717 - mse: 11.0704 - val_loss: 30.1806 - val_mse: 30.1793\n",
      "Epoch 30/128\n",
      "57/57 - 3s - loss: 10.7408 - mse: 10.7395 - val_loss: 30.1280 - val_mse: 30.1267\n",
      "Epoch 31/128\n",
      "57/57 - 3s - loss: 10.7206 - mse: 10.7193 - val_loss: 30.1154 - val_mse: 30.1141\n",
      "Epoch 32/128\n",
      "57/57 - 3s - loss: 10.4837 - mse: 10.4824 - val_loss: 30.0114 - val_mse: 30.0102\n",
      "Epoch 33/128\n",
      "57/57 - 3s - loss: 9.9969 - mse: 9.9956 - val_loss: 30.0040 - val_mse: 30.0027\n",
      "Epoch 34/128\n",
      "57/57 - 3s - loss: 9.3637 - mse: 9.3624 - val_loss: 30.4184 - val_mse: 30.4171\n",
      "Epoch 35/128\n",
      "57/57 - 3s - loss: 9.5606 - mse: 9.5593 - val_loss: 31.3904 - val_mse: 31.3891\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0002252548874821514.\n",
      "Epoch 36/128\n",
      "57/57 - 3s - loss: 9.2121 - mse: 9.2108 - val_loss: 30.3547 - val_mse: 30.3534\n",
      "Epoch 37/128\n",
      "57/57 - 3s - loss: 8.8531 - mse: 8.8517 - val_loss: 30.4349 - val_mse: 30.4336\n",
      "Epoch 38/128\n",
      "57/57 - 3s - loss: 8.7432 - mse: 8.7418 - val_loss: 30.5731 - val_mse: 30.5718\n",
      "Epoch 39/128\n",
      "57/57 - 3s - loss: 8.6649 - mse: 8.6636 - val_loss: 30.5645 - val_mse: 30.5631\n",
      "Epoch 40/128\n",
      "57/57 - 3s - loss: 8.4683 - mse: 8.4669 - val_loss: 30.2254 - val_mse: 30.2240\n",
      "Epoch 41/128\n",
      "57/57 - 3s - loss: 8.5879 - mse: 8.5866 - val_loss: 30.4063 - val_mse: 30.4050\n",
      "Epoch 42/128\n",
      "57/57 - 3s - loss: 8.2933 - mse: 8.2919 - val_loss: 30.6080 - val_mse: 30.6067\n",
      "Epoch 43/128\n",
      "57/57 - 3s - loss: 8.1438 - mse: 8.1425 - val_loss: 30.6186 - val_mse: 30.6173\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0001126274437410757.\n"
     ]
    }
   ],
   "source": [
    "# Melakukan fitting model.\n",
    "set_seed()\n",
    "model = prepare_model()\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                    verbose = 2,\n",
    "                    steps_per_epoch = X_train.shape[0] // batch_size,\n",
    "                    callbacks = [earlystop,\n",
    "                                 learning_rate_reduction,\n",
    "                                 Metrics(X_valid,\n",
    "                                         X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82545d18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:33.549376Z",
     "iopub.status.busy": "2021-11-04T11:29:33.548484Z",
     "iopub.status.idle": "2021-11-04T11:29:34.775029Z",
     "shell.execute_reply": "2021-11-04T11:29:34.775557Z",
     "shell.execute_reply.started": "2021-11-04T08:32:50.263585Z"
    },
    "papermill": {
     "duration": 1.352117,
     "end_time": "2021-11-04T11:29:34.775768",
     "exception": false,
     "start_time": "2021-11-04T11:29:33.423651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Melakukan visualisasi nilai MSE pada data training dan testing.\n",
    "fig, ax = plt.subplots(1, 1, figsize = (12, 12))\n",
    "ax.plot(history.history['mse'], color='b', label = 'training MSE')\n",
    "ax.plot(history.history['val_mse'], color='r', label = 'validation MSE')\n",
    "ax.set_xticks(np.arange(1, epochs, 1))\n",
    "legend = plt.legend(loc = 'best', shadow = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b1c0beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:35.038037Z",
     "iopub.status.busy": "2021-11-04T11:29:35.037358Z",
     "iopub.status.idle": "2021-11-04T11:29:35.054247Z",
     "shell.execute_reply": "2021-11-04T11:29:35.053778Z",
     "shell.execute_reply.started": "2021-11-04T05:26:23.068789Z"
    },
    "papermill": {
     "duration": 0.15137,
     "end_time": "2021-11-04T11:29:35.054384",
     "exception": false,
     "start_time": "2021-11-04T11:29:34.903014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>27.415617</td>\n",
       "      <td>27.415213</td>\n",
       "      <td>26.190453</td>\n",
       "      <td>26.190039</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>25.982101</td>\n",
       "      <td>25.981680</td>\n",
       "      <td>26.529543</td>\n",
       "      <td>26.529102</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>24.757999</td>\n",
       "      <td>24.757547</td>\n",
       "      <td>27.064230</td>\n",
       "      <td>27.063753</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>22.587107</td>\n",
       "      <td>22.586527</td>\n",
       "      <td>27.267977</td>\n",
       "      <td>27.267372</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>23.092241</td>\n",
       "      <td>23.091618</td>\n",
       "      <td>27.285826</td>\n",
       "      <td>27.285179</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>23.977095</td>\n",
       "      <td>23.976597</td>\n",
       "      <td>27.544479</td>\n",
       "      <td>27.543961</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>22.296566</td>\n",
       "      <td>22.295824</td>\n",
       "      <td>27.874516</td>\n",
       "      <td>27.873734</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>22.793512</td>\n",
       "      <td>22.792831</td>\n",
       "      <td>27.935377</td>\n",
       "      <td>27.934669</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>21.446690</td>\n",
       "      <td>21.445894</td>\n",
       "      <td>28.054220</td>\n",
       "      <td>28.053406</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>19.820576</td>\n",
       "      <td>19.819668</td>\n",
       "      <td>28.225061</td>\n",
       "      <td>28.224129</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>18.748884</td>\n",
       "      <td>18.747936</td>\n",
       "      <td>28.318859</td>\n",
       "      <td>28.317898</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>25.339771</td>\n",
       "      <td>25.339228</td>\n",
       "      <td>28.719700</td>\n",
       "      <td>28.719135</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>17.887270</td>\n",
       "      <td>17.886290</td>\n",
       "      <td>28.915638</td>\n",
       "      <td>28.914635</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>30.256077</td>\n",
       "      <td>30.255688</td>\n",
       "      <td>29.117706</td>\n",
       "      <td>29.117310</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>56.077660</td>\n",
       "      <td>56.077343</td>\n",
       "      <td>29.131687</td>\n",
       "      <td>29.131308</td>\n",
       "      <td>0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>13.886600</td>\n",
       "      <td>13.885419</td>\n",
       "      <td>29.324810</td>\n",
       "      <td>29.323614</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>17.347523</td>\n",
       "      <td>17.346497</td>\n",
       "      <td>29.332354</td>\n",
       "      <td>29.331297</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21</td>\n",
       "      <td>14.145051</td>\n",
       "      <td>14.143908</td>\n",
       "      <td>29.340797</td>\n",
       "      <td>29.339645</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>16.128798</td>\n",
       "      <td>16.127724</td>\n",
       "      <td>29.359316</td>\n",
       "      <td>29.358219</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>15.189638</td>\n",
       "      <td>15.188535</td>\n",
       "      <td>29.450502</td>\n",
       "      <td>29.449390</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24</td>\n",
       "      <td>13.018140</td>\n",
       "      <td>13.016935</td>\n",
       "      <td>29.455435</td>\n",
       "      <td>29.454218</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32</td>\n",
       "      <td>9.996902</td>\n",
       "      <td>9.995606</td>\n",
       "      <td>30.004044</td>\n",
       "      <td>30.002747</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>31</td>\n",
       "      <td>10.483664</td>\n",
       "      <td>10.482382</td>\n",
       "      <td>30.011446</td>\n",
       "      <td>30.010157</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20</td>\n",
       "      <td>14.832260</td>\n",
       "      <td>14.831139</td>\n",
       "      <td>30.012022</td>\n",
       "      <td>30.010893</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>19.927626</td>\n",
       "      <td>19.926758</td>\n",
       "      <td>30.012407</td>\n",
       "      <td>30.011522</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>12.053679</td>\n",
       "      <td>12.052441</td>\n",
       "      <td>30.107624</td>\n",
       "      <td>30.106371</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>10.720560</td>\n",
       "      <td>10.719283</td>\n",
       "      <td>30.115383</td>\n",
       "      <td>30.114100</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>10.740750</td>\n",
       "      <td>10.739482</td>\n",
       "      <td>30.128002</td>\n",
       "      <td>30.126726</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>11.071703</td>\n",
       "      <td>11.070439</td>\n",
       "      <td>30.180601</td>\n",
       "      <td>30.179335</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12</td>\n",
       "      <td>20.767599</td>\n",
       "      <td>20.766771</td>\n",
       "      <td>30.208635</td>\n",
       "      <td>30.207790</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>39</td>\n",
       "      <td>8.468267</td>\n",
       "      <td>8.466939</td>\n",
       "      <td>30.225370</td>\n",
       "      <td>30.224041</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>27</td>\n",
       "      <td>11.331838</td>\n",
       "      <td>11.330586</td>\n",
       "      <td>30.232447</td>\n",
       "      <td>30.231190</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>22</td>\n",
       "      <td>14.198963</td>\n",
       "      <td>14.197801</td>\n",
       "      <td>30.244627</td>\n",
       "      <td>30.243450</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>35</td>\n",
       "      <td>9.212124</td>\n",
       "      <td>9.210812</td>\n",
       "      <td>30.354740</td>\n",
       "      <td>30.353426</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>40</td>\n",
       "      <td>8.587898</td>\n",
       "      <td>8.586568</td>\n",
       "      <td>30.406284</td>\n",
       "      <td>30.404953</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>33</td>\n",
       "      <td>9.363714</td>\n",
       "      <td>9.362411</td>\n",
       "      <td>30.418446</td>\n",
       "      <td>30.417145</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>8.853054</td>\n",
       "      <td>8.851737</td>\n",
       "      <td>30.434902</td>\n",
       "      <td>30.433586</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>8.664892</td>\n",
       "      <td>8.663568</td>\n",
       "      <td>30.564468</td>\n",
       "      <td>30.563143</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>37</td>\n",
       "      <td>8.743165</td>\n",
       "      <td>8.741844</td>\n",
       "      <td>30.573133</td>\n",
       "      <td>30.571814</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41</td>\n",
       "      <td>8.293255</td>\n",
       "      <td>8.291922</td>\n",
       "      <td>30.608009</td>\n",
       "      <td>30.606674</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>42</td>\n",
       "      <td>8.143844</td>\n",
       "      <td>8.142505</td>\n",
       "      <td>30.618603</td>\n",
       "      <td>30.617262</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>25</td>\n",
       "      <td>12.515408</td>\n",
       "      <td>12.514186</td>\n",
       "      <td>30.779062</td>\n",
       "      <td>30.777836</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>34</td>\n",
       "      <td>9.560642</td>\n",
       "      <td>9.559335</td>\n",
       "      <td>31.390383</td>\n",
       "      <td>31.389072</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       loss        mse   val_loss    val_mse        lr\n",
       "0       2  27.415617  27.415213  26.190453  26.190039  0.003604\n",
       "1       3  25.982101  25.981680  26.529543  26.529102  0.003604\n",
       "2       4  24.757999  24.757547  27.064230  27.063753  0.003604\n",
       "3       7  22.587107  22.586527  27.267977  27.267372  0.003604\n",
       "4       8  23.092241  23.091618  27.285826  27.285179  0.003604\n",
       "5       5  23.977095  23.976597  27.544479  27.543961  0.003604\n",
       "6      10  22.296566  22.295824  27.874516  27.873734  0.003604\n",
       "7       9  22.793512  22.792831  27.935377  27.934669  0.003604\n",
       "8      11  21.446690  21.445894  28.054220  28.053406  0.001802\n",
       "9      14  19.820576  19.819668  28.225061  28.224129  0.001802\n",
       "10     15  18.748884  18.747936  28.318859  28.317898  0.001802\n",
       "11      6  25.339771  25.339228  28.719700  28.719135  0.003604\n",
       "12     16  17.887270  17.886290  28.915638  28.914635  0.001802\n",
       "13      1  30.256077  30.255688  29.117706  29.117310  0.003604\n",
       "14      0  56.077660  56.077343  29.131687  29.131308  0.003604\n",
       "15     23  13.886600  13.885419  29.324810  29.323614  0.000901\n",
       "16     17  17.347523  17.346497  29.332354  29.331297  0.001802\n",
       "17     21  14.145051  14.143908  29.340797  29.339645  0.000901\n",
       "18     18  16.128798  16.127724  29.359316  29.358219  0.001802\n",
       "19     19  15.189638  15.188535  29.450502  29.449390  0.000901\n",
       "20     24  13.018140  13.016935  29.455435  29.454218  0.000901\n",
       "21     32   9.996902   9.995606  30.004044  30.002747  0.000451\n",
       "22     31  10.483664  10.482382  30.011446  30.010157  0.000451\n",
       "23     20  14.832260  14.831139  30.012022  30.010893  0.000901\n",
       "24     13  19.927626  19.926758  30.012407  30.011522  0.001802\n",
       "25     26  12.053679  12.052441  30.107624  30.106371  0.000901\n",
       "26     30  10.720560  10.719283  30.115383  30.114100  0.000451\n",
       "27     29  10.740750  10.739482  30.128002  30.126726  0.000451\n",
       "28     28  11.071703  11.070439  30.180601  30.179335  0.000451\n",
       "29     12  20.767599  20.766771  30.208635  30.207790  0.001802\n",
       "30     39   8.468267   8.466939  30.225370  30.224041  0.000225\n",
       "31     27  11.331838  11.330586  30.232447  30.231190  0.000451\n",
       "32     22  14.198963  14.197801  30.244627  30.243450  0.000901\n",
       "33     35   9.212124   9.210812  30.354740  30.353426  0.000225\n",
       "34     40   8.587898   8.586568  30.406284  30.404953  0.000225\n",
       "35     33   9.363714   9.362411  30.418446  30.417145  0.000451\n",
       "36     36   8.853054   8.851737  30.434902  30.433586  0.000225\n",
       "37     38   8.664892   8.663568  30.564468  30.563143  0.000225\n",
       "38     37   8.743165   8.741844  30.573133  30.571814  0.000225\n",
       "39     41   8.293255   8.291922  30.608009  30.606674  0.000225\n",
       "40     42   8.143844   8.142505  30.618603  30.617262  0.000225\n",
       "41     25  12.515408  12.514186  30.779062  30.777836  0.000901\n",
       "42     34   9.560642   9.559335  31.390383  31.389072  0.000451"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menyusun rekam jejak model berdasarkan nilai MSE pada setiap epoch, diurutkan dari yang terbaik.\n",
    "history_df = pd.DataFrame(history.history).sort_values('val_mse').reset_index()\n",
    "history_df.rename(columns = {'index': 'epoch'}, inplace = True)\n",
    "history_df.to_csv('history_{}.csv'.format(codename), index = False)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d86e916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:35.310951Z",
     "iopub.status.busy": "2021-11-04T11:29:35.310302Z",
     "iopub.status.idle": "2021-11-04T11:29:35.532085Z",
     "shell.execute_reply": "2021-11-04T11:29:35.531495Z"
    },
    "papermill": {
     "duration": 0.353368,
     "end_time": "2021-11-04T11:29:35.532235",
     "exception": false,
     "start_time": "2021-11-04T11:29:35.178867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyimpan nilai prediksi validasi dan testing diurutkan berdasarkan nilai validasi MSE terbaik.\n",
    "best_valid_preds = pd.DataFrame()\n",
    "best_test_preds = pd.DataFrame()\n",
    "\n",
    "for temp_index in list(history_df.iloc[:, 0]):\n",
    "    temp_df_valid = pd.read_csv('./valid_preds_{}.csv'.format(temp_index))\n",
    "    temp_df_test = pd.read_csv('./test_preds_{}.csv'.format(temp_index))\n",
    "    best_valid_preds = pd.concat([best_valid_preds, temp_df_valid], axis = 1, ignore_index = True)\n",
    "    best_test_preds = pd.concat([best_test_preds, temp_df_test], axis = 1, ignore_index = True)\n",
    "\n",
    "best_valid_preds.to_csv('valid_preds_{}.csv'.format(codename), index = False)\n",
    "best_test_preds.to_csv('test_preds_{}.csv'.format(codename), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17cad7aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:35.782825Z",
     "iopub.status.busy": "2021-11-04T11:29:35.781896Z",
     "iopub.status.idle": "2021-11-04T11:29:35.788891Z",
     "shell.execute_reply": "2021-11-04T11:29:35.789400Z"
    },
    "papermill": {
     "duration": 0.134209,
     "end_time": "2021-11-04T11:29:35.789563",
     "exception": false,
     "start_time": "2021-11-04T11:29:35.655354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Membuang file yang sudah tidak diperlukan.\n",
    "for temp_index in list(history_df.iloc[:, 0]):\n",
    "    os.remove('./valid_preds_{}.csv'.format(temp_index))\n",
    "    os.remove('./test_preds_{}.csv'.format(temp_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a42b133a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:36.042431Z",
     "iopub.status.busy": "2021-11-04T11:29:36.041530Z",
     "iopub.status.idle": "2021-11-04T11:29:36.070872Z",
     "shell.execute_reply": "2021-11-04T11:29:36.071328Z"
    },
    "papermill": {
     "duration": 0.158478,
     "end_time": "2021-11-04T11:29:36.071489",
     "exception": false,
     "start_time": "2021-11-04T11:29:35.913011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.066225</td>\n",
       "      <td>24.918793</td>\n",
       "      <td>24.316340</td>\n",
       "      <td>26.541680</td>\n",
       "      <td>25.574040</td>\n",
       "      <td>25.075190</td>\n",
       "      <td>23.924046</td>\n",
       "      <td>26.557503</td>\n",
       "      <td>24.864698</td>\n",
       "      <td>24.640543</td>\n",
       "      <td>...</td>\n",
       "      <td>23.568680</td>\n",
       "      <td>23.337934</td>\n",
       "      <td>23.548744</td>\n",
       "      <td>23.649218</td>\n",
       "      <td>23.314445</td>\n",
       "      <td>23.423716</td>\n",
       "      <td>23.656054</td>\n",
       "      <td>23.511005</td>\n",
       "      <td>23.036709</td>\n",
       "      <td>22.930708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.881943</td>\n",
       "      <td>26.665360</td>\n",
       "      <td>25.750557</td>\n",
       "      <td>26.472118</td>\n",
       "      <td>26.369308</td>\n",
       "      <td>25.991564</td>\n",
       "      <td>25.780123</td>\n",
       "      <td>27.836160</td>\n",
       "      <td>26.212800</td>\n",
       "      <td>26.600239</td>\n",
       "      <td>...</td>\n",
       "      <td>25.780460</td>\n",
       "      <td>25.825796</td>\n",
       "      <td>26.055346</td>\n",
       "      <td>25.845636</td>\n",
       "      <td>25.655659</td>\n",
       "      <td>25.927940</td>\n",
       "      <td>26.169203</td>\n",
       "      <td>26.132792</td>\n",
       "      <td>25.120922</td>\n",
       "      <td>25.097548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.056345</td>\n",
       "      <td>24.926455</td>\n",
       "      <td>23.905330</td>\n",
       "      <td>24.790838</td>\n",
       "      <td>24.126595</td>\n",
       "      <td>24.582527</td>\n",
       "      <td>23.931602</td>\n",
       "      <td>24.978870</td>\n",
       "      <td>23.573774</td>\n",
       "      <td>23.693243</td>\n",
       "      <td>...</td>\n",
       "      <td>22.059622</td>\n",
       "      <td>21.983814</td>\n",
       "      <td>22.188707</td>\n",
       "      <td>22.069965</td>\n",
       "      <td>21.777473</td>\n",
       "      <td>21.888786</td>\n",
       "      <td>22.052097</td>\n",
       "      <td>21.765615</td>\n",
       "      <td>22.208870</td>\n",
       "      <td>21.352875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.836480</td>\n",
       "      <td>24.391039</td>\n",
       "      <td>23.183790</td>\n",
       "      <td>23.227370</td>\n",
       "      <td>23.517310</td>\n",
       "      <td>23.332947</td>\n",
       "      <td>22.562720</td>\n",
       "      <td>24.591143</td>\n",
       "      <td>22.738777</td>\n",
       "      <td>22.753010</td>\n",
       "      <td>...</td>\n",
       "      <td>22.710230</td>\n",
       "      <td>22.780144</td>\n",
       "      <td>23.326603</td>\n",
       "      <td>22.764593</td>\n",
       "      <td>23.073020</td>\n",
       "      <td>23.046236</td>\n",
       "      <td>23.644520</td>\n",
       "      <td>23.424433</td>\n",
       "      <td>21.753176</td>\n",
       "      <td>21.886787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.183617</td>\n",
       "      <td>27.146978</td>\n",
       "      <td>27.285295</td>\n",
       "      <td>27.628487</td>\n",
       "      <td>26.974306</td>\n",
       "      <td>26.878757</td>\n",
       "      <td>27.605259</td>\n",
       "      <td>29.074558</td>\n",
       "      <td>27.155638</td>\n",
       "      <td>28.075613</td>\n",
       "      <td>...</td>\n",
       "      <td>29.312082</td>\n",
       "      <td>29.787947</td>\n",
       "      <td>29.407133</td>\n",
       "      <td>29.234713</td>\n",
       "      <td>29.308916</td>\n",
       "      <td>29.363993</td>\n",
       "      <td>29.520390</td>\n",
       "      <td>29.517887</td>\n",
       "      <td>27.586807</td>\n",
       "      <td>28.661404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>23.361141</td>\n",
       "      <td>22.823730</td>\n",
       "      <td>22.372240</td>\n",
       "      <td>23.112087</td>\n",
       "      <td>23.381025</td>\n",
       "      <td>22.684406</td>\n",
       "      <td>23.735237</td>\n",
       "      <td>24.199877</td>\n",
       "      <td>23.201963</td>\n",
       "      <td>23.607325</td>\n",
       "      <td>...</td>\n",
       "      <td>24.320124</td>\n",
       "      <td>24.242195</td>\n",
       "      <td>24.833967</td>\n",
       "      <td>23.820210</td>\n",
       "      <td>23.825478</td>\n",
       "      <td>24.112854</td>\n",
       "      <td>24.487116</td>\n",
       "      <td>24.283459</td>\n",
       "      <td>23.469797</td>\n",
       "      <td>23.362719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>23.648000</td>\n",
       "      <td>23.087670</td>\n",
       "      <td>21.871044</td>\n",
       "      <td>22.055040</td>\n",
       "      <td>22.456224</td>\n",
       "      <td>21.989058</td>\n",
       "      <td>21.904959</td>\n",
       "      <td>23.346016</td>\n",
       "      <td>21.274925</td>\n",
       "      <td>22.205040</td>\n",
       "      <td>...</td>\n",
       "      <td>22.692612</td>\n",
       "      <td>22.495106</td>\n",
       "      <td>23.198948</td>\n",
       "      <td>22.692577</td>\n",
       "      <td>22.540768</td>\n",
       "      <td>22.732187</td>\n",
       "      <td>22.725708</td>\n",
       "      <td>22.616137</td>\n",
       "      <td>22.774097</td>\n",
       "      <td>22.116735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>24.877169</td>\n",
       "      <td>24.423199</td>\n",
       "      <td>24.054700</td>\n",
       "      <td>24.417046</td>\n",
       "      <td>24.226744</td>\n",
       "      <td>23.553774</td>\n",
       "      <td>24.821772</td>\n",
       "      <td>25.695887</td>\n",
       "      <td>23.814367</td>\n",
       "      <td>23.781538</td>\n",
       "      <td>...</td>\n",
       "      <td>23.460363</td>\n",
       "      <td>23.470697</td>\n",
       "      <td>23.777317</td>\n",
       "      <td>23.092993</td>\n",
       "      <td>23.429264</td>\n",
       "      <td>23.532207</td>\n",
       "      <td>23.824396</td>\n",
       "      <td>23.779310</td>\n",
       "      <td>22.911709</td>\n",
       "      <td>22.781553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>25.818043</td>\n",
       "      <td>25.148209</td>\n",
       "      <td>24.498966</td>\n",
       "      <td>24.027033</td>\n",
       "      <td>23.525045</td>\n",
       "      <td>23.638090</td>\n",
       "      <td>23.271383</td>\n",
       "      <td>24.729195</td>\n",
       "      <td>22.853596</td>\n",
       "      <td>23.383774</td>\n",
       "      <td>...</td>\n",
       "      <td>23.409990</td>\n",
       "      <td>23.547293</td>\n",
       "      <td>23.531696</td>\n",
       "      <td>23.368343</td>\n",
       "      <td>23.310663</td>\n",
       "      <td>23.250082</td>\n",
       "      <td>23.658432</td>\n",
       "      <td>23.828903</td>\n",
       "      <td>22.340921</td>\n",
       "      <td>22.701435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>27.457317</td>\n",
       "      <td>26.359060</td>\n",
       "      <td>26.061808</td>\n",
       "      <td>25.766462</td>\n",
       "      <td>24.545858</td>\n",
       "      <td>24.761282</td>\n",
       "      <td>24.790367</td>\n",
       "      <td>26.334167</td>\n",
       "      <td>24.768726</td>\n",
       "      <td>26.647379</td>\n",
       "      <td>...</td>\n",
       "      <td>25.251886</td>\n",
       "      <td>25.573816</td>\n",
       "      <td>25.668901</td>\n",
       "      <td>25.042099</td>\n",
       "      <td>24.854654</td>\n",
       "      <td>25.006819</td>\n",
       "      <td>25.225883</td>\n",
       "      <td>25.396536</td>\n",
       "      <td>23.849556</td>\n",
       "      <td>24.682411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5   \\\n",
       "0    25.066225  24.918793  24.316340  26.541680  25.574040  25.075190   \n",
       "1    26.881943  26.665360  25.750557  26.472118  26.369308  25.991564   \n",
       "2    25.056345  24.926455  23.905330  24.790838  24.126595  24.582527   \n",
       "3    23.836480  24.391039  23.183790  23.227370  23.517310  23.332947   \n",
       "4    27.183617  27.146978  27.285295  27.628487  26.974306  26.878757   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "456  23.361141  22.823730  22.372240  23.112087  23.381025  22.684406   \n",
       "457  23.648000  23.087670  21.871044  22.055040  22.456224  21.989058   \n",
       "458  24.877169  24.423199  24.054700  24.417046  24.226744  23.553774   \n",
       "459  25.818043  25.148209  24.498966  24.027033  23.525045  23.638090   \n",
       "460  27.457317  26.359060  26.061808  25.766462  24.545858  24.761282   \n",
       "\n",
       "            6          7          8          9   ...         33         34  \\\n",
       "0    23.924046  26.557503  24.864698  24.640543  ...  23.568680  23.337934   \n",
       "1    25.780123  27.836160  26.212800  26.600239  ...  25.780460  25.825796   \n",
       "2    23.931602  24.978870  23.573774  23.693243  ...  22.059622  21.983814   \n",
       "3    22.562720  24.591143  22.738777  22.753010  ...  22.710230  22.780144   \n",
       "4    27.605259  29.074558  27.155638  28.075613  ...  29.312082  29.787947   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "456  23.735237  24.199877  23.201963  23.607325  ...  24.320124  24.242195   \n",
       "457  21.904959  23.346016  21.274925  22.205040  ...  22.692612  22.495106   \n",
       "458  24.821772  25.695887  23.814367  23.781538  ...  23.460363  23.470697   \n",
       "459  23.271383  24.729195  22.853596  23.383774  ...  23.409990  23.547293   \n",
       "460  24.790367  26.334167  24.768726  26.647379  ...  25.251886  25.573816   \n",
       "\n",
       "            35         36         37         38         39         40  \\\n",
       "0    23.548744  23.649218  23.314445  23.423716  23.656054  23.511005   \n",
       "1    26.055346  25.845636  25.655659  25.927940  26.169203  26.132792   \n",
       "2    22.188707  22.069965  21.777473  21.888786  22.052097  21.765615   \n",
       "3    23.326603  22.764593  23.073020  23.046236  23.644520  23.424433   \n",
       "4    29.407133  29.234713  29.308916  29.363993  29.520390  29.517887   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "456  24.833967  23.820210  23.825478  24.112854  24.487116  24.283459   \n",
       "457  23.198948  22.692577  22.540768  22.732187  22.725708  22.616137   \n",
       "458  23.777317  23.092993  23.429264  23.532207  23.824396  23.779310   \n",
       "459  23.531696  23.368343  23.310663  23.250082  23.658432  23.828903   \n",
       "460  25.668901  25.042099  24.854654  25.006819  25.225883  25.396536   \n",
       "\n",
       "            41         42  \n",
       "0    23.036709  22.930708  \n",
       "1    25.120922  25.097548  \n",
       "2    22.208870  21.352875  \n",
       "3    21.753176  21.886787  \n",
       "4    27.586807  28.661404  \n",
       "..         ...        ...  \n",
       "456  23.469797  23.362719  \n",
       "457  22.774097  22.116735  \n",
       "458  22.911709  22.781553  \n",
       "459  22.340921  22.701435  \n",
       "460  23.849556  24.682411  \n",
       "\n",
       "[461 rows x 43 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan prediksi data validasi diurutkan berdasarkan nilai validasi MSE terbaik.\n",
    "best_valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7e81df8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:36.322960Z",
     "iopub.status.busy": "2021-11-04T11:29:36.322045Z",
     "iopub.status.idle": "2021-11-04T11:29:36.351957Z",
     "shell.execute_reply": "2021-11-04T11:29:36.352373Z"
    },
    "papermill": {
     "duration": 0.156906,
     "end_time": "2021-11-04T11:29:36.352538",
     "exception": false,
     "start_time": "2021-11-04T11:29:36.195632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.046722</td>\n",
       "      <td>24.880568</td>\n",
       "      <td>25.408089</td>\n",
       "      <td>25.865208</td>\n",
       "      <td>24.607958</td>\n",
       "      <td>24.684143</td>\n",
       "      <td>23.714714</td>\n",
       "      <td>25.257723</td>\n",
       "      <td>23.909250</td>\n",
       "      <td>24.711859</td>\n",
       "      <td>...</td>\n",
       "      <td>22.942047</td>\n",
       "      <td>22.934944</td>\n",
       "      <td>23.225850</td>\n",
       "      <td>23.000048</td>\n",
       "      <td>22.701733</td>\n",
       "      <td>22.847687</td>\n",
       "      <td>22.956238</td>\n",
       "      <td>22.859430</td>\n",
       "      <td>22.461447</td>\n",
       "      <td>22.391277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.820332</td>\n",
       "      <td>27.329538</td>\n",
       "      <td>26.085688</td>\n",
       "      <td>27.335402</td>\n",
       "      <td>26.900948</td>\n",
       "      <td>26.666023</td>\n",
       "      <td>25.902367</td>\n",
       "      <td>27.918760</td>\n",
       "      <td>26.256042</td>\n",
       "      <td>26.760046</td>\n",
       "      <td>...</td>\n",
       "      <td>25.118620</td>\n",
       "      <td>25.312092</td>\n",
       "      <td>25.259407</td>\n",
       "      <td>24.970633</td>\n",
       "      <td>24.916570</td>\n",
       "      <td>24.894380</td>\n",
       "      <td>25.091064</td>\n",
       "      <td>24.524633</td>\n",
       "      <td>24.313745</td>\n",
       "      <td>24.571362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.404518</td>\n",
       "      <td>25.814974</td>\n",
       "      <td>25.833800</td>\n",
       "      <td>27.672333</td>\n",
       "      <td>27.048986</td>\n",
       "      <td>25.999866</td>\n",
       "      <td>27.334225</td>\n",
       "      <td>28.316988</td>\n",
       "      <td>27.304146</td>\n",
       "      <td>27.695858</td>\n",
       "      <td>...</td>\n",
       "      <td>28.615667</td>\n",
       "      <td>28.501050</td>\n",
       "      <td>28.902798</td>\n",
       "      <td>28.318588</td>\n",
       "      <td>28.313631</td>\n",
       "      <td>28.562454</td>\n",
       "      <td>28.775906</td>\n",
       "      <td>28.705750</td>\n",
       "      <td>26.892412</td>\n",
       "      <td>27.760454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.454271</td>\n",
       "      <td>28.671846</td>\n",
       "      <td>28.129107</td>\n",
       "      <td>29.129759</td>\n",
       "      <td>28.449524</td>\n",
       "      <td>27.970129</td>\n",
       "      <td>28.845520</td>\n",
       "      <td>30.882956</td>\n",
       "      <td>28.860159</td>\n",
       "      <td>30.361692</td>\n",
       "      <td>...</td>\n",
       "      <td>30.767332</td>\n",
       "      <td>31.025780</td>\n",
       "      <td>31.013440</td>\n",
       "      <td>30.674220</td>\n",
       "      <td>30.490833</td>\n",
       "      <td>30.889800</td>\n",
       "      <td>31.415369</td>\n",
       "      <td>30.684217</td>\n",
       "      <td>29.582115</td>\n",
       "      <td>30.068295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.236654</td>\n",
       "      <td>28.729807</td>\n",
       "      <td>28.036520</td>\n",
       "      <td>29.949581</td>\n",
       "      <td>28.493382</td>\n",
       "      <td>28.268976</td>\n",
       "      <td>28.609882</td>\n",
       "      <td>30.476395</td>\n",
       "      <td>29.438246</td>\n",
       "      <td>29.845919</td>\n",
       "      <td>...</td>\n",
       "      <td>28.274614</td>\n",
       "      <td>28.140884</td>\n",
       "      <td>28.709368</td>\n",
       "      <td>28.236652</td>\n",
       "      <td>27.862185</td>\n",
       "      <td>28.190653</td>\n",
       "      <td>27.976366</td>\n",
       "      <td>28.034640</td>\n",
       "      <td>28.116898</td>\n",
       "      <td>27.688896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>29.626627</td>\n",
       "      <td>28.609201</td>\n",
       "      <td>28.914095</td>\n",
       "      <td>30.723640</td>\n",
       "      <td>28.670475</td>\n",
       "      <td>28.303940</td>\n",
       "      <td>28.369800</td>\n",
       "      <td>30.873602</td>\n",
       "      <td>29.388065</td>\n",
       "      <td>29.643938</td>\n",
       "      <td>...</td>\n",
       "      <td>27.550259</td>\n",
       "      <td>27.437439</td>\n",
       "      <td>28.150370</td>\n",
       "      <td>27.327015</td>\n",
       "      <td>26.925766</td>\n",
       "      <td>27.142687</td>\n",
       "      <td>27.417791</td>\n",
       "      <td>27.136831</td>\n",
       "      <td>28.071230</td>\n",
       "      <td>26.890303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>24.851566</td>\n",
       "      <td>23.479578</td>\n",
       "      <td>23.482533</td>\n",
       "      <td>24.440285</td>\n",
       "      <td>24.202217</td>\n",
       "      <td>23.087010</td>\n",
       "      <td>24.248196</td>\n",
       "      <td>25.801336</td>\n",
       "      <td>23.755978</td>\n",
       "      <td>25.189625</td>\n",
       "      <td>...</td>\n",
       "      <td>27.518948</td>\n",
       "      <td>27.606619</td>\n",
       "      <td>27.895765</td>\n",
       "      <td>27.436071</td>\n",
       "      <td>27.278236</td>\n",
       "      <td>27.352667</td>\n",
       "      <td>27.568275</td>\n",
       "      <td>27.698250</td>\n",
       "      <td>25.898380</td>\n",
       "      <td>26.941866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>25.251234</td>\n",
       "      <td>25.030981</td>\n",
       "      <td>24.519314</td>\n",
       "      <td>25.994260</td>\n",
       "      <td>24.886562</td>\n",
       "      <td>25.345526</td>\n",
       "      <td>25.518387</td>\n",
       "      <td>27.142600</td>\n",
       "      <td>25.233513</td>\n",
       "      <td>26.157719</td>\n",
       "      <td>...</td>\n",
       "      <td>26.039730</td>\n",
       "      <td>26.152287</td>\n",
       "      <td>26.196365</td>\n",
       "      <td>25.930500</td>\n",
       "      <td>26.020378</td>\n",
       "      <td>26.066069</td>\n",
       "      <td>26.344800</td>\n",
       "      <td>25.879030</td>\n",
       "      <td>25.319017</td>\n",
       "      <td>25.366710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>25.533180</td>\n",
       "      <td>25.953117</td>\n",
       "      <td>25.060223</td>\n",
       "      <td>26.310404</td>\n",
       "      <td>25.418081</td>\n",
       "      <td>24.844421</td>\n",
       "      <td>23.844840</td>\n",
       "      <td>26.594020</td>\n",
       "      <td>24.706617</td>\n",
       "      <td>24.345528</td>\n",
       "      <td>...</td>\n",
       "      <td>23.685820</td>\n",
       "      <td>23.767231</td>\n",
       "      <td>24.026810</td>\n",
       "      <td>23.770632</td>\n",
       "      <td>23.551998</td>\n",
       "      <td>23.764439</td>\n",
       "      <td>23.723919</td>\n",
       "      <td>23.646612</td>\n",
       "      <td>22.816685</td>\n",
       "      <td>23.086576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>25.107480</td>\n",
       "      <td>24.482363</td>\n",
       "      <td>23.831890</td>\n",
       "      <td>24.592852</td>\n",
       "      <td>24.033813</td>\n",
       "      <td>23.743254</td>\n",
       "      <td>23.807795</td>\n",
       "      <td>25.085640</td>\n",
       "      <td>23.304668</td>\n",
       "      <td>24.040638</td>\n",
       "      <td>...</td>\n",
       "      <td>22.083961</td>\n",
       "      <td>21.636154</td>\n",
       "      <td>22.033613</td>\n",
       "      <td>21.977255</td>\n",
       "      <td>21.714125</td>\n",
       "      <td>21.868393</td>\n",
       "      <td>21.803688</td>\n",
       "      <td>21.836409</td>\n",
       "      <td>21.492880</td>\n",
       "      <td>21.381887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5   \\\n",
       "0    25.046722  24.880568  25.408089  25.865208  24.607958  24.684143   \n",
       "1    26.820332  27.329538  26.085688  27.335402  26.900948  26.666023   \n",
       "2    26.404518  25.814974  25.833800  27.672333  27.048986  25.999866   \n",
       "3    28.454271  28.671846  28.129107  29.129759  28.449524  27.970129   \n",
       "4    28.236654  28.729807  28.036520  29.949581  28.493382  28.268976   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "985  29.626627  28.609201  28.914095  30.723640  28.670475  28.303940   \n",
       "986  24.851566  23.479578  23.482533  24.440285  24.202217  23.087010   \n",
       "987  25.251234  25.030981  24.519314  25.994260  24.886562  25.345526   \n",
       "988  25.533180  25.953117  25.060223  26.310404  25.418081  24.844421   \n",
       "989  25.107480  24.482363  23.831890  24.592852  24.033813  23.743254   \n",
       "\n",
       "            6          7          8          9   ...         33         34  \\\n",
       "0    23.714714  25.257723  23.909250  24.711859  ...  22.942047  22.934944   \n",
       "1    25.902367  27.918760  26.256042  26.760046  ...  25.118620  25.312092   \n",
       "2    27.334225  28.316988  27.304146  27.695858  ...  28.615667  28.501050   \n",
       "3    28.845520  30.882956  28.860159  30.361692  ...  30.767332  31.025780   \n",
       "4    28.609882  30.476395  29.438246  29.845919  ...  28.274614  28.140884   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "985  28.369800  30.873602  29.388065  29.643938  ...  27.550259  27.437439   \n",
       "986  24.248196  25.801336  23.755978  25.189625  ...  27.518948  27.606619   \n",
       "987  25.518387  27.142600  25.233513  26.157719  ...  26.039730  26.152287   \n",
       "988  23.844840  26.594020  24.706617  24.345528  ...  23.685820  23.767231   \n",
       "989  23.807795  25.085640  23.304668  24.040638  ...  22.083961  21.636154   \n",
       "\n",
       "            35         36         37         38         39         40  \\\n",
       "0    23.225850  23.000048  22.701733  22.847687  22.956238  22.859430   \n",
       "1    25.259407  24.970633  24.916570  24.894380  25.091064  24.524633   \n",
       "2    28.902798  28.318588  28.313631  28.562454  28.775906  28.705750   \n",
       "3    31.013440  30.674220  30.490833  30.889800  31.415369  30.684217   \n",
       "4    28.709368  28.236652  27.862185  28.190653  27.976366  28.034640   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "985  28.150370  27.327015  26.925766  27.142687  27.417791  27.136831   \n",
       "986  27.895765  27.436071  27.278236  27.352667  27.568275  27.698250   \n",
       "987  26.196365  25.930500  26.020378  26.066069  26.344800  25.879030   \n",
       "988  24.026810  23.770632  23.551998  23.764439  23.723919  23.646612   \n",
       "989  22.033613  21.977255  21.714125  21.868393  21.803688  21.836409   \n",
       "\n",
       "            41         42  \n",
       "0    22.461447  22.391277  \n",
       "1    24.313745  24.571362  \n",
       "2    26.892412  27.760454  \n",
       "3    29.582115  30.068295  \n",
       "4    28.116898  27.688896  \n",
       "..         ...        ...  \n",
       "985  28.071230  26.890303  \n",
       "986  25.898380  26.941866  \n",
       "987  25.319017  25.366710  \n",
       "988  22.816685  23.086576  \n",
       "989  21.492880  21.381887  \n",
       "\n",
       "[990 rows x 43 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan prediksi data testing diurutkan berdasarkan nilai validasi MSE terbaik.\n",
    "best_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c3e9b72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:36.609105Z",
     "iopub.status.busy": "2021-11-04T11:29:36.608466Z",
     "iopub.status.idle": "2021-11-04T11:29:36.612965Z",
     "shell.execute_reply": "2021-11-04T11:29:36.613405Z"
    },
    "papermill": {
     "duration": 0.135046,
     "end_time": "2021-11-04T11:29:36.613581",
     "exception": false,
     "start_time": "2021-11-04T11:29:36.478535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nilai MSE pada data validasi:  26.19003715101544\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan nilai MSE terbaik pada data validasi.\n",
    "error = MSE(y_valid, best_valid_preds[0])\n",
    "print('nilai MSE pada data validasi: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4e909e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:36.866259Z",
     "iopub.status.busy": "2021-11-04T11:29:36.865695Z",
     "iopub.status.idle": "2021-11-04T11:29:36.869298Z",
     "shell.execute_reply": "2021-11-04T11:29:36.869723Z"
    },
    "papermill": {
     "duration": 0.132072,
     "end_time": "2021-11-04T11:29:36.869889",
     "exception": false,
     "start_time": "2021-11-04T11:29:36.737817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total execution time: 0:13:48.686182\n"
     ]
    }
   ],
   "source": [
    "# Mencatat waktu berakhirnya keseluruhan program model dan prediksi data.\n",
    "global_end_time = time.time()\n",
    "\n",
    "# Menampilkan waktu eksekusi dari keseluruhan program model dan prediksi data.\n",
    "total_execution_time = datetime.timedelta(seconds = global_end_time - global_start_time)\n",
    "print(\"total execution time: %s\" % (total_execution_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 847.071426,
   "end_time": "2021-11-04T11:29:39.972116",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-04T11:15:32.900690",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
