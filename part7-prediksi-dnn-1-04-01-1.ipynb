{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c04420",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-04T11:13:20.093355Z",
     "iopub.status.busy": "2021-11-04T11:13:20.092146Z",
     "iopub.status.idle": "2021-11-04T11:13:28.310081Z",
     "shell.execute_reply": "2021-11-04T11:13:28.309297Z",
     "shell.execute_reply.started": "2021-11-04T10:48:34.207266Z"
    },
    "papermill": {
     "duration": 8.24814,
     "end_time": "2021-11-04T11:13:28.310288",
     "exception": false,
     "start_time": "2021-11-04T11:13:20.062148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Melakukan impor libraries yang diperlukan untuk membangun model dan prediksi data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23d09bf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:13:28.365061Z",
     "iopub.status.busy": "2021-11-04T11:13:28.364045Z",
     "iopub.status.idle": "2021-11-04T11:13:28.366658Z",
     "shell.execute_reply": "2021-11-04T11:13:28.367207Z",
     "shell.execute_reply.started": "2021-11-04T04:01:49.258697Z"
    },
    "papermill": {
     "duration": 0.033127,
     "end_time": "2021-11-04T11:13:28.367453",
     "exception": false,
     "start_time": "2021-11-04T11:13:28.334326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mencatat waktu dimulainya keseluruhan program model dan prediksi data.\n",
    "global_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cafe385c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:13:28.418056Z",
     "iopub.status.busy": "2021-11-04T11:13:28.417337Z",
     "iopub.status.idle": "2021-11-04T11:13:28.422385Z",
     "shell.execute_reply": "2021-11-04T11:13:28.422954Z",
     "shell.execute_reply.started": "2021-11-04T10:04:54.282612Z"
    },
    "papermill": {
     "duration": 0.031348,
     "end_time": "2021-11-04T11:13:28.423130",
     "exception": false,
     "start_time": "2021-11-04T11:13:28.391782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menetapkan nilai seed untuk reproduksi model.\n",
    "seed = 2021\n",
    "def set_seed(seed = seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = str(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01993d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:13:28.473136Z",
     "iopub.status.busy": "2021-11-04T11:13:28.472434Z",
     "iopub.status.idle": "2021-11-04T11:13:28.476540Z",
     "shell.execute_reply": "2021-11-04T11:13:28.477088Z",
     "shell.execute_reply.started": "2021-11-04T10:04:57.579289Z"
    },
    "papermill": {
     "duration": 0.030438,
     "end_time": "2021-11-04T11:13:28.477263",
     "exception": false,
     "start_time": "2021-11-04T11:13:28.446825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menentukan indeks fold, kode penamaan program, banyak epoch, dan ukuran batch.\n",
    "fold_index = 1\n",
    "codename = '1_04_01_{}'.format(fold_index)\n",
    "epochs = 128\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ddb592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:13:28.530474Z",
     "iopub.status.busy": "2021-11-04T11:13:28.529811Z",
     "iopub.status.idle": "2021-11-04T11:14:32.969029Z",
     "shell.execute_reply": "2021-11-04T11:14:32.968242Z",
     "shell.execute_reply.started": "2021-11-04T10:05:01.137768Z"
    },
    "papermill": {
     "duration": 64.469008,
     "end_time": "2021-11-04T11:14:32.969193",
     "exception": false,
     "start_time": "2021-11-04T11:13:28.500185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyusun data training.\n",
    "df_train = pd.read_csv('../input/bdc-sd2021-train-tabular-data/train_gray.csv')\n",
    "fake_train = pd.DataFrame(np.array(df_train).reshape((2305, 128, 128))[:, :, ::-1].reshape((2305, 128*128)))\n",
    "fake_train.columns = df_train.columns\n",
    "df_train = pd.concat([df_train, fake_train], ignore_index = True)\n",
    "del fake_train\n",
    "\n",
    "# Menyusun data testing.\n",
    "df_test = pd.read_csv('../input/bdc-sd2021-test-tabular-data/test_gray.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2889df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:14:33.021921Z",
     "iopub.status.busy": "2021-11-04T11:14:33.021223Z",
     "iopub.status.idle": "2021-11-04T11:14:33.616410Z",
     "shell.execute_reply": "2021-11-04T11:14:33.616937Z",
     "shell.execute_reply.started": "2021-11-04T10:06:09.166332Z"
    },
    "papermill": {
     "duration": 0.62413,
     "end_time": "2021-11-04T11:14:33.617115",
     "exception": false,
     "start_time": "2021-11-04T11:14:32.992985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16374</th>\n",
       "      <th>16375</th>\n",
       "      <th>16376</th>\n",
       "      <th>16377</th>\n",
       "      <th>16378</th>\n",
       "      <th>16379</th>\n",
       "      <th>16380</th>\n",
       "      <th>16381</th>\n",
       "      <th>16382</th>\n",
       "      <th>16383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.183857</td>\n",
       "      <td>0.139013</td>\n",
       "      <td>0.098655</td>\n",
       "      <td>0.116592</td>\n",
       "      <td>0.121076</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.116592</td>\n",
       "      <td>0.094170</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>0.076233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242152</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.121076</td>\n",
       "      <td>0.134529</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.174888</td>\n",
       "      <td>0.152466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.827411</td>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.827411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319797</td>\n",
       "      <td>0.294416</td>\n",
       "      <td>0.253807</td>\n",
       "      <td>0.208122</td>\n",
       "      <td>0.147208</td>\n",
       "      <td>0.116751</td>\n",
       "      <td>0.096447</td>\n",
       "      <td>0.065990</td>\n",
       "      <td>0.055838</td>\n",
       "      <td>0.040609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.559091</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.486364</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.368182</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.154167</td>\n",
       "      <td>0.154167</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.893023</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.804651</td>\n",
       "      <td>0.879070</td>\n",
       "      <td>0.869767</td>\n",
       "      <td>0.637209</td>\n",
       "      <td>0.479070</td>\n",
       "      <td>0.269767</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106977</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.018605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.356828</td>\n",
       "      <td>0.370044</td>\n",
       "      <td>0.396476</td>\n",
       "      <td>0.409692</td>\n",
       "      <td>0.396476</td>\n",
       "      <td>0.422907</td>\n",
       "      <td>0.471366</td>\n",
       "      <td>0.515419</td>\n",
       "      <td>0.480176</td>\n",
       "      <td>0.436123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.039648</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.035242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.306977</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.339535</td>\n",
       "      <td>0.330233</td>\n",
       "      <td>0.320930</td>\n",
       "      <td>0.367442</td>\n",
       "      <td>0.367442</td>\n",
       "      <td>0.316279</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>0.339535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060465</td>\n",
       "      <td>0.074419</td>\n",
       "      <td>0.065116</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.083721</td>\n",
       "      <td>0.065116</td>\n",
       "      <td>0.055814</td>\n",
       "      <td>0.097674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>0.157258</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.137097</td>\n",
       "      <td>0.108871</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.068548</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.060484</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100806</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.044355</td>\n",
       "      <td>0.044355</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.052419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4610 rows × 16384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.183857  0.139013  0.098655  0.116592  0.121076  0.103139  0.116592   \n",
       "1     0.857868  0.857868  0.857868  0.857868  0.857868  0.857868  0.842640   \n",
       "2     0.018182  0.013636  0.013636  0.018182  0.018182  0.018182  0.018182   \n",
       "3     0.162500  0.162500  0.154167  0.154167  0.166667  0.187500  0.216667   \n",
       "4     0.893023  0.860465  0.804651  0.879070  0.869767  0.637209  0.479070   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4605  0.090476  0.076190  0.095238  0.114286  0.090476  0.109524  0.076190   \n",
       "4606  0.356828  0.370044  0.396476  0.409692  0.396476  0.422907  0.471366   \n",
       "4607  0.306977  0.279070  0.339535  0.330233  0.320930  0.367442  0.367442   \n",
       "4608  0.145000  0.240000  0.290000  0.295000  0.230000  0.170000  0.185000   \n",
       "4609  0.157258  0.161290  0.137097  0.108871  0.112903  0.096774  0.068548   \n",
       "\n",
       "             7         8         9  ...     16374     16375     16376  \\\n",
       "0     0.094170  0.089686  0.076233  ...  0.242152  0.089686  0.103139   \n",
       "1     0.827411  0.842640  0.827411  ...  0.319797  0.294416  0.253807   \n",
       "2     0.018182  0.013636  0.018182  ...  0.568182  0.559091  0.536364   \n",
       "3     0.254167  0.233333  0.183333  ...  0.666667  0.675000  0.745833   \n",
       "4     0.269767  0.186047  0.186047  ...  0.106977  0.032558  0.027907   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4605  0.061905  0.052381  0.076190  ...  0.157143  0.114286  0.133333   \n",
       "4606  0.515419  0.480176  0.436123  ...  0.030837  0.035242  0.030837   \n",
       "4607  0.316279  0.283721  0.339535  ...  0.060465  0.074419  0.065116   \n",
       "4608  0.200000  0.200000  0.230000  ...  0.015000  0.015000  0.015000   \n",
       "4609  0.072581  0.060484  0.072581  ...  0.100806  0.064516  0.044355   \n",
       "\n",
       "         16377     16378     16379     16380     16381     16382     16383  \n",
       "0     0.121076  0.134529  0.156951  0.156951  0.156951  0.174888  0.152466  \n",
       "1     0.208122  0.147208  0.116751  0.096447  0.065990  0.055838  0.040609  \n",
       "2     0.518182  0.486364  0.436364  0.368182  0.254545  0.113636  0.045455  \n",
       "3     0.887500  0.908333  0.900000  0.916667  0.945833  0.966667  0.966667  \n",
       "4     0.018605  0.004651  0.000000  0.000000  0.004651  0.009302  0.018605  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4605  0.047619  0.061905  0.061905  0.052381  0.042857  0.042857  0.042857  \n",
       "4606  0.026432  0.022026  0.017621  0.039648  0.026432  0.017621  0.035242  \n",
       "4607  0.051163  0.051163  0.046512  0.083721  0.065116  0.055814  0.097674  \n",
       "4608  0.015000  0.015000  0.015000  0.015000  0.010000  0.010000  0.010000  \n",
       "4609  0.044355  0.040323  0.032258  0.020161  0.012097  0.016129  0.052419  \n",
       "\n",
       "[4610 rows x 16384 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan normalisasi pada data training.\n",
    "scaler = MinMaxScaler(copy = False)\n",
    "scaler.fit_transform(df_train.T)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f104a65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:14:33.669904Z",
     "iopub.status.busy": "2021-11-04T11:14:33.669119Z",
     "iopub.status.idle": "2021-11-04T11:14:33.829119Z",
     "shell.execute_reply": "2021-11-04T11:14:33.828480Z",
     "shell.execute_reply.started": "2021-11-04T10:06:14.713247Z"
    },
    "papermill": {
     "duration": 0.187323,
     "end_time": "2021-11-04T11:14:33.829271",
     "exception": false,
     "start_time": "2021-11-04T11:14:33.641948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16374</th>\n",
       "      <th>16375</th>\n",
       "      <th>16376</th>\n",
       "      <th>16377</th>\n",
       "      <th>16378</th>\n",
       "      <th>16379</th>\n",
       "      <th>16380</th>\n",
       "      <th>16381</th>\n",
       "      <th>16382</th>\n",
       "      <th>16383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347619</td>\n",
       "      <td>0.361905</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.257143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417355</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.471074</td>\n",
       "      <td>0.508264</td>\n",
       "      <td>0.475207</td>\n",
       "      <td>0.541322</td>\n",
       "      <td>0.644628</td>\n",
       "      <td>0.611570</td>\n",
       "      <td>0.512397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.531120</td>\n",
       "      <td>0.493776</td>\n",
       "      <td>0.485477</td>\n",
       "      <td>0.427386</td>\n",
       "      <td>0.402490</td>\n",
       "      <td>0.356846</td>\n",
       "      <td>0.340249</td>\n",
       "      <td>0.356846</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.340249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190871</td>\n",
       "      <td>0.112033</td>\n",
       "      <td>0.062241</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.053942</td>\n",
       "      <td>0.045643</td>\n",
       "      <td>0.053942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.763736</td>\n",
       "      <td>0.763736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>0.906593</td>\n",
       "      <td>0.879121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.248677</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.248677</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>0.608466</td>\n",
       "      <td>0.608466</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.566138</td>\n",
       "      <td>0.502646</td>\n",
       "      <td>0.470899</td>\n",
       "      <td>0.449735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.844898</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.963265</td>\n",
       "      <td>0.987755</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.722449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.848980</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.832653</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.820408</td>\n",
       "      <td>0.783673</td>\n",
       "      <td>0.767347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.077236</td>\n",
       "      <td>0.105691</td>\n",
       "      <td>0.117886</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.126016</td>\n",
       "      <td>0.069106</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.052846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186992</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.223577</td>\n",
       "      <td>0.239837</td>\n",
       "      <td>0.260163</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.321138</td>\n",
       "      <td>0.337398</td>\n",
       "      <td>0.357724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.037915</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.109244</td>\n",
       "      <td>0.155462</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.121849</td>\n",
       "      <td>0.113445</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>0.084034</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525210</td>\n",
       "      <td>0.281513</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.037815</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.042017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.156398</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.165877</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.127962</td>\n",
       "      <td>0.109005</td>\n",
       "      <td>0.118483</td>\n",
       "      <td>0.127962</td>\n",
       "      <td>0.123223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.127962</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.080569</td>\n",
       "      <td>0.142180</td>\n",
       "      <td>0.156398</td>\n",
       "      <td>0.132701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 16384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.095238  0.100000  0.100000  0.095238  0.095238  0.100000  0.109524   \n",
       "1    0.061983  0.061983  0.061983  0.061983  0.061983  0.061983  0.061983   \n",
       "2    0.531120  0.493776  0.485477  0.427386  0.402490  0.356846  0.340249   \n",
       "3    0.796703  0.796703  0.791209  0.791209  0.796703  0.818681  0.818681   \n",
       "4    0.222222  0.232804  0.232804  0.248677  0.253968  0.259259  0.248677   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "985  0.828571  0.844898  0.804082  0.824490  0.918367  0.963265  0.987755   \n",
       "986  0.048780  0.065041  0.077236  0.105691  0.117886  0.121951  0.126016   \n",
       "987  0.056872  0.056872  0.061611  0.061611  0.071090  0.056872  0.037915   \n",
       "988  0.109244  0.155462  0.168067  0.121849  0.113445  0.088235  0.079832   \n",
       "989  0.156398  0.146919  0.151659  0.165877  0.151659  0.127962  0.109005   \n",
       "\n",
       "            7         8         9  ...     16374     16375     16376  \\\n",
       "0    0.114286  0.119048  0.104762  ...  0.347619  0.361905  0.314286   \n",
       "1    0.061983  0.066116  0.066116  ...  0.417355  0.322314  0.285124   \n",
       "2    0.356846  0.336100  0.340249  ...  0.190871  0.112033  0.062241   \n",
       "3    0.785714  0.763736  0.763736  ...  0.961538  0.950549  0.950549   \n",
       "4    0.243386  0.243386  0.243386  ...  0.619048  0.613757  0.608466   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "985  0.959184  0.873469  0.722449  ...  0.857143  0.848980  0.828571   \n",
       "986  0.069106  0.060976  0.052846  ...  0.186992  0.207317  0.223577   \n",
       "987  0.023697  0.009479  0.018957  ...  0.900474  0.890995  0.895735   \n",
       "988  0.084034  0.079832  0.067227  ...  0.525210  0.281513  0.050420   \n",
       "989  0.118483  0.127962  0.123223  ...  0.146919  0.151659  0.146919   \n",
       "\n",
       "        16377     16378     16379     16380     16381     16382     16383  \n",
       "0    0.400000  0.419048  0.261905  0.233333  0.300000  0.266667  0.257143  \n",
       "1    0.471074  0.508264  0.475207  0.541322  0.644628  0.611570  0.512397  \n",
       "2    0.058091  0.074689  0.066390  0.058091  0.053942  0.045643  0.053942  \n",
       "3    0.945055  0.939560  0.928571  0.923077  0.917582  0.906593  0.879121  \n",
       "4    0.608466  0.613757  0.592593  0.566138  0.502646  0.470899  0.449735  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "985  0.832653  0.840816  0.840816  0.816327  0.820408  0.783673  0.767347  \n",
       "986  0.239837  0.260163  0.284553  0.304878  0.321138  0.337398  0.357724  \n",
       "987  0.900474  0.895735  0.895735  0.890995  0.890995  0.890995  0.890995  \n",
       "988  0.033613  0.037815  0.033613  0.033613  0.042017  0.042017  0.042017  \n",
       "989  0.127962  0.151659  0.071090  0.080569  0.142180  0.156398  0.132701  \n",
       "\n",
       "[990 rows x 16384 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan normalisasi pada data testing.\n",
    "scaler.fit_transform(df_test.T)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f40a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:14:33.887023Z",
     "iopub.status.busy": "2021-11-04T11:14:33.886157Z",
     "iopub.status.idle": "2021-11-04T11:14:33.915037Z",
     "shell.execute_reply": "2021-11-04T11:14:33.915595Z",
     "shell.execute_reply.started": "2021-11-04T10:06:18.909964Z"
    },
    "papermill": {
     "duration": 0.060755,
     "end_time": "2021-11-04T11:14:33.915807",
     "exception": false,
     "start_time": "2021-11-04T11:14:33.855052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usia</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4610 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      usia  fold\n",
       "0       27     3\n",
       "1       27     3\n",
       "2       27     3\n",
       "3       24     0\n",
       "4       24     0\n",
       "...    ...   ...\n",
       "4605    23     4\n",
       "4606    23     4\n",
       "4607    27     4\n",
       "4608    27     4\n",
       "4609    27     4\n",
       "\n",
       "[4610 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Memunculkan target prediksi.\n",
    "target_0 = pd.read_csv('../input/bdc-sd2021-data-tambahan/train_target_and_fold.csv')[['usia', 'fold']]\n",
    "target_1 = pd.concat([target_0 for iteration in range(2)], ignore_index = True)\n",
    "target_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38fc3989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:14:33.971569Z",
     "iopub.status.busy": "2021-11-04T11:14:33.970471Z",
     "iopub.status.idle": "2021-11-04T11:14:34.061702Z",
     "shell.execute_reply": "2021-11-04T11:14:34.062279Z",
     "shell.execute_reply.started": "2021-11-04T10:06:23.078369Z"
    },
    "papermill": {
     "duration": 0.120026,
     "end_time": "2021-11-04T11:14:34.062466",
     "exception": false,
     "start_time": "2021-11-04T11:14:33.942440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_le</th>\n",
       "      <th>y_le</th>\n",
       "      <th>x_re</th>\n",
       "      <th>y_re</th>\n",
       "      <th>x_n</th>\n",
       "      <th>y_n</th>\n",
       "      <th>x_ml</th>\n",
       "      <th>y_ml</th>\n",
       "      <th>x_mr</th>\n",
       "      <th>y_mr</th>\n",
       "      <th>...</th>\n",
       "      <th>adj_n_ml</th>\n",
       "      <th>sym_le_mr</th>\n",
       "      <th>adj_le_mr</th>\n",
       "      <th>sym_re_mr</th>\n",
       "      <th>adj_re_mr</th>\n",
       "      <th>sym_n_mr</th>\n",
       "      <th>adj_n_mr</th>\n",
       "      <th>sym_ml_mr</th>\n",
       "      <th>adj_ml_mr</th>\n",
       "      <th>abs_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>0.698052</td>\n",
       "      <td>0.392694</td>\n",
       "      <td>0.405844</td>\n",
       "      <td>0.618721</td>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249515</td>\n",
       "      <td>0.615908</td>\n",
       "      <td>0.693416</td>\n",
       "      <td>0.314818</td>\n",
       "      <td>0.446237</td>\n",
       "      <td>0.339205</td>\n",
       "      <td>0.350364</td>\n",
       "      <td>0.539005</td>\n",
       "      <td>0.539049</td>\n",
       "      <td>0.061566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179724</td>\n",
       "      <td>0.397351</td>\n",
       "      <td>0.589862</td>\n",
       "      <td>0.403974</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.619205</td>\n",
       "      <td>0.202765</td>\n",
       "      <td>0.725166</td>\n",
       "      <td>0.635945</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171500</td>\n",
       "      <td>0.563722</td>\n",
       "      <td>0.648461</td>\n",
       "      <td>0.327759</td>\n",
       "      <td>0.453958</td>\n",
       "      <td>0.362484</td>\n",
       "      <td>0.377599</td>\n",
       "      <td>0.433192</td>\n",
       "      <td>0.433204</td>\n",
       "      <td>0.134023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195946</td>\n",
       "      <td>0.404878</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.404878</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.614634</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.682432</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239078</td>\n",
       "      <td>0.586077</td>\n",
       "      <td>0.664537</td>\n",
       "      <td>0.327457</td>\n",
       "      <td>0.453156</td>\n",
       "      <td>0.325814</td>\n",
       "      <td>0.344595</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.174672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266055</td>\n",
       "      <td>0.373239</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.373239</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.238532</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272772</td>\n",
       "      <td>0.565660</td>\n",
       "      <td>0.629561</td>\n",
       "      <td>0.331113</td>\n",
       "      <td>0.431290</td>\n",
       "      <td>0.323865</td>\n",
       "      <td>0.348745</td>\n",
       "      <td>0.486442</td>\n",
       "      <td>0.486585</td>\n",
       "      <td>0.121842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.244565</td>\n",
       "      <td>0.389764</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.393701</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.578740</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.696850</td>\n",
       "      <td>0.706522</td>\n",
       "      <td>0.712598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254682</td>\n",
       "      <td>0.563583</td>\n",
       "      <td>0.641880</td>\n",
       "      <td>0.319083</td>\n",
       "      <td>0.440352</td>\n",
       "      <td>0.322564</td>\n",
       "      <td>0.346806</td>\n",
       "      <td>0.489384</td>\n",
       "      <td>0.489613</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.362934</td>\n",
       "      <td>0.401146</td>\n",
       "      <td>0.803089</td>\n",
       "      <td>0.383954</td>\n",
       "      <td>0.660232</td>\n",
       "      <td>0.616046</td>\n",
       "      <td>0.389961</td>\n",
       "      <td>0.759312</td>\n",
       "      <td>0.737452</td>\n",
       "      <td>0.753582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327708</td>\n",
       "      <td>0.530242</td>\n",
       "      <td>0.629355</td>\n",
       "      <td>0.364131</td>\n",
       "      <td>0.487068</td>\n",
       "      <td>0.162752</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.347538</td>\n",
       "      <td>0.347576</td>\n",
       "      <td>0.540420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.386256</td>\n",
       "      <td>0.744108</td>\n",
       "      <td>0.398104</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.649289</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.772512</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.779621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274054</td>\n",
       "      <td>0.612584</td>\n",
       "      <td>0.719783</td>\n",
       "      <td>0.387194</td>\n",
       "      <td>0.549482</td>\n",
       "      <td>0.236635</td>\n",
       "      <td>0.267332</td>\n",
       "      <td>0.404103</td>\n",
       "      <td>0.404167</td>\n",
       "      <td>0.552494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.274869</td>\n",
       "      <td>0.400372</td>\n",
       "      <td>0.759162</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>0.523560</td>\n",
       "      <td>0.616387</td>\n",
       "      <td>0.324607</td>\n",
       "      <td>0.780261</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>0.780261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304386</td>\n",
       "      <td>0.562206</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.386895</td>\n",
       "      <td>0.539038</td>\n",
       "      <td>0.230645</td>\n",
       "      <td>0.281800</td>\n",
       "      <td>0.361257</td>\n",
       "      <td>0.361257</td>\n",
       "      <td>0.162489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>0.323887</td>\n",
       "      <td>0.405836</td>\n",
       "      <td>0.801619</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.668016</td>\n",
       "      <td>0.631300</td>\n",
       "      <td>0.425101</td>\n",
       "      <td>0.801061</td>\n",
       "      <td>0.785425</td>\n",
       "      <td>0.814324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370196</td>\n",
       "      <td>0.602490</td>\n",
       "      <td>0.749939</td>\n",
       "      <td>0.395557</td>\n",
       "      <td>0.603456</td>\n",
       "      <td>0.206407</td>\n",
       "      <td>0.284469</td>\n",
       "      <td>0.360568</td>\n",
       "      <td>0.360892</td>\n",
       "      <td>0.456213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>0.357488</td>\n",
       "      <td>0.393750</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>0.384375</td>\n",
       "      <td>0.632850</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>0.314010</td>\n",
       "      <td>0.753125</td>\n",
       "      <td>0.830918</td>\n",
       "      <td>0.753125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405912</td>\n",
       "      <td>0.600094</td>\n",
       "      <td>0.741007</td>\n",
       "      <td>0.362607</td>\n",
       "      <td>0.557652</td>\n",
       "      <td>0.256197</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.378831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4610 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x_le      y_le      x_re      y_re       x_n       y_n      x_ml  \\\n",
       "0     0.204545  0.390411  0.698052  0.392694  0.405844  0.618721  0.194805   \n",
       "1     0.179724  0.397351  0.589862  0.403974  0.290323  0.619205  0.202765   \n",
       "2     0.195946  0.404878  0.662162  0.404878  0.378378  0.614634  0.202703   \n",
       "3     0.266055  0.373239  0.715596  0.373239  0.440367  0.549296  0.238532   \n",
       "4     0.244565  0.389764  0.695652  0.393701  0.413043  0.578740  0.217391   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4605  0.362934  0.401146  0.803089  0.383954  0.660232  0.616046  0.389961   \n",
       "4606  0.232323  0.386256  0.744108  0.398104  0.515152  0.649289  0.313131   \n",
       "4607  0.274869  0.400372  0.759162  0.396648  0.523560  0.616387  0.324607   \n",
       "4608  0.323887  0.405836  0.801619  0.413793  0.668016  0.631300  0.425101   \n",
       "4609  0.357488  0.393750  0.879227  0.384375  0.632850  0.590625  0.314010   \n",
       "\n",
       "          y_ml      x_mr      y_mr  ...  adj_n_ml  sym_le_mr  adj_le_mr  \\\n",
       "0     0.712329  0.733766  0.705479  ...  0.249515   0.615908   0.693416   \n",
       "1     0.725166  0.635945  0.728477  ...  0.171500   0.563722   0.648461   \n",
       "2     0.731707  0.682432  0.731707  ...  0.239078   0.586077   0.664537   \n",
       "3     0.690141  0.724771  0.704225  ...  0.272772   0.565660   0.629561   \n",
       "4     0.696850  0.706522  0.712598  ...  0.254682   0.563583   0.641880   \n",
       "...        ...       ...       ...  ...       ...        ...        ...   \n",
       "4605  0.759312  0.737452  0.753582  ...  0.327708   0.530242   0.629355   \n",
       "4606  0.772512  0.717172  0.779621  ...  0.274054   0.612584   0.719783   \n",
       "4607  0.780261  0.685864  0.780261  ...  0.304386   0.562206   0.678031   \n",
       "4608  0.801061  0.785425  0.814324  ...  0.370196   0.602490   0.749939   \n",
       "4609  0.753125  0.830918  0.753125  ...  0.405912   0.600094   0.741007   \n",
       "\n",
       "      sym_re_mr  adj_re_mr  sym_n_mr  adj_n_mr  sym_ml_mr  adj_ml_mr  \\\n",
       "0      0.314818   0.446237  0.339205  0.350364   0.539005   0.539049   \n",
       "1      0.327759   0.453958  0.362484  0.377599   0.433192   0.433204   \n",
       "2      0.327457   0.453156  0.325814  0.344595   0.479730   0.479730   \n",
       "3      0.331113   0.431290  0.323865  0.348745   0.486442   0.486585   \n",
       "4      0.319083   0.440352  0.322564  0.346806   0.489384   0.489613   \n",
       "...         ...        ...       ...       ...        ...        ...   \n",
       "4605   0.364131   0.487068  0.162752  0.207921   0.347538   0.347576   \n",
       "4606   0.387194   0.549482  0.236635  0.267332   0.404103   0.404167   \n",
       "4607   0.386895   0.539038  0.230645  0.281800   0.361257   0.361257   \n",
       "4608   0.395557   0.603456  0.206407  0.284469   0.360568   0.360892   \n",
       "4609   0.362607   0.557652  0.256197  0.319900   0.516908   0.516908   \n",
       "\n",
       "      abs_angle  \n",
       "0      0.061566  \n",
       "1      0.134023  \n",
       "2      0.174672  \n",
       "3      0.121842  \n",
       "4      0.012195  \n",
       "...         ...  \n",
       "4605   0.540420  \n",
       "4606   0.552494  \n",
       "4607   0.162489  \n",
       "4608   0.456213  \n",
       "4609   0.378831  \n",
       "\n",
       "[4610 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan penambahan data training yang berkaitan dengan posisi relatif fitur pada wajah.\n",
    "df_train_1 = pd.read_csv('../input/bdc-sd2021-data-tambahan/train_facial_relative.csv')\n",
    "fake_train_1 = df_train_1.copy()\n",
    "fake_train_1['x_le'] = 1 - df_train_1['x_re']\n",
    "fake_train_1['x_re'] = 1 - df_train_1['x_le']\n",
    "fake_train_1['x_n'] = 1 - df_train_1['x_n']\n",
    "fake_train_1['x_ml'] = 1 - df_train_1['x_mr']\n",
    "fake_train_1['x_mr'] = 1 - df_train_1['x_ml']\n",
    "fake_train_1[['sym_le_n', 'adj_le_n', 'sym_re_n', 'adj_re_n']] = df_train_1[['sym_re_n', 'adj_re_n', 'sym_le_n', 'adj_le_n']]\n",
    "fake_train_1[['sym_le_ml', 'adj_le_ml', 'sym_re_mr', 'adj_re_mr']] = df_train_1[['sym_re_mr', 'adj_re_mr', 'sym_le_ml', 'adj_le_ml']]\n",
    "fake_train_1[['sym_le_mr', 'adj_le_mr', 'sym_re_ml', 'adj_re_ml']] = df_train_1[['sym_re_ml', 'adj_re_ml', 'sym_le_mr', 'adj_le_mr']]\n",
    "fake_train_1[['sym_n_ml', 'adj_n_ml', 'sym_n_mr', 'adj_n_mr']] = df_train_1[['sym_n_mr', 'adj_n_mr', 'sym_n_ml', 'adj_n_ml']]\n",
    "\n",
    "df_train_1 = pd.concat([df_train_1, fake_train_1], ignore_index = True)\n",
    "del fake_train_1\n",
    "\n",
    "df_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7c3151d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:14:34.120454Z",
     "iopub.status.busy": "2021-11-04T11:14:34.119320Z",
     "iopub.status.idle": "2021-11-04T11:14:34.176292Z",
     "shell.execute_reply": "2021-11-04T11:14:34.176818Z",
     "shell.execute_reply.started": "2021-11-04T10:06:27.057874Z"
    },
    "papermill": {
     "duration": 0.088136,
     "end_time": "2021-11-04T11:14:34.176997",
     "exception": false,
     "start_time": "2021-11-04T11:14:34.088861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_le</th>\n",
       "      <th>y_le</th>\n",
       "      <th>x_re</th>\n",
       "      <th>y_re</th>\n",
       "      <th>x_n</th>\n",
       "      <th>y_n</th>\n",
       "      <th>x_ml</th>\n",
       "      <th>y_ml</th>\n",
       "      <th>x_mr</th>\n",
       "      <th>y_mr</th>\n",
       "      <th>...</th>\n",
       "      <th>adj_n_ml</th>\n",
       "      <th>sym_le_mr</th>\n",
       "      <th>adj_le_mr</th>\n",
       "      <th>sym_re_mr</th>\n",
       "      <th>adj_re_mr</th>\n",
       "      <th>sym_n_mr</th>\n",
       "      <th>adj_n_mr</th>\n",
       "      <th>sym_ml_mr</th>\n",
       "      <th>adj_ml_mr</th>\n",
       "      <th>abs_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.291209</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.521978</td>\n",
       "      <td>0.516432</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.737089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338570</td>\n",
       "      <td>0.596852</td>\n",
       "      <td>0.645365</td>\n",
       "      <td>0.400006</td>\n",
       "      <td>0.467840</td>\n",
       "      <td>0.303782</td>\n",
       "      <td>0.332088</td>\n",
       "      <td>0.434091</td>\n",
       "      <td>0.434101</td>\n",
       "      <td>0.070471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.405128</td>\n",
       "      <td>0.753521</td>\n",
       "      <td>0.394872</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.625641</td>\n",
       "      <td>0.260563</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318229</td>\n",
       "      <td>0.554593</td>\n",
       "      <td>0.623428</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.429635</td>\n",
       "      <td>0.213573</td>\n",
       "      <td>0.227106</td>\n",
       "      <td>0.486159</td>\n",
       "      <td>0.486375</td>\n",
       "      <td>0.029403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214533</td>\n",
       "      <td>0.403023</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>0.397985</td>\n",
       "      <td>0.366782</td>\n",
       "      <td>0.612091</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.727960</td>\n",
       "      <td>0.692042</td>\n",
       "      <td>0.722922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206456</td>\n",
       "      <td>0.574761</td>\n",
       "      <td>0.648943</td>\n",
       "      <td>0.326426</td>\n",
       "      <td>0.447452</td>\n",
       "      <td>0.343624</td>\n",
       "      <td>0.359129</td>\n",
       "      <td>0.456775</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.022553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.365517</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.402062</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>0.597938</td>\n",
       "      <td>0.393103</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346547</td>\n",
       "      <td>0.537095</td>\n",
       "      <td>0.627927</td>\n",
       "      <td>0.356271</td>\n",
       "      <td>0.476312</td>\n",
       "      <td>0.194191</td>\n",
       "      <td>0.240590</td>\n",
       "      <td>0.365844</td>\n",
       "      <td>0.366102</td>\n",
       "      <td>0.064427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.381323</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.369650</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.603113</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.747082</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.735409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279993</td>\n",
       "      <td>0.575064</td>\n",
       "      <td>0.655712</td>\n",
       "      <td>0.366092</td>\n",
       "      <td>0.489833</td>\n",
       "      <td>0.255644</td>\n",
       "      <td>0.281443</td>\n",
       "      <td>0.422036</td>\n",
       "      <td>0.422164</td>\n",
       "      <td>0.044914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.356364</td>\n",
       "      <td>0.398892</td>\n",
       "      <td>0.821818</td>\n",
       "      <td>0.398892</td>\n",
       "      <td>0.650909</td>\n",
       "      <td>0.617729</td>\n",
       "      <td>0.374545</td>\n",
       "      <td>0.739612</td>\n",
       "      <td>0.785455</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319338</td>\n",
       "      <td>0.546195</td>\n",
       "      <td>0.617197</td>\n",
       "      <td>0.339901</td>\n",
       "      <td>0.445124</td>\n",
       "      <td>0.179696</td>\n",
       "      <td>0.206282</td>\n",
       "      <td>0.410918</td>\n",
       "      <td>0.410925</td>\n",
       "      <td>0.124355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.373016</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.563492</td>\n",
       "      <td>0.362637</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369237</td>\n",
       "      <td>0.602016</td>\n",
       "      <td>0.700027</td>\n",
       "      <td>0.381111</td>\n",
       "      <td>0.527587</td>\n",
       "      <td>0.251896</td>\n",
       "      <td>0.311010</td>\n",
       "      <td>0.385352</td>\n",
       "      <td>0.386026</td>\n",
       "      <td>0.047583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328573</td>\n",
       "      <td>0.573337</td>\n",
       "      <td>0.690348</td>\n",
       "      <td>0.364790</td>\n",
       "      <td>0.522544</td>\n",
       "      <td>0.259399</td>\n",
       "      <td>0.308120</td>\n",
       "      <td>0.449389</td>\n",
       "      <td>0.449509</td>\n",
       "      <td>0.031240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.338403</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.338403</td>\n",
       "      <td>0.319048</td>\n",
       "      <td>0.593156</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.779468</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.779468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261948</td>\n",
       "      <td>0.605120</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.444751</td>\n",
       "      <td>0.555329</td>\n",
       "      <td>0.302327</td>\n",
       "      <td>0.333367</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.020199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.280255</td>\n",
       "      <td>0.414596</td>\n",
       "      <td>0.787686</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.556263</td>\n",
       "      <td>0.639752</td>\n",
       "      <td>0.280255</td>\n",
       "      <td>0.729814</td>\n",
       "      <td>0.755839</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302233</td>\n",
       "      <td>0.573150</td>\n",
       "      <td>0.646119</td>\n",
       "      <td>0.323002</td>\n",
       "      <td>0.440643</td>\n",
       "      <td>0.220912</td>\n",
       "      <td>0.237915</td>\n",
       "      <td>0.475607</td>\n",
       "      <td>0.475627</td>\n",
       "      <td>0.145516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_le      y_le      x_re      y_re       x_n       y_n      x_ml  \\\n",
       "0    0.291209  0.333333  0.758242  0.338028  0.521978  0.516432  0.296703   \n",
       "1    0.281690  0.405128  0.753521  0.394872  0.549296  0.625641  0.260563   \n",
       "2    0.214533  0.403023  0.660900  0.397985  0.366782  0.612091  0.235294   \n",
       "3    0.365517  0.391753  0.779310  0.402062  0.648276  0.597938  0.393103   \n",
       "4    0.265625  0.381323  0.734375  0.369650  0.500000  0.603113  0.296875   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "985  0.356364  0.398892  0.821818  0.398892  0.650909  0.617729  0.374545   \n",
       "986  0.274725  0.380952  0.758242  0.373016  0.582418  0.563492  0.362637   \n",
       "987  0.289855  0.373737  0.753623  0.383838  0.521739  0.585859  0.275362   \n",
       "988  0.142857  0.338403  0.614286  0.338403  0.319048  0.593156  0.200000   \n",
       "989  0.280255  0.414596  0.787686  0.413043  0.556263  0.639752  0.280255   \n",
       "\n",
       "         y_ml      x_mr      y_mr  ...  adj_n_ml  sym_le_mr  adj_le_mr  \\\n",
       "0    0.732394  0.730769  0.737089  ...  0.338570   0.596852   0.645365   \n",
       "1    0.723077  0.746479  0.707692  ...  0.318229   0.554593   0.623428   \n",
       "2    0.727960  0.692042  0.722922  ...  0.206456   0.574761   0.648943   \n",
       "3    0.773196  0.758621  0.757732  ...  0.346547   0.537095   0.627927   \n",
       "4    0.747082  0.718750  0.735409  ...  0.279993   0.575064   0.655712   \n",
       "..        ...       ...       ...  ...       ...        ...        ...   \n",
       "985  0.739612  0.785455  0.736842  ...  0.319338   0.546195   0.617197   \n",
       "986  0.777778  0.747253  0.753968  ...  0.369237   0.602016   0.700027   \n",
       "987  0.737374  0.724638  0.747475  ...  0.328573   0.573337   0.690348   \n",
       "988  0.779468  0.557143  0.779468  ...  0.261948   0.605120   0.690476   \n",
       "989  0.729814  0.755839  0.734472  ...  0.302233   0.573150   0.646119   \n",
       "\n",
       "     sym_re_mr  adj_re_mr  sym_n_mr  adj_n_mr  sym_ml_mr  adj_ml_mr  abs_angle  \n",
       "0     0.400006   0.467840  0.303782  0.332088   0.434091   0.434101   0.070471  \n",
       "1     0.312900   0.429635  0.213573  0.227106   0.486159   0.486375   0.029403  \n",
       "2     0.326426   0.447452  0.343624  0.359129   0.456775   0.456800   0.022553  \n",
       "3     0.356271   0.476312  0.194191  0.240590   0.365844   0.366102   0.064427  \n",
       "4     0.366092   0.489833  0.255644  0.281443   0.422036   0.422164   0.044914  \n",
       "..         ...        ...       ...       ...        ...        ...        ...  \n",
       "985   0.339901   0.445124  0.179696  0.206282   0.410918   0.410925   0.124355  \n",
       "986   0.381111   0.527587  0.251896  0.311010   0.385352   0.386026   0.047583  \n",
       "987   0.364790   0.522544  0.259399  0.308120   0.449389   0.449509   0.031240  \n",
       "988   0.444751   0.555329  0.302327  0.333367   0.357143   0.357143   0.020199  \n",
       "989   0.323002   0.440643  0.220912  0.237915   0.475607   0.475627   0.145516  \n",
       "\n",
       "[990 rows x 37 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan penambahan data testing yang berkaitan dengan posisi relatif fitur pada wajah.\n",
    "df_test_1 = pd.read_csv('../input/bdc-sd2021-data-tambahan/test_facial_relative.csv')\n",
    "df_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39a7646d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:14:34.240423Z",
     "iopub.status.busy": "2021-11-04T11:14:34.239664Z",
     "iopub.status.idle": "2021-11-04T11:15:34.320636Z",
     "shell.execute_reply": "2021-11-04T11:15:34.321613Z",
     "shell.execute_reply.started": "2021-11-04T10:10:05.524524Z"
    },
    "papermill": {
     "duration": 60.118143,
     "end_time": "2021-11-04T11:15:34.321936",
     "exception": false,
     "start_time": "2021-11-04T11:14:34.203793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyusun indeks untuk data training dan melakukan shuffle.\n",
    "train_index = list(target_1[target_1['fold'] != fold_index].index)\n",
    "random.seed(seed)\n",
    "random.shuffle(train_index)\n",
    "\n",
    "# Menyusun indeks untuk data validasi.\n",
    "valid_index = list(target_0[target_0['fold'] == fold_index].index)\n",
    "\n",
    "# Memisahkan data validasi dari data training, serta menginisiasi data testing.\n",
    "X_train = df_train.iloc[train_index]\n",
    "X_valid = df_train.iloc[valid_index]\n",
    "X_test = df_test.copy()\n",
    "\n",
    "X_train_1 = df_train_1.iloc[train_index]\n",
    "X_valid_1 = df_train_1.iloc[valid_index]\n",
    "X_test_1 = df_test_1.copy()\n",
    "\n",
    "# Melakukan reduksi dimensi dengan menggunakan PCA.\n",
    "pca = PCA(0.95)\n",
    "X_train = pd.DataFrame(pca.fit_transform(X_train))\n",
    "X_valid = pd.DataFrame(pca.transform(X_valid))\n",
    "X_test = pd.DataFrame(pca.transform(X_test))\n",
    "\n",
    "pca = PCA(0.95)\n",
    "X_train_1 = pd.DataFrame(pca.fit_transform(X_train_1))\n",
    "X_valid_1 = pd.DataFrame(pca.transform(X_valid_1))\n",
    "X_test_1 = pd.DataFrame(pca.transform(X_test_1))\n",
    "\n",
    "# Menggabungkan informasi pada data training, validasi, dan testing.\n",
    "X_train = pd.concat([X_train, X_train_1], axis = 1, ignore_index = True)\n",
    "X_valid = pd.concat([X_valid, X_valid_1], axis = 1, ignore_index = True)\n",
    "X_test = pd.concat([X_test, X_test_1], axis = 1, ignore_index = True)\n",
    "del X_train_1, X_valid_1, X_test_1\n",
    "\n",
    "# Mengubah ukuran data agar sesuai dengan input yang diharapkan oleh model.\n",
    "X_train = X_train.values.reshape(-1, X_train.shape[1], 1).astype('float64')\n",
    "X_valid = X_valid.values.reshape(-1, X_valid.shape[1], 1).astype('float64')\n",
    "X_test = X_test.values.reshape(-1, X_test.shape[1], 1).astype('float64')\n",
    "\n",
    "# Memisahkan target validasi dari target training.\n",
    "y_train = target_1.iloc[train_index, 0].astype('int64')\n",
    "y_valid = target_0.iloc[valid_index, 0].astype('int64')\n",
    "\n",
    "# Membuang informasi yang sudah tidak diperlukan lagi.\n",
    "del df_train, df_test, df_train_1, df_test_1, pca, target_0, target_1, train_index, valid_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b3bc52d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:34.432485Z",
     "iopub.status.busy": "2021-11-04T11:15:34.421749Z",
     "iopub.status.idle": "2021-11-04T11:15:34.435836Z",
     "shell.execute_reply": "2021-11-04T11:15:34.435237Z",
     "shell.execute_reply.started": "2021-11-04T10:34:04.234056Z"
    },
    "papermill": {
     "duration": 0.06413,
     "end_time": "2021-11-04T11:15:34.435997",
     "exception": false,
     "start_time": "2021-11-04T11:15:34.371867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mendefinisikan fungsi untuk mencari parameter terbaik dengan nilai error terkecil.\n",
    "def create_model(trial):\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 5)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-10, 1e-3, log = True)\n",
    "    dropout = trial.suggest_float('dropout', 0.2, 0.5, log = True)\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers-1):\n",
    "        num_hidden = trial.suggest_int('n_units_l{}'.format(i), 32, 256, log = True)\n",
    "        if i:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "            model.add(Dropout(dropout))\n",
    "        else:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(weight_decay),\n",
    "                            input_shape = (X_train.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    num_hidden = trial.suggest_int('n_units_l{}'.format(n_layers-1), 32, 256, log = True)\n",
    "    model.add(Dense(num_hidden,\n",
    "                    activation = 'relu',\n",
    "                    kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "    model.add(Dense(1,\n",
    "                    activation = 'linear',\n",
    "                    kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "    return model\n",
    "\n",
    "def create_optimizer(trial):\n",
    "    kwargs = {}\n",
    "    optimizer_options = ['RMSprop', 'Adam', 'SGD']\n",
    "    optimizer_selected = trial.suggest_categorical('optimizer', optimizer_options)\n",
    "    if optimizer_selected == 'RMSprop':\n",
    "        kwargs['learning_rate'] = trial.suggest_float(\n",
    "            'rmsprop_learning_rate', 1e-5, 1e-1, log=True)\n",
    "        kwargs['decay'] = trial.suggest_float('rmsprop_decay', 0.85, 0.99)\n",
    "        kwargs['momentum'] = trial.suggest_float('rmsprop_momentum', 1e-5, 1e-1, log = True)\n",
    "    elif optimizer_selected == 'Adam':\n",
    "        kwargs['learning_rate'] = trial.suggest_float('adam_learning_rate', 1e-5, 1e-1, log = True)\n",
    "    elif optimizer_selected == 'SGD':\n",
    "        kwargs['learning_rate'] = trial.suggest_float(\n",
    "            'sgd_opt_learning_rate', 1e-5, 1e-1, log=True)\n",
    "        kwargs['momentum'] = trial.suggest_float('sgd_opt_momentum', 1e-5, 1e-1, log = True)\n",
    "    \n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "    return optimizer\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    optimizer = create_optimizer(trial)\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = 'mean_squared_error',\n",
    "                  metrics = ['mse'])\n",
    "    set_seed()\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs = 3,\n",
    "                        validation_data = (X_valid, y_valid),\n",
    "                        verbose = 2,\n",
    "                        steps_per_epoch = X_train.shape[0] // batch_size)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    try:\n",
    "        mse = MSE(y_valid, y_valid_pred)\n",
    "    except ValueError:\n",
    "        mse = 1e+32\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f108475",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:34.493626Z",
     "iopub.status.busy": "2021-11-04T11:15:34.492589Z",
     "iopub.status.idle": "2021-11-04T11:23:36.858757Z",
     "shell.execute_reply": "2021-11-04T11:23:36.859435Z"
    },
    "papermill": {
     "duration": 482.396475,
     "end_time": "2021-11-04T11:23:36.859649",
     "exception": false,
     "start_time": "2021-11-04T11:15:34.463174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:15:34,495]\u001b[0m A new study created in memory with name: no-name-37069104-b2e2-4037-ad76-f67676812d2a\u001b[0m\n",
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   KMP_WARNINGS=0\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_ENABLE_TASK_THROTTLING=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=4\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=false\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=1\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "   OMP_NUM_THREADS: value is not defined\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2021-11-04 11:15:34.557723: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-11-04 11:15:34.832998: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 634.8336 - mse: 634.8301 - val_loss: 423.8717 - val_mse: 423.8681\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 125.6765 - mse: 125.6729 - val_loss: 36.1906 - val_mse: 36.1870\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 40.1108 - mse: 40.1071 - val_loss: 34.7381 - val_mse: 34.7345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:15:49,618]\u001b[0m Trial 0 finished with value: 34.73448750497162 and parameters: {'n_layers': 4, 'weight_decay': 1.3601459990500093e-05, 'dropout': 0.22715517141780636, 'n_units_l0': 61, 'n_units_l1': 255, 'n_units_l2': 41, 'n_units_l3': 46, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 2.4410551066709827e-05, 'sgd_opt_momentum': 1.7150829926878746e-05}. Best is trial 0 with value: 34.73448750497162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 10s - loss: 254.3599 - mse: 254.3587 - val_loss: 35.4346 - val_mse: 35.4334\n",
      "Epoch 2/3\n",
      "57/57 - 9s - loss: 36.6444 - mse: 36.6433 - val_loss: 32.9135 - val_mse: 32.9123\n",
      "Epoch 3/3\n",
      "57/57 - 9s - loss: 34.1625 - mse: 34.1613 - val_loss: 31.4375 - val_mse: 31.4363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:16:17,838]\u001b[0m Trial 1 finished with value: 31.43630854105587 and parameters: {'n_layers': 5, 'weight_decay': 2.069674778352553e-06, 'dropout': 0.2165227444547113, 'n_units_l0': 102, 'n_units_l1': 115, 'n_units_l2': 238, 'n_units_l3': 105, 'n_units_l4': 69, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 6.0309245793449296e-05, 'sgd_opt_momentum': 0.0021618027516387694}. Best is trial 1 with value: 31.43630854105587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 76.3753 - mse: 76.3751 - val_loss: 34.1831 - val_mse: 34.1829\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 31.7772 - mse: 31.7770 - val_loss: 29.9077 - val_mse: 29.9075\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 27.2061 - mse: 27.2059 - val_loss: 38.6936 - val_mse: 38.6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:16:25,787]\u001b[0m Trial 2 finished with value: 38.693349207880566 and parameters: {'n_layers': 3, 'weight_decay': 4.2140608469491625e-07, 'dropout': 0.425181023662834, 'n_units_l0': 146, 'n_units_l1': 36, 'n_units_l2': 129, 'optimizer': 'Adam', 'adam_learning_rate': 0.0029509089780652155}. Best is trial 1 with value: 31.43630854105587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 7s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 2/3\n",
      "57/57 - 6s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 3/3\n",
      "57/57 - 6s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:16:45,461]\u001b[0m Trial 3 finished with value: 1e+32 and parameters: {'n_layers': 4, 'weight_decay': 1.280797128821542e-08, 'dropout': 0.4445600696908863, 'n_units_l0': 108, 'n_units_l1': 247, 'n_units_l2': 80, 'n_units_l3': 41, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.006855869932485577, 'sgd_opt_momentum': 0.03652763447965056}. Best is trial 1 with value: 31.43630854105587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 156.8244 - mse: 156.8236 - val_loss: 34.4153 - val_mse: 34.4145\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 34.9324 - mse: 34.9316 - val_loss: 35.2198 - val_mse: 35.2191\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 32.6407 - mse: 32.6399 - val_loss: 33.5615 - val_mse: 33.5607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:16:55,521]\u001b[0m Trial 4 finished with value: 33.56075167510972 and parameters: {'n_layers': 4, 'weight_decay': 2.869521426120942e-06, 'dropout': 0.2736582989224417, 'n_units_l0': 177, 'n_units_l1': 60, 'n_units_l2': 60, 'n_units_l3': 48, 'optimizer': 'Adam', 'adam_learning_rate': 0.0003587550277569686}. Best is trial 1 with value: 31.43630854105587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:17:09,987]\u001b[0m Trial 5 finished with value: 1e+32 and parameters: {'n_layers': 4, 'weight_decay': 8.671491605192508e-05, 'dropout': 0.2120474687506201, 'n_units_l0': 75, 'n_units_l1': 63, 'n_units_l2': 143, 'n_units_l3': 85, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.012820573397259222, 'sgd_opt_momentum': 0.01219735525440408}. Best is trial 1 with value: 31.43630854105587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 96.6569 - mse: 96.6566 - val_loss: 51.8062 - val_mse: 51.8060\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 47.5060 - mse: 47.5058 - val_loss: 44.3367 - val_mse: 44.3365\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 42.9320 - mse: 42.9318 - val_loss: 42.8384 - val_mse: 42.8382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:17:13,539]\u001b[0m Trial 6 finished with value: 42.83820703611039 and parameters: {'n_layers': 2, 'weight_decay': 1.4490033299339797e-06, 'dropout': 0.4134236878013778, 'n_units_l0': 56, 'n_units_l1': 69, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.0004666904757351211, 'rmsprop_decay': 0.894925822839254, 'rmsprop_momentum': 0.000308450498248823}. Best is trial 1 with value: 31.43630854105587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 51693.7031 - mse: 51693.6797 - val_loss: 95.0701 - val_mse: 95.0516\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 114.4079 - mse: 114.3893 - val_loss: 68.6590 - val_mse: 68.6405\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 87.6211 - mse: 87.6026 - val_loss: 51.5808 - val_mse: 51.5623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:17:24,899]\u001b[0m Trial 7 finished with value: 51.562279684989946 and parameters: {'n_layers': 3, 'weight_decay': 5.713328696681321e-06, 'dropout': 0.3407865362809055, 'n_units_l0': 241, 'n_units_l1': 75, 'n_units_l2': 63, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.019638650422524002, 'rmsprop_decay': 0.9279674621367233, 'rmsprop_momentum': 0.007481765717358807}. Best is trial 1 with value: 31.43630854105587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 7s - loss: 592376.3750 - mse: 592376.3750 - val_loss: 152.1273 - val_mse: 152.1265\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 89.9662 - mse: 89.9654 - val_loss: 496.6796 - val_mse: 496.6787\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 49.3858 - mse: 49.3851 - val_loss: 457.9046 - val_mse: 457.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:17:41,509]\u001b[0m Trial 8 finished with value: 457.90383606235645 and parameters: {'n_layers': 5, 'weight_decay': 2.9653117862224153e-07, 'dropout': 0.3197493177048565, 'n_units_l0': 123, 'n_units_l1': 65, 'n_units_l2': 116, 'n_units_l3': 83, 'n_units_l4': 41, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.019054962911205356, 'rmsprop_decay': 0.874518227528278, 'rmsprop_momentum': 8.371297680962848e-05}. Best is trial 1 with value: 31.43630854105587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 10s - loss: 3393.5132 - mse: 3393.4929 - val_loss: 46.4741 - val_mse: 46.4526\n",
      "Epoch 2/3\n",
      "57/57 - 9s - loss: 46.7461 - mse: 46.7246 - val_loss: 52.9697 - val_mse: 52.9483\n",
      "Epoch 3/3\n",
      "57/57 - 9s - loss: 43.0072 - mse: 42.9857 - val_loss: 48.0517 - val_mse: 48.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:18:10,064]\u001b[0m Trial 9 finished with value: 48.03028401045839 and parameters: {'n_layers': 4, 'weight_decay': 1.0556840099451229e-05, 'dropout': 0.22909938508654398, 'n_units_l0': 72, 'n_units_l1': 170, 'n_units_l2': 172, 'n_units_l3': 167, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.005553572385099785, 'rmsprop_decay': 0.9526963318618572, 'rmsprop_momentum': 3.908613352528237e-05}. Best is trial 1 with value: 31.43630854105587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 15s - loss: 274.1419 - mse: 273.7236 - val_loss: 44.7344 - val_mse: 44.3154\n",
      "Epoch 2/3\n",
      "57/57 - 15s - loss: 43.0074 - mse: 42.5884 - val_loss: 38.6879 - val_mse: 38.2690\n",
      "Epoch 3/3\n",
      "57/57 - 14s - loss: 37.5745 - mse: 37.1556 - val_loss: 35.9418 - val_mse: 35.5229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:18:54,622]\u001b[0m Trial 10 finished with value: 35.52291416349176 and parameters: {'n_layers': 5, 'weight_decay': 0.0005607749803615716, 'dropout': 0.25711182212661465, 'n_units_l0': 37, 'n_units_l1': 125, 'n_units_l2': 249, 'n_units_l3': 250, 'n_units_l4': 134, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 4.155963099092157e-05, 'sgd_opt_momentum': 0.0003658096808836848}. Best is trial 1 with value: 31.43630854105587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 666.5981 - mse: 666.5981 - val_loss: 632.5893 - val_mse: 632.5893\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 538.8043 - mse: 538.8043 - val_loss: 493.5829 - val_mse: 493.5829\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 347.2929 - mse: 347.2929 - val_loss: 299.3513 - val_mse: 299.3513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:19:06,717]\u001b[0m Trial 11 finished with value: 299.3513227897971 and parameters: {'n_layers': 5, 'weight_decay': 1.1843952875855866e-10, 'dropout': 0.2702778531622035, 'n_units_l0': 203, 'n_units_l1': 33, 'n_units_l2': 49, 'n_units_l3': 61, 'n_units_l4': 60, 'optimizer': 'Adam', 'adam_learning_rate': 1.7630844023554656e-05}. Best is trial 1 with value: 31.43630854105587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 12s - loss: 176.8014 - mse: 176.8013 - val_loss: 48.6558 - val_mse: 48.6558\n",
      "Epoch 2/3\n",
      "57/57 - 11s - loss: 37.2086 - mse: 37.2085 - val_loss: 47.9133 - val_mse: 47.9133\n",
      "Epoch 3/3\n",
      "57/57 - 12s - loss: 35.1885 - mse: 35.1884 - val_loss: 45.3208 - val_mse: 45.3208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:19:42,505]\u001b[0m Trial 12 finished with value: 45.3208064216457 and parameters: {'n_layers': 5, 'weight_decay': 3.21608857508737e-08, 'dropout': 0.27386946613903135, 'n_units_l0': 175, 'n_units_l1': 111, 'n_units_l2': 256, 'n_units_l3': 105, 'n_units_l4': 207, 'optimizer': 'Adam', 'adam_learning_rate': 0.00010565943595791708}. Best is trial 1 with value: 31.43630854105587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 8946.6250 - mse: 8946.6211 - val_loss: 33.7755 - val_mse: 33.7725\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 30.2716 - mse: 30.2686 - val_loss: 27.1984 - val_mse: 27.1955\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 29.7833 - mse: 29.7804 - val_loss: 26.3538 - val_mse: 26.3508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:19:48,679]\u001b[0m Trial 13 finished with value: 26.35082871919939 and parameters: {'n_layers': 3, 'weight_decay': 2.607328259877047e-08, 'dropout': 0.20039271841337425, 'n_units_l0': 102, 'n_units_l1': 47, 'n_units_l2': 81, 'optimizer': 'Adam', 'adam_learning_rate': 0.06446082645452265}. Best is trial 13 with value: 26.35082871919939.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 79.0408 - mse: 79.0408 - val_loss: 36.2047 - val_mse: 36.2047\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 34.3139 - mse: 34.3139 - val_loss: 33.1697 - val_mse: 33.1697\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 31.1729 - mse: 31.1729 - val_loss: 33.7390 - val_mse: 33.7390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:19:52,416]\u001b[0m Trial 14 finished with value: 33.73901749049731 and parameters: {'n_layers': 2, 'weight_decay': 2.487724929776922e-09, 'dropout': 0.20888252738428795, 'n_units_l0': 94, 'n_units_l1': 46, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.0003058229563518317, 'sgd_opt_momentum': 0.0008551851734327569}. Best is trial 13 with value: 26.35082871919939.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 1538.1008 - mse: 1538.0967 - val_loss: 26.9734 - val_mse: 26.9689\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 30.2020 - mse: 30.1975 - val_loss: 26.0292 - val_mse: 26.0247\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 28.8581 - mse: 28.8535 - val_loss: 29.4979 - val_mse: 29.4933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:19:59,154]\u001b[0m Trial 15 finished with value: 29.493343754123238 and parameters: {'n_layers': 3, 'weight_decay': 8.181013529817704e-08, 'dropout': 0.20128655724063546, 'n_units_l0': 45, 'n_units_l1': 101, 'n_units_l2': 33, 'optimizer': 'Adam', 'adam_learning_rate': 0.04753843514332544}. Best is trial 13 with value: 26.35082871919939.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 26136.4844 - mse: 26136.4844 - val_loss: 30.6235 - val_mse: 30.6234\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 37.1303 - mse: 37.1302 - val_loss: 26.3093 - val_mse: 26.3092\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 29.4020 - mse: 29.4019 - val_loss: 26.3015 - val_mse: 26.3014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:03,338]\u001b[0m Trial 16 finished with value: 26.301350929034097 and parameters: {'n_layers': 3, 'weight_decay': 9.96925986192978e-10, 'dropout': 0.20070666515891994, 'n_units_l0': 33, 'n_units_l1': 45, 'n_units_l2': 36, 'optimizer': 'Adam', 'adam_learning_rate': 0.09210028229878241}. Best is trial 16 with value: 26.301350929034097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 23060.8418 - mse: 23060.8418 - val_loss: 26.9360 - val_mse: 26.9359\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 32.8262 - mse: 32.8261 - val_loss: 25.6387 - val_mse: 25.6386\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 32.5217 - mse: 32.5216 - val_loss: 29.8719 - val_mse: 29.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:08,336]\u001b[0m Trial 17 finished with value: 29.871781183236113 and parameters: {'n_layers': 3, 'weight_decay': 4.850544857334963e-10, 'dropout': 0.3669793195121413, 'n_units_l0': 34, 'n_units_l1': 45, 'n_units_l2': 87, 'optimizer': 'Adam', 'adam_learning_rate': 0.08225898549473024}. Best is trial 16 with value: 26.301350929034097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 1s - loss: 53.5569 - mse: 53.5569 - val_loss: 37.7420 - val_mse: 37.7420\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 28.6603 - mse: 28.6603 - val_loss: 29.5803 - val_mse: 29.5803\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 25.2900 - mse: 25.2900 - val_loss: 29.7158 - val_mse: 29.7158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:10,957]\u001b[0m Trial 18 finished with value: 29.71581599291893 and parameters: {'n_layers': 2, 'weight_decay': 2.2863701982259663e-09, 'dropout': 0.23997616526591342, 'n_units_l0': 47, 'n_units_l1': 47, 'optimizer': 'Adam', 'adam_learning_rate': 0.007162048235810037}. Best is trial 16 with value: 26.301350929034097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 86.8269 - mse: 86.8269 - val_loss: 36.0617 - val_mse: 36.0617\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 28.6025 - mse: 28.6025 - val_loss: 27.7998 - val_mse: 27.7998\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 25.9565 - mse: 25.9565 - val_loss: 28.0559 - val_mse: 28.0559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:18,310]\u001b[0m Trial 19 finished with value: 28.055894443087965 and parameters: {'n_layers': 3, 'weight_decay': 6.392003966642512e-09, 'dropout': 0.30225315165775285, 'n_units_l0': 78, 'n_units_l1': 86, 'n_units_l2': 32, 'optimizer': 'Adam', 'adam_learning_rate': 0.01236166362000488}. Best is trial 16 with value: 26.301350929034097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 2138.0361 - mse: 2138.0361 - val_loss: 679.2095 - val_mse: 679.2095\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 657.2342 - mse: 657.2342 - val_loss: 625.7754 - val_mse: 625.7754\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 601.5881 - mse: 601.5881 - val_loss: 569.0262 - val_mse: 569.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:23,733]\u001b[0m Trial 20 finished with value: 569.0262638869089 and parameters: {'n_layers': 2, 'weight_decay': 4.715994969828002e-10, 'dropout': 0.24691745434598827, 'n_units_l0': 127, 'n_units_l1': 52, 'optimizer': 'Adam', 'adam_learning_rate': 0.029449839727083912}. Best is trial 16 with value: 26.301350929034097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 86.0600 - mse: 86.0600 - val_loss: 35.2244 - val_mse: 35.2244\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 28.5070 - mse: 28.5070 - val_loss: 26.8738 - val_mse: 26.8738\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 26.6988 - mse: 26.6988 - val_loss: 28.9349 - val_mse: 28.9349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:30,514]\u001b[0m Trial 21 finished with value: 28.934913408745913 and parameters: {'n_layers': 3, 'weight_decay': 6.223370085335233e-09, 'dropout': 0.29659053900479393, 'n_units_l0': 78, 'n_units_l1': 84, 'n_units_l2': 32, 'optimizer': 'Adam', 'adam_learning_rate': 0.01188014813394967}. Best is trial 16 with value: 26.301350929034097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 12079.5215 - mse: 12079.5127 - val_loss: 682.6414 - val_mse: 682.6340\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 649.1901 - mse: 649.1827 - val_loss: 604.1893 - val_mse: 604.1818\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 565.2624 - mse: 565.2548 - val_loss: 517.0289 - val_mse: 517.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:34,970]\u001b[0m Trial 22 finished with value: 517.0213214594507 and parameters: {'n_layers': 3, 'weight_decay': 6.124427129306328e-08, 'dropout': 0.35650680588847766, 'n_units_l0': 59, 'n_units_l1': 39, 'n_units_l2': 46, 'optimizer': 'Adam', 'adam_learning_rate': 0.09785920375579395}. Best is trial 16 with value: 26.301350929034097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 66.4295 - mse: 66.4295 - val_loss: 35.6466 - val_mse: 35.6466\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 28.6821 - mse: 28.6821 - val_loss: 26.8201 - val_mse: 26.8201\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 26.8667 - mse: 26.8667 - val_loss: 26.4166 - val_mse: 26.4166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:39,824]\u001b[0m Trial 23 finished with value: 26.416583020869258 and parameters: {'n_layers': 3, 'weight_decay': 8.276774310863693e-10, 'dropout': 0.301697910549081, 'n_units_l0': 46, 'n_units_l1': 56, 'n_units_l2': 39, 'optimizer': 'Adam', 'adam_learning_rate': 0.01654880293689386}. Best is trial 16 with value: 26.301350929034097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 79.0580 - mse: 79.0580 - val_loss: 37.8795 - val_mse: 37.8795\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 33.5851 - mse: 33.5851 - val_loss: 31.7087 - val_mse: 31.7087\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 27.7371 - mse: 27.7371 - val_loss: 30.2155 - val_mse: 30.2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:44,684]\u001b[0m Trial 24 finished with value: 30.215506775035877 and parameters: {'n_layers': 3, 'weight_decay': 6.926160267996678e-10, 'dropout': 0.47927036650060084, 'n_units_l0': 32, 'n_units_l1': 55, 'n_units_l2': 60, 'optimizer': 'Adam', 'adam_learning_rate': 0.001906397138856184}. Best is trial 16 with value: 26.301350929034097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 1s - loss: 212.0444 - mse: 212.0444 - val_loss: 49.8783 - val_mse: 49.8783\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 41.9881 - mse: 41.9881 - val_loss: 39.8365 - val_mse: 39.8365\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 33.6959 - mse: 33.6959 - val_loss: 33.0034 - val_mse: 33.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:47,768]\u001b[0m Trial 25 finished with value: 33.00339172221071 and parameters: {'n_layers': 2, 'weight_decay': 1.0880254333669598e-09, 'dropout': 0.38881376292396724, 'n_units_l0': 42, 'n_units_l1': 40, 'optimizer': 'Adam', 'adam_learning_rate': 0.021013318874982232}. Best is trial 16 with value: 26.301350929034097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 22998.8672 - mse: 22998.8672 - val_loss: 27.0801 - val_mse: 27.0800\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 30.6605 - mse: 30.6605 - val_loss: 26.8450 - val_mse: 26.8450\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 30.7086 - mse: 30.7086 - val_loss: 26.1930 - val_mse: 26.1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:51,803]\u001b[0m Trial 26 finished with value: 26.19303046346208 and parameters: {'n_layers': 3, 'weight_decay': 1.33094091219024e-10, 'dropout': 0.2229920625842613, 'n_units_l0': 52, 'n_units_l1': 32, 'n_units_l2': 41, 'optimizer': 'Adam', 'adam_learning_rate': 0.09969115687481436}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 4712.0430 - mse: 4712.0430 - val_loss: 678.2220 - val_mse: 678.2220\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 650.4084 - mse: 650.4084 - val_loss: 611.9948 - val_mse: 611.9948\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 580.1085 - mse: 580.1085 - val_loss: 539.3088 - val_mse: 539.3088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:58,815]\u001b[0m Trial 27 finished with value: 539.3088003457544 and parameters: {'n_layers': 4, 'weight_decay': 1.2634722388693204e-10, 'dropout': 0.22482980644959324, 'n_units_l0': 51, 'n_units_l1': 35, 'n_units_l2': 71, 'n_units_l3': 33, 'optimizer': 'Adam', 'adam_learning_rate': 0.052459905685578886}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 17632.0879 - mse: 17632.0859 - val_loss: 28.1525 - val_mse: 28.1504\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 30.1227 - mse: 30.1207 - val_loss: 26.6445 - val_mse: 26.6424\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 29.6788 - mse: 29.6767 - val_loss: 29.0712 - val_mse: 29.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:02,681]\u001b[0m Trial 28 finished with value: 29.06909149847589 and parameters: {'n_layers': 3, 'weight_decay': 2.2111849598105394e-08, 'dropout': 0.20221321385518184, 'n_units_l0': 39, 'n_units_l1': 32, 'n_units_l2': 51, 'optimizer': 'Adam', 'adam_learning_rate': 0.09428372225560808}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 1s - loss: 687.4625 - mse: 687.4625 - val_loss: 680.2941 - val_mse: 680.2941\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 683.0707 - mse: 683.0707 - val_loss: 678.3441 - val_mse: 678.3441\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 681.5997 - mse: 681.5997 - val_loss: 677.2025 - val_mse: 677.2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:05,865]\u001b[0m Trial 29 finished with value: 677.2024937297424 and parameters: {'n_layers': 2, 'weight_decay': 2.1332822085773946e-10, 'dropout': 0.2297773744778781, 'n_units_l0': 68, 'n_units_l1': 47, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 1.0402760173150245e-05, 'rmsprop_decay': 0.9897512076033865, 'rmsprop_momentum': 0.06878114980550995}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 86.4393 - mse: 86.4393 - val_loss: 32.5724 - val_mse: 32.5724\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 29.7739 - mse: 29.7739 - val_loss: 28.0393 - val_mse: 28.0393\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 26.2797 - mse: 26.2797 - val_loss: 34.0750 - val_mse: 34.0750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:12,170]\u001b[0m Trial 30 finished with value: 34.07497822663281 and parameters: {'n_layers': 3, 'weight_decay': 3.2329504509028435e-09, 'dropout': 0.24109646796800954, 'n_units_l0': 87, 'n_units_l1': 42, 'n_units_l2': 100, 'optimizer': 'Adam', 'adam_learning_rate': 0.006697972724085538}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 189.5239 - mse: 189.5239 - val_loss: 30.4061 - val_mse: 30.4061\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 29.5134 - mse: 29.5134 - val_loss: 26.7644 - val_mse: 26.7644\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 27.9433 - mse: 27.9433 - val_loss: 36.5033 - val_mse: 36.5033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:16,905]\u001b[0m Trial 31 finished with value: 36.50331583206722 and parameters: {'n_layers': 3, 'weight_decay': 3.1552359609892795e-10, 'dropout': 0.22103333604665668, 'n_units_l0': 38, 'n_units_l1': 56, 'n_units_l2': 40, 'optimizer': 'Adam', 'adam_learning_rate': 0.028037694056998148}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 142.1580 - mse: 142.1580 - val_loss: 34.1614 - val_mse: 34.1614\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 30.5939 - mse: 30.5939 - val_loss: 27.9637 - val_mse: 27.9637\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 29.6139 - mse: 29.6139 - val_loss: 31.5543 - val_mse: 31.5543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:21,822]\u001b[0m Trial 32 finished with value: 31.554264653402154 and parameters: {'n_layers': 3, 'weight_decay': 1.2870327215604745e-09, 'dropout': 0.2175194288970339, 'n_units_l0': 52, 'n_units_l1': 39, 'n_units_l2': 39, 'optimizer': 'Adam', 'adam_learning_rate': 0.03153411772702817}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 2583.6958 - mse: 2583.6890 - val_loss: 32.7852 - val_mse: 32.7774\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 29.2337 - mse: 29.2259 - val_loss: 27.2143 - val_mse: 27.2065\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 28.3801 - mse: 28.3723 - val_loss: 31.1272 - val_mse: 31.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:26,891]\u001b[0m Trial 33 finished with value: 31.11943809326196 and parameters: {'n_layers': 3, 'weight_decay': 2.477590450161284e-07, 'dropout': 0.2044577066067441, 'n_units_l0': 60, 'n_units_l1': 54, 'n_units_l2': 38, 'optimizer': 'Adam', 'adam_learning_rate': 0.04858184621852765}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 331.8829 - mse: 331.8828 - val_loss: 32.1197 - val_mse: 32.1196\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 32.5853 - mse: 32.5852 - val_loss: 27.7802 - val_mse: 27.7800\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 29.4717 - mse: 29.4716 - val_loss: 32.5908 - val_mse: 32.5906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:35,474]\u001b[0m Trial 34 finished with value: 32.59063151139894 and parameters: {'n_layers': 4, 'weight_decay': 6.9217653773653725e-09, 'dropout': 0.24840512174306031, 'n_units_l0': 46, 'n_units_l1': 36, 'n_units_l2': 52, 'n_units_l3': 165, 'optimizer': 'Adam', 'adam_learning_rate': 0.01842057963852743}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:39,913]\u001b[0m Trial 35 finished with value: 1e+32 and parameters: {'n_layers': 3, 'weight_decay': 1.262779528370658e-09, 'dropout': 0.25926439594163686, 'n_units_l0': 112, 'n_units_l1': 32, 'n_units_l2': 44, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.06629357743341274, 'sgd_opt_momentum': 1.759872564543093e-05}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 40052.0000 - mse: 40051.9961 - val_loss: 703.9713 - val_mse: 703.9652\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 687.0010 - mse: 686.9951 - val_loss: 659.7087 - val_mse: 659.7026\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 637.6628 - mse: 637.6569 - val_loss: 606.2416 - val_mse: 606.2357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:47,307]\u001b[0m Trial 36 finished with value: 606.2355875625649 and parameters: {'n_layers': 4, 'weight_decay': 1.4752694588112887e-08, 'dropout': 0.21476899205644603, 'n_units_l0': 35, 'n_units_l1': 51, 'n_units_l2': 37, 'n_units_l3': 159, 'optimizer': 'Adam', 'adam_learning_rate': 0.09416343924547677}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 114.8148 - mse: 114.8148 - val_loss: 39.9766 - val_mse: 39.9766\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 36.3612 - mse: 36.3612 - val_loss: 35.2906 - val_mse: 35.2906\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 33.4078 - mse: 33.4078 - val_loss: 32.5724 - val_mse: 32.5724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:53,984]\u001b[0m Trial 37 finished with value: 32.57235883231018 and parameters: {'n_layers': 3, 'weight_decay': 2.5387144573985014e-10, 'dropout': 0.28600738290346134, 'n_units_l0': 42, 'n_units_l1': 75, 'n_units_l2': 54, 'optimizer': 'Adam', 'adam_learning_rate': 0.00045746631207427014}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 139.6436 - mse: 139.6436 - val_loss: 173.4093 - val_mse: 173.4093\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 107.7605 - mse: 107.7605 - val_loss: 64.6025 - val_mse: 64.6025\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 98.9663 - mse: 98.9662 - val_loss: 142.1221 - val_mse: 142.1221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:00,159]\u001b[0m Trial 38 finished with value: 142.12210866127907 and parameters: {'n_layers': 2, 'weight_decay': 8.60568096216635e-08, 'dropout': 0.32341636299189913, 'n_units_l0': 144, 'n_units_l1': 60, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.001084841011086213, 'sgd_opt_momentum': 0.0001018170720602631}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 10s - loss: 117.1389 - mse: 117.1389 - val_loss: 31.4198 - val_mse: 31.4198\n",
      "Epoch 2/3\n",
      "57/57 - 9s - loss: 30.4877 - mse: 30.4877 - val_loss: 26.3839 - val_mse: 26.3839\n",
      "Epoch 3/3\n",
      "57/57 - 9s - loss: 27.4409 - mse: 27.4409 - val_loss: 31.0816 - val_mse: 31.0816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:28,503]\u001b[0m Trial 39 finished with value: 31.081647603482207 and parameters: {'n_layers': 4, 'weight_decay': 1.0294176742586245e-10, 'dropout': 0.2347540391173023, 'n_units_l0': 66, 'n_units_l1': 37, 'n_units_l2': 205, 'n_units_l3': 251, 'optimizer': 'Adam', 'adam_learning_rate': 0.006144326830334085}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 664.9351 - mse: 664.9349 - val_loss: 650.6103 - val_mse: 650.6102\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 652.4896 - mse: 652.4893 - val_loss: 645.0192 - val_mse: 645.0190\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 648.4366 - mse: 648.4365 - val_loss: 641.7587 - val_mse: 641.7585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:33,604]\u001b[0m Trial 40 finished with value: 641.7585296555244 and parameters: {'n_layers': 3, 'weight_decay': 1.0460573202023051e-06, 'dropout': 0.21485154737974854, 'n_units_l0': 87, 'n_units_l1': 43, 'n_units_l2': 43, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 6.910158370414252e-05, 'rmsprop_decay': 0.8517099743481978, 'rmsprop_momentum': 0.00432600269098558}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 154.5115 - mse: 154.5115 - val_loss: 28.7549 - val_mse: 28.7549\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 29.9272 - mse: 29.9271 - val_loss: 27.1120 - val_mse: 27.1120\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 29.4352 - mse: 29.4351 - val_loss: 37.0325 - val_mse: 37.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:41,060]\u001b[0m Trial 41 finished with value: 37.0325010774691 and parameters: {'n_layers': 3, 'weight_decay': 6.4176592759431705e-09, 'dropout': 0.3045267963269722, 'n_units_l0': 99, 'n_units_l1': 83, 'n_units_l2': 34, 'optimizer': 'Adam', 'adam_learning_rate': 0.019483185129666222}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 65.8135 - mse: 65.8135 - val_loss: 32.8901 - val_mse: 32.8901\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 28.1047 - mse: 28.1047 - val_loss: 26.5368 - val_mse: 26.5368\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 26.8617 - mse: 26.8617 - val_loss: 26.8991 - val_mse: 26.8991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:47,565]\u001b[0m Trial 42 finished with value: 26.899102191426113 and parameters: {'n_layers': 3, 'weight_decay': 3.4496492647564097e-09, 'dropout': 0.33683866800779977, 'n_units_l0': 81, 'n_units_l1': 73, 'n_units_l2': 36, 'optimizer': 'Adam', 'adam_learning_rate': 0.011305051256069015}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 1876.2394 - mse: 1876.2393 - val_loss: 32.3108 - val_mse: 32.3107\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 29.2633 - mse: 29.2631 - val_loss: 27.1180 - val_mse: 27.1179\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 28.9248 - mse: 28.9247 - val_loss: 28.9031 - val_mse: 28.9030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:53,240]\u001b[0m Trial 43 finished with value: 28.902959148419875 and parameters: {'n_layers': 3, 'weight_decay': 2.8760332376919667e-09, 'dropout': 0.33260702150628657, 'n_units_l0': 55, 'n_units_l1': 68, 'n_units_l2': 37, 'optimizer': 'Adam', 'adam_learning_rate': 0.04976526047657166}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 1673.2140 - mse: 1673.2140 - val_loss: 68.5985 - val_mse: 68.5984\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 38.4452 - mse: 38.4452 - val_loss: 28.1302 - val_mse: 28.1301\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 30.8657 - mse: 30.8657 - val_loss: 34.4197 - val_mse: 34.4197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:59,393]\u001b[0m Trial 44 finished with value: 34.419647770948266 and parameters: {'n_layers': 3, 'weight_decay': 7.508425293667419e-10, 'dropout': 0.3868131837146298, 'n_units_l0': 32, 'n_units_l1': 76, 'n_units_l2': 44, 'optimizer': 'Adam', 'adam_learning_rate': 0.04382299744067572}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 73.7199 - mse: 73.7199 - val_loss: 32.9917 - val_mse: 32.9916\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 30.9858 - mse: 30.9858 - val_loss: 30.9279 - val_mse: 30.9279\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 26.8004 - mse: 26.8004 - val_loss: 35.8446 - val_mse: 35.8446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:06,304]\u001b[0m Trial 45 finished with value: 35.84455494097453 and parameters: {'n_layers': 3, 'weight_decay': 2.915333031968692e-08, 'dropout': 0.3514936850216254, 'n_units_l0': 106, 'n_units_l1': 59, 'n_units_l2': 68, 'optimizer': 'Adam', 'adam_learning_rate': 0.0027341333591559274}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 71376152.0000 - mse: 71376152.0000 - val_loss: 633.4423 - val_mse: 633.4422\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 112.8138 - mse: 112.8137 - val_loss: 612.7665 - val_mse: 612.7665\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 104.3169 - mse: 104.3168 - val_loss: 583.3986 - val_mse: 583.3986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:13,951]\u001b[0m Trial 46 finished with value: 583.3985530986616 and parameters: {'n_layers': 4, 'weight_decay': 1.860661280599323e-09, 'dropout': 0.20975371540400095, 'n_units_l0': 67, 'n_units_l1': 66, 'n_units_l2': 36, 'n_units_l3': 59, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.08444363716563694, 'rmsprop_decay': 0.9872116445810203, 'rmsprop_momentum': 0.08704476593468345}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 124.3268 - mse: 124.3092 - val_loss: 91.4237 - val_mse: 91.4062\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 62.5984 - mse: 62.5809 - val_loss: 31.0082 - val_mse: 30.9908\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 37.3628 - mse: 37.3453 - val_loss: 55.7076 - val_mse: 55.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:20,434]\u001b[0m Trial 47 finished with value: 55.69003613313211 and parameters: {'n_layers': 3, 'weight_decay': 9.392166421144212e-05, 'dropout': 0.4280342678722083, 'n_units_l0': 125, 'n_units_l1': 49, 'n_units_l2': 56, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.0006972184825879552, 'sgd_opt_momentum': 0.09758246992813781}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 159.2350 - mse: 159.2350 - val_loss: 48.9137 - val_mse: 48.9137\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 39.7862 - mse: 39.7862 - val_loss: 38.3711 - val_mse: 38.3711\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 33.2939 - mse: 33.2939 - val_loss: 33.6667 - val_mse: 33.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:24,910]\u001b[0m Trial 48 finished with value: 33.66672663148164 and parameters: {'n_layers': 2, 'weight_decay': 3.0126154066964726e-10, 'dropout': 0.2834272704930574, 'n_units_l0': 50, 'n_units_l1': 135, 'optimizer': 'Adam', 'adam_learning_rate': 0.011314213105170773}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 55775.4453 - mse: 55775.4453 - val_loss: 29.4947 - val_mse: 29.4925\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 30.3358 - mse: 30.3335 - val_loss: 26.9976 - val_mse: 26.9954\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 29.9458 - mse: 29.9435 - val_loss: 30.7757 - val_mse: 30.7734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:36,853]\u001b[0m Trial 49 finished with value: 30.773422743171214 and parameters: {'n_layers': 3, 'weight_decay': 1.0521367324548371e-08, 'dropout': 0.20018145443371368, 'n_units_l0': 145, 'n_units_l1': 99, 'n_units_l2': 77, 'optimizer': 'Adam', 'adam_learning_rate': 0.06227992763119252}. Best is trial 26 with value: 26.19303046346208.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Mencari hyperparameters terbaik.\n",
    "try:\n",
    "    study = optuna.create_study(sampler = TPESampler(seed = seed), direction = 'minimize')\n",
    "    study.optimize(objective, n_trials = 50)\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b151ecb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:23:37.132018Z",
     "iopub.status.busy": "2021-11-04T11:23:37.131030Z",
     "iopub.status.idle": "2021-11-04T11:23:37.137061Z",
     "shell.execute_reply": "2021-11-04T11:23:37.137759Z",
     "shell.execute_reply.started": "2021-11-04T10:25:54.753997Z"
    },
    "papermill": {
     "duration": 0.14288,
     "end_time": "2021-11-04T11:23:37.137936",
     "exception": false,
     "start_time": "2021-11-04T11:23:36.995056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 3,\n",
       " 'weight_decay': 1.33094091219024e-10,\n",
       " 'dropout': 0.2229920625842613,\n",
       " 'n_units_l0': 52,\n",
       " 'n_units_l1': 32,\n",
       " 'n_units_l2': 41,\n",
       " 'optimizer': 'Adam',\n",
       " 'adam_learning_rate': 0.09969115687481436}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan parameter-parameter terbaik.\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f831351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:23:37.408152Z",
     "iopub.status.busy": "2021-11-04T11:23:37.407073Z",
     "iopub.status.idle": "2021-11-04T11:23:37.421368Z",
     "shell.execute_reply": "2021-11-04T11:23:37.421966Z",
     "shell.execute_reply.started": "2021-11-04T10:26:02.784876Z"
    },
    "papermill": {
     "duration": 0.150981,
     "end_time": "2021-11-04T11:23:37.422144",
     "exception": false,
     "start_time": "2021-11-04T11:23:37.271163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Membangun model.\n",
    "def prepare_model():\n",
    "    model = Sequential(name = 'Sequential')\n",
    "    n_layers = study.best_params['n_layers']\n",
    "    for i in range(n_layers-1):\n",
    "        num_hidden = study.best_params['n_units_l{}'.format(i)]\n",
    "        if i:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                            name = 'Dense_{}'.format(i)))\n",
    "            model.add(Dropout(study.best_params['dropout'],\n",
    "                              name = 'Dropout_{}'.format(i)))\n",
    "        else:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                            input_shape = (X_train.shape[1], 1),\n",
    "                            name = 'Dense_{}'.format(i)))\n",
    "    model.add(Flatten(name = 'Flatten'))\n",
    "    num_hidden = study.best_params['n_units_l{}'.format(n_layers-1)]\n",
    "    model.add(Dense(num_hidden,\n",
    "                    activation = 'relu',\n",
    "                    kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                    name = 'Dense_{}'.format(n_layers-1)))\n",
    "    model.add(Dense(1,\n",
    "                    activation = 'linear',\n",
    "                    kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                    name = 'Final_Dense'))\n",
    "    \n",
    "    # Mendefinisikan optimizer.\n",
    "    kwargs = {}\n",
    "    optimizer_selected = study.best_params['optimizer']\n",
    "    if optimizer_selected == 'RMSprop':\n",
    "        kwargs['learning_rate'] = study.best_params['rmsprop_learning_rate']\n",
    "        kwargs['decay'] = study.best_params['rmsprop_decay']\n",
    "        kwargs['momentum'] = study.best_params['rmsprop_momentum']\n",
    "    elif optimizer_selected == 'Adam':\n",
    "        kwargs['learning_rate'] = study.best_params['adam_learning_rate']\n",
    "    elif optimizer_selected == 'SGD':\n",
    "        kwargs['learning_rate'] = study.best_params['sgd_opt_learning_rate']\n",
    "        kwargs['momentum'] = study.best_params['sgd_opt_momentum']    \n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "    \n",
    "    # Mengkompilasi model.\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = 'mean_squared_error',\n",
    "                  metrics = ['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6ded6fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:23:37.694742Z",
     "iopub.status.busy": "2021-11-04T11:23:37.694059Z",
     "iopub.status.idle": "2021-11-04T11:23:37.772884Z",
     "shell.execute_reply": "2021-11-04T11:23:37.772318Z",
     "shell.execute_reply.started": "2021-11-04T10:26:07.607163Z"
    },
    "papermill": {
     "duration": 0.217412,
     "end_time": "2021-11-04T11:23:37.773039",
     "exception": false,
     "start_time": "2021-11-04T11:23:37.555627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_0 (Dense)              (None, 269, 52)           104       \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 269, 32)           1696      \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 269, 32)           0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 8608)              0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 41)                352969    \n",
      "_________________________________________________________________\n",
      "Final_Dense (Dense)          (None, 1)                 42        \n",
      "=================================================================\n",
      "Total params: 354,811\n",
      "Trainable params: 354,811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan ringkasan dari model.\n",
    "model = prepare_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "083e8301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:23:38.047980Z",
     "iopub.status.busy": "2021-11-04T11:23:38.047306Z",
     "iopub.status.idle": "2021-11-04T11:23:38.049749Z",
     "shell.execute_reply": "2021-11-04T11:23:38.050204Z",
     "shell.execute_reply.started": "2021-11-04T10:26:14.472587Z"
    },
    "papermill": {
     "duration": 0.142524,
     "end_time": "2021-11-04T11:23:38.050385",
     "exception": false,
     "start_time": "2021-11-04T11:23:37.907861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menetapkan batasan untuk berhenti melanjutkan epoch lebih awal.\n",
    "earlystop = EarlyStopping(patience = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebd629f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:23:38.322416Z",
     "iopub.status.busy": "2021-11-04T11:23:38.321743Z",
     "iopub.status.idle": "2021-11-04T11:23:38.324152Z",
     "shell.execute_reply": "2021-11-04T11:23:38.323514Z",
     "shell.execute_reply.started": "2021-11-04T10:26:17.623786Z"
    },
    "papermill": {
     "duration": 0.14041,
     "end_time": "2021-11-04T11:23:38.324290",
     "exception": false,
     "start_time": "2021-11-04T11:23:38.183880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menetapkan batasan untuk learning rate.\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_mse', \n",
    "                                            patience = 8,\n",
    "                                            verbose = 1,\n",
    "                                            factor = 0.5,\n",
    "                                            mode = 'min',\n",
    "                                            min_lr = 1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3c498a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:23:38.601301Z",
     "iopub.status.busy": "2021-11-04T11:23:38.597795Z",
     "iopub.status.idle": "2021-11-04T11:23:38.603853Z",
     "shell.execute_reply": "2021-11-04T11:23:38.604326Z",
     "shell.execute_reply.started": "2021-11-04T10:26:20.705731Z"
    },
    "papermill": {
     "duration": 0.145348,
     "end_time": "2021-11-04T11:23:38.604507",
     "exception": false,
     "start_time": "2021-11-04T11:23:38.459159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Membentuk kelas guna menyimpan output prediksi validasi dan testing untuk setiap epoch.\n",
    "class Metrics(Callback):\n",
    "    def __init__(self, valid_data, test_data):\n",
    "        super().__init__()\n",
    "        self.valid_data = valid_data\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_valid_pred = self.model.predict(self.valid_data)\n",
    "        y_test_pred = self.model.predict(self.test_data)\n",
    "        pd.DataFrame(y_valid_pred).to_csv('valid_preds_{}.csv'.format(epoch), index = False)\n",
    "        pd.DataFrame(y_test_pred).to_csv('test_preds_{}.csv'.format(epoch), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ab2c5b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:23:38.886452Z",
     "iopub.status.busy": "2021-11-04T11:23:38.885777Z",
     "iopub.status.idle": "2021-11-04T11:24:40.495347Z",
     "shell.execute_reply": "2021-11-04T11:24:40.495887Z",
     "shell.execute_reply.started": "2021-11-04T10:26:23.335319Z"
    },
    "papermill": {
     "duration": 61.757436,
     "end_time": "2021-11-04T11:24:40.496071",
     "exception": false,
     "start_time": "2021-11-04T11:23:38.738635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "57/57 - 2s - loss: 22998.8672 - mse: 22998.8672 - val_loss: 27.0801 - val_mse: 27.0800\n",
      "Epoch 2/128\n",
      "57/57 - 1s - loss: 30.6605 - mse: 30.6605 - val_loss: 26.8450 - val_mse: 26.8450\n",
      "Epoch 3/128\n",
      "57/57 - 1s - loss: 30.7086 - mse: 30.7086 - val_loss: 26.1930 - val_mse: 26.1930\n",
      "Epoch 4/128\n",
      "57/57 - 1s - loss: 30.9573 - mse: 30.9573 - val_loss: 36.6366 - val_mse: 36.6366\n",
      "Epoch 5/128\n",
      "57/57 - 1s - loss: 31.6681 - mse: 31.6681 - val_loss: 35.6867 - val_mse: 35.6867\n",
      "Epoch 6/128\n",
      "57/57 - 1s - loss: 31.2319 - mse: 31.2319 - val_loss: 27.4254 - val_mse: 27.4254\n",
      "Epoch 7/128\n",
      "57/57 - 1s - loss: 31.3840 - mse: 31.3840 - val_loss: 26.6730 - val_mse: 26.6729\n",
      "Epoch 8/128\n",
      "57/57 - 1s - loss: 30.3655 - mse: 30.3655 - val_loss: 26.4251 - val_mse: 26.4251\n",
      "Epoch 9/128\n",
      "57/57 - 1s - loss: 32.4921 - mse: 32.4921 - val_loss: 31.6085 - val_mse: 31.6085\n",
      "Epoch 10/128\n",
      "57/57 - 1s - loss: 31.7576 - mse: 31.7576 - val_loss: 31.4718 - val_mse: 31.4718\n",
      "Epoch 11/128\n",
      "57/57 - 1s - loss: 28.9296 - mse: 28.9296 - val_loss: 26.6449 - val_mse: 26.6448\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.049845580011606216.\n",
      "Epoch 12/128\n",
      "57/57 - 1s - loss: 28.5789 - mse: 28.5789 - val_loss: 29.2202 - val_mse: 29.2202\n",
      "Epoch 13/128\n",
      "57/57 - 1s - loss: 30.8810 - mse: 30.8810 - val_loss: 27.0611 - val_mse: 27.0611\n",
      "Epoch 14/128\n",
      "57/57 - 1s - loss: 29.0384 - mse: 29.0384 - val_loss: 27.9688 - val_mse: 27.9688\n",
      "Epoch 15/128\n",
      "57/57 - 1s - loss: 27.3532 - mse: 27.3532 - val_loss: 25.4857 - val_mse: 25.4857\n",
      "Epoch 16/128\n",
      "57/57 - 1s - loss: 28.9340 - mse: 28.9340 - val_loss: 30.5706 - val_mse: 30.5705\n",
      "Epoch 17/128\n",
      "57/57 - 1s - loss: 28.8160 - mse: 28.8160 - val_loss: 25.8123 - val_mse: 25.8122\n",
      "Epoch 18/128\n",
      "57/57 - 1s - loss: 27.9957 - mse: 27.9957 - val_loss: 26.1733 - val_mse: 26.1732\n",
      "Epoch 19/128\n",
      "57/57 - 1s - loss: 27.8259 - mse: 27.8259 - val_loss: 27.4437 - val_mse: 27.4437\n",
      "Epoch 20/128\n",
      "57/57 - 1s - loss: 29.5130 - mse: 29.5130 - val_loss: 26.3613 - val_mse: 26.3613\n",
      "Epoch 21/128\n",
      "57/57 - 1s - loss: 30.1733 - mse: 30.1733 - val_loss: 26.2107 - val_mse: 26.2107\n",
      "Epoch 22/128\n",
      "57/57 - 2s - loss: 27.2439 - mse: 27.2439 - val_loss: 31.1613 - val_mse: 31.1612\n",
      "Epoch 23/128\n",
      "57/57 - 1s - loss: 29.7083 - mse: 29.7083 - val_loss: 29.1010 - val_mse: 29.1009\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.024922790005803108.\n",
      "Epoch 24/128\n",
      "57/57 - 1s - loss: 27.1452 - mse: 27.1452 - val_loss: 26.7360 - val_mse: 26.7360\n",
      "Epoch 25/128\n",
      "57/57 - 1s - loss: 26.6755 - mse: 26.6755 - val_loss: 26.2508 - val_mse: 26.2508\n",
      "Epoch 26/128\n",
      "57/57 - 1s - loss: 26.7586 - mse: 26.7586 - val_loss: 26.3829 - val_mse: 26.3829\n",
      "Epoch 27/128\n",
      "57/57 - 1s - loss: 27.2758 - mse: 27.2758 - val_loss: 29.3723 - val_mse: 29.3722\n",
      "Epoch 28/128\n",
      "57/57 - 1s - loss: 27.7802 - mse: 27.7802 - val_loss: 26.8231 - val_mse: 26.8231\n",
      "Epoch 29/128\n",
      "57/57 - 1s - loss: 26.8865 - mse: 26.8865 - val_loss: 27.2888 - val_mse: 27.2888\n",
      "Epoch 30/128\n",
      "57/57 - 1s - loss: 26.8162 - mse: 26.8162 - val_loss: 27.7675 - val_mse: 27.7675\n",
      "Epoch 31/128\n",
      "57/57 - 1s - loss: 26.3759 - mse: 26.3758 - val_loss: 27.2617 - val_mse: 27.2617\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.012461395002901554.\n",
      "Epoch 32/128\n",
      "57/57 - 1s - loss: 26.1930 - mse: 26.1930 - val_loss: 27.7297 - val_mse: 27.7296\n",
      "Epoch 33/128\n",
      "57/57 - 1s - loss: 26.3472 - mse: 26.3472 - val_loss: 26.5283 - val_mse: 26.5283\n",
      "Epoch 34/128\n",
      "57/57 - 1s - loss: 26.3374 - mse: 26.3373 - val_loss: 26.7090 - val_mse: 26.7089\n",
      "Epoch 35/128\n",
      "57/57 - 1s - loss: 25.8683 - mse: 25.8683 - val_loss: 26.6459 - val_mse: 26.6459\n",
      "Epoch 36/128\n",
      "57/57 - 1s - loss: 26.2814 - mse: 26.2814 - val_loss: 27.3606 - val_mse: 27.3606\n",
      "Epoch 37/128\n",
      "57/57 - 1s - loss: 25.4403 - mse: 25.4403 - val_loss: 26.5987 - val_mse: 26.5987\n",
      "Epoch 38/128\n",
      "57/57 - 1s - loss: 25.8085 - mse: 25.8085 - val_loss: 26.6755 - val_mse: 26.6755\n",
      "Epoch 39/128\n",
      "57/57 - 1s - loss: 26.6688 - mse: 26.6688 - val_loss: 26.5939 - val_mse: 26.5938\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.006230697501450777.\n",
      "Epoch 40/128\n",
      "57/57 - 1s - loss: 25.4433 - mse: 25.4433 - val_loss: 26.5618 - val_mse: 26.5618\n",
      "Epoch 41/128\n",
      "57/57 - 1s - loss: 26.1828 - mse: 26.1828 - val_loss: 26.6005 - val_mse: 26.6005\n",
      "Epoch 42/128\n",
      "57/57 - 1s - loss: 25.8257 - mse: 25.8256 - val_loss: 27.8963 - val_mse: 27.8963\n",
      "Epoch 43/128\n",
      "57/57 - 1s - loss: 25.8301 - mse: 25.8301 - val_loss: 26.7024 - val_mse: 26.7024\n",
      "Epoch 44/128\n",
      "57/57 - 1s - loss: 25.3889 - mse: 25.3888 - val_loss: 29.8454 - val_mse: 29.8454\n",
      "Epoch 45/128\n",
      "57/57 - 1s - loss: 25.4285 - mse: 25.4285 - val_loss: 26.8817 - val_mse: 26.8816\n",
      "Epoch 46/128\n",
      "57/57 - 1s - loss: 25.5144 - mse: 25.5144 - val_loss: 26.6990 - val_mse: 26.6989\n",
      "Epoch 47/128\n",
      "57/57 - 1s - loss: 25.4738 - mse: 25.4738 - val_loss: 27.7810 - val_mse: 27.7810\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0031153487507253885.\n",
      "Epoch 48/128\n",
      "57/57 - 1s - loss: 24.9670 - mse: 24.9670 - val_loss: 26.8031 - val_mse: 26.8031\n",
      "Epoch 49/128\n",
      "57/57 - 1s - loss: 25.3341 - mse: 25.3341 - val_loss: 26.8502 - val_mse: 26.8502\n",
      "Epoch 50/128\n",
      "57/57 - 1s - loss: 25.1561 - mse: 25.1561 - val_loss: 26.5632 - val_mse: 26.5632\n",
      "Epoch 51/128\n",
      "57/57 - 2s - loss: 25.2949 - mse: 25.2949 - val_loss: 26.7484 - val_mse: 26.7483\n",
      "Epoch 52/128\n",
      "57/57 - 1s - loss: 25.1540 - mse: 25.1540 - val_loss: 26.8582 - val_mse: 26.8582\n",
      "Epoch 53/128\n",
      "57/57 - 1s - loss: 25.2123 - mse: 25.2123 - val_loss: 26.7354 - val_mse: 26.7354\n",
      "Epoch 54/128\n",
      "57/57 - 1s - loss: 25.3345 - mse: 25.3345 - val_loss: 26.6930 - val_mse: 26.6930\n",
      "Epoch 55/128\n",
      "57/57 - 1s - loss: 25.4248 - mse: 25.4248 - val_loss: 26.5677 - val_mse: 26.5677\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0015576743753626943.\n"
     ]
    }
   ],
   "source": [
    "# Melakukan fitting model.\n",
    "set_seed()\n",
    "model = prepare_model()\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                    verbose = 2,\n",
    "                    steps_per_epoch = X_train.shape[0] // batch_size,\n",
    "                    callbacks = [earlystop,\n",
    "                                 learning_rate_reduction,\n",
    "                                 Metrics(X_valid,\n",
    "                                         X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c675de6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:24:40.835458Z",
     "iopub.status.busy": "2021-11-04T11:24:40.834839Z",
     "iopub.status.idle": "2021-11-04T11:24:42.127553Z",
     "shell.execute_reply": "2021-11-04T11:24:42.126972Z",
     "shell.execute_reply.started": "2021-11-04T08:32:50.263585Z"
    },
    "papermill": {
     "duration": 1.462926,
     "end_time": "2021-11-04T11:24:42.127708",
     "exception": false,
     "start_time": "2021-11-04T11:24:40.664782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Melakukan visualisasi nilai MSE pada data training dan testing.\n",
    "fig, ax = plt.subplots(1, 1, figsize = (12, 12))\n",
    "ax.plot(history.history['mse'], color='b', label = 'training MSE')\n",
    "ax.plot(history.history['val_mse'], color='r', label = 'validation MSE')\n",
    "ax.set_xticks(np.arange(1, epochs, 1))\n",
    "legend = plt.legend(loc = 'best', shadow = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9da967d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:24:42.518105Z",
     "iopub.status.busy": "2021-11-04T11:24:42.498155Z",
     "iopub.status.idle": "2021-11-04T11:24:42.521505Z",
     "shell.execute_reply": "2021-11-04T11:24:42.522015Z",
     "shell.execute_reply.started": "2021-11-04T05:26:23.068789Z"
    },
    "papermill": {
     "duration": 0.225066,
     "end_time": "2021-11-04T11:24:42.522189",
     "exception": false,
     "start_time": "2021-11-04T11:24:42.297123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>27.353174</td>\n",
       "      <td>27.353170</td>\n",
       "      <td>25.485693</td>\n",
       "      <td>25.485682</td>\n",
       "      <td>0.049846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>28.815987</td>\n",
       "      <td>28.815981</td>\n",
       "      <td>25.812254</td>\n",
       "      <td>25.812239</td>\n",
       "      <td>0.049846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>27.995691</td>\n",
       "      <td>27.995678</td>\n",
       "      <td>26.173250</td>\n",
       "      <td>26.173239</td>\n",
       "      <td>0.049846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>30.708574</td>\n",
       "      <td>30.708567</td>\n",
       "      <td>26.193041</td>\n",
       "      <td>26.193031</td>\n",
       "      <td>0.099691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>30.173267</td>\n",
       "      <td>30.173254</td>\n",
       "      <td>26.210712</td>\n",
       "      <td>26.210697</td>\n",
       "      <td>0.049846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>26.675478</td>\n",
       "      <td>26.675468</td>\n",
       "      <td>26.250793</td>\n",
       "      <td>26.250784</td>\n",
       "      <td>0.024923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>29.513023</td>\n",
       "      <td>29.513014</td>\n",
       "      <td>26.361317</td>\n",
       "      <td>26.361303</td>\n",
       "      <td>0.049846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25</td>\n",
       "      <td>26.758577</td>\n",
       "      <td>26.758566</td>\n",
       "      <td>26.382872</td>\n",
       "      <td>26.382864</td>\n",
       "      <td>0.024923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>30.365482</td>\n",
       "      <td>30.365471</td>\n",
       "      <td>26.425076</td>\n",
       "      <td>26.425060</td>\n",
       "      <td>0.099691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>26.347160</td>\n",
       "      <td>26.347151</td>\n",
       "      <td>26.528269</td>\n",
       "      <td>26.528257</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39</td>\n",
       "      <td>25.443296</td>\n",
       "      <td>25.443285</td>\n",
       "      <td>26.561773</td>\n",
       "      <td>26.561764</td>\n",
       "      <td>0.006231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>49</td>\n",
       "      <td>25.156103</td>\n",
       "      <td>25.156097</td>\n",
       "      <td>26.563223</td>\n",
       "      <td>26.563213</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>54</td>\n",
       "      <td>25.424829</td>\n",
       "      <td>25.424810</td>\n",
       "      <td>26.567720</td>\n",
       "      <td>26.567703</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>38</td>\n",
       "      <td>26.668779</td>\n",
       "      <td>26.668768</td>\n",
       "      <td>26.593863</td>\n",
       "      <td>26.593845</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36</td>\n",
       "      <td>25.440290</td>\n",
       "      <td>25.440275</td>\n",
       "      <td>26.598709</td>\n",
       "      <td>26.598696</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>26.182848</td>\n",
       "      <td>26.182840</td>\n",
       "      <td>26.600533</td>\n",
       "      <td>26.600525</td>\n",
       "      <td>0.006231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>28.929577</td>\n",
       "      <td>28.929569</td>\n",
       "      <td>26.644859</td>\n",
       "      <td>26.644850</td>\n",
       "      <td>0.099691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>34</td>\n",
       "      <td>25.868311</td>\n",
       "      <td>25.868298</td>\n",
       "      <td>26.645874</td>\n",
       "      <td>26.645864</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>31.384010</td>\n",
       "      <td>31.383993</td>\n",
       "      <td>26.672962</td>\n",
       "      <td>26.672949</td>\n",
       "      <td>0.099691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>37</td>\n",
       "      <td>25.808548</td>\n",
       "      <td>25.808538</td>\n",
       "      <td>26.675467</td>\n",
       "      <td>26.675457</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>53</td>\n",
       "      <td>25.334501</td>\n",
       "      <td>25.334490</td>\n",
       "      <td>26.693007</td>\n",
       "      <td>26.692993</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>45</td>\n",
       "      <td>25.514374</td>\n",
       "      <td>25.514360</td>\n",
       "      <td>26.698957</td>\n",
       "      <td>26.698948</td>\n",
       "      <td>0.006231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42</td>\n",
       "      <td>25.830099</td>\n",
       "      <td>25.830090</td>\n",
       "      <td>26.702419</td>\n",
       "      <td>26.702414</td>\n",
       "      <td>0.006231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33</td>\n",
       "      <td>26.337357</td>\n",
       "      <td>26.337341</td>\n",
       "      <td>26.708961</td>\n",
       "      <td>26.708948</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>52</td>\n",
       "      <td>25.212330</td>\n",
       "      <td>25.212320</td>\n",
       "      <td>26.735407</td>\n",
       "      <td>26.735392</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>23</td>\n",
       "      <td>27.145241</td>\n",
       "      <td>27.145231</td>\n",
       "      <td>26.736038</td>\n",
       "      <td>26.736027</td>\n",
       "      <td>0.024923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>25.294909</td>\n",
       "      <td>25.294903</td>\n",
       "      <td>26.748356</td>\n",
       "      <td>26.748346</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>47</td>\n",
       "      <td>24.967047</td>\n",
       "      <td>24.967041</td>\n",
       "      <td>26.803141</td>\n",
       "      <td>26.803133</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>27.780228</td>\n",
       "      <td>27.780216</td>\n",
       "      <td>26.823120</td>\n",
       "      <td>26.823109</td>\n",
       "      <td>0.024923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>30.660461</td>\n",
       "      <td>30.660456</td>\n",
       "      <td>26.845007</td>\n",
       "      <td>26.844994</td>\n",
       "      <td>0.099691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>48</td>\n",
       "      <td>25.334074</td>\n",
       "      <td>25.334057</td>\n",
       "      <td>26.850178</td>\n",
       "      <td>26.850168</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>51</td>\n",
       "      <td>25.154009</td>\n",
       "      <td>25.153992</td>\n",
       "      <td>26.858244</td>\n",
       "      <td>26.858229</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>44</td>\n",
       "      <td>25.428522</td>\n",
       "      <td>25.428509</td>\n",
       "      <td>26.881657</td>\n",
       "      <td>26.881649</td>\n",
       "      <td>0.006231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12</td>\n",
       "      <td>30.881029</td>\n",
       "      <td>30.881016</td>\n",
       "      <td>27.061115</td>\n",
       "      <td>27.061104</td>\n",
       "      <td>0.049846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>22998.867188</td>\n",
       "      <td>22998.867188</td>\n",
       "      <td>27.080053</td>\n",
       "      <td>27.080040</td>\n",
       "      <td>0.099691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30</td>\n",
       "      <td>26.375862</td>\n",
       "      <td>26.375849</td>\n",
       "      <td>27.261694</td>\n",
       "      <td>27.261684</td>\n",
       "      <td>0.024923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28</td>\n",
       "      <td>26.886469</td>\n",
       "      <td>26.886457</td>\n",
       "      <td>27.288788</td>\n",
       "      <td>27.288774</td>\n",
       "      <td>0.024923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>35</td>\n",
       "      <td>26.281424</td>\n",
       "      <td>26.281406</td>\n",
       "      <td>27.360638</td>\n",
       "      <td>27.360626</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>31.231884</td>\n",
       "      <td>31.231871</td>\n",
       "      <td>27.425402</td>\n",
       "      <td>27.425394</td>\n",
       "      <td>0.099691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>18</td>\n",
       "      <td>27.825897</td>\n",
       "      <td>27.825886</td>\n",
       "      <td>27.443739</td>\n",
       "      <td>27.443726</td>\n",
       "      <td>0.049846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>31</td>\n",
       "      <td>26.192965</td>\n",
       "      <td>26.192955</td>\n",
       "      <td>27.729658</td>\n",
       "      <td>27.729645</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>29</td>\n",
       "      <td>26.816210</td>\n",
       "      <td>26.816195</td>\n",
       "      <td>27.767506</td>\n",
       "      <td>27.767498</td>\n",
       "      <td>0.024923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>46</td>\n",
       "      <td>25.473782</td>\n",
       "      <td>25.473764</td>\n",
       "      <td>27.780987</td>\n",
       "      <td>27.780977</td>\n",
       "      <td>0.006231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>41</td>\n",
       "      <td>25.825661</td>\n",
       "      <td>25.825647</td>\n",
       "      <td>27.896334</td>\n",
       "      <td>27.896320</td>\n",
       "      <td>0.006231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>13</td>\n",
       "      <td>29.038401</td>\n",
       "      <td>29.038389</td>\n",
       "      <td>27.968792</td>\n",
       "      <td>27.968777</td>\n",
       "      <td>0.049846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>22</td>\n",
       "      <td>29.708332</td>\n",
       "      <td>29.708323</td>\n",
       "      <td>29.100954</td>\n",
       "      <td>29.100939</td>\n",
       "      <td>0.049846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>11</td>\n",
       "      <td>28.578922</td>\n",
       "      <td>28.578913</td>\n",
       "      <td>29.220230</td>\n",
       "      <td>29.220221</td>\n",
       "      <td>0.049846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>26</td>\n",
       "      <td>27.275812</td>\n",
       "      <td>27.275806</td>\n",
       "      <td>29.372257</td>\n",
       "      <td>29.372244</td>\n",
       "      <td>0.024923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>43</td>\n",
       "      <td>25.388851</td>\n",
       "      <td>25.388844</td>\n",
       "      <td>29.845379</td>\n",
       "      <td>29.845371</td>\n",
       "      <td>0.006231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>15</td>\n",
       "      <td>28.934048</td>\n",
       "      <td>28.934034</td>\n",
       "      <td>30.570553</td>\n",
       "      <td>30.570541</td>\n",
       "      <td>0.049846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>21</td>\n",
       "      <td>27.243872</td>\n",
       "      <td>27.243855</td>\n",
       "      <td>31.161251</td>\n",
       "      <td>31.161243</td>\n",
       "      <td>0.049846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>9</td>\n",
       "      <td>31.757641</td>\n",
       "      <td>31.757626</td>\n",
       "      <td>31.471817</td>\n",
       "      <td>31.471807</td>\n",
       "      <td>0.099691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8</td>\n",
       "      <td>32.492096</td>\n",
       "      <td>32.492092</td>\n",
       "      <td>31.608490</td>\n",
       "      <td>31.608480</td>\n",
       "      <td>0.099691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>31.668089</td>\n",
       "      <td>31.668083</td>\n",
       "      <td>35.686722</td>\n",
       "      <td>35.686707</td>\n",
       "      <td>0.099691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3</td>\n",
       "      <td>30.957302</td>\n",
       "      <td>30.957289</td>\n",
       "      <td>36.636608</td>\n",
       "      <td>36.636597</td>\n",
       "      <td>0.099691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch          loss           mse   val_loss    val_mse        lr\n",
       "0      14     27.353174     27.353170  25.485693  25.485682  0.049846\n",
       "1      16     28.815987     28.815981  25.812254  25.812239  0.049846\n",
       "2      17     27.995691     27.995678  26.173250  26.173239  0.049846\n",
       "3       2     30.708574     30.708567  26.193041  26.193031  0.099691\n",
       "4      20     30.173267     30.173254  26.210712  26.210697  0.049846\n",
       "5      24     26.675478     26.675468  26.250793  26.250784  0.024923\n",
       "6      19     29.513023     29.513014  26.361317  26.361303  0.049846\n",
       "7      25     26.758577     26.758566  26.382872  26.382864  0.024923\n",
       "8       7     30.365482     30.365471  26.425076  26.425060  0.099691\n",
       "9      32     26.347160     26.347151  26.528269  26.528257  0.012461\n",
       "10     39     25.443296     25.443285  26.561773  26.561764  0.006231\n",
       "11     49     25.156103     25.156097  26.563223  26.563213  0.003115\n",
       "12     54     25.424829     25.424810  26.567720  26.567703  0.003115\n",
       "13     38     26.668779     26.668768  26.593863  26.593845  0.012461\n",
       "14     36     25.440290     25.440275  26.598709  26.598696  0.012461\n",
       "15     40     26.182848     26.182840  26.600533  26.600525  0.006231\n",
       "16     10     28.929577     28.929569  26.644859  26.644850  0.099691\n",
       "17     34     25.868311     25.868298  26.645874  26.645864  0.012461\n",
       "18      6     31.384010     31.383993  26.672962  26.672949  0.099691\n",
       "19     37     25.808548     25.808538  26.675467  26.675457  0.012461\n",
       "20     53     25.334501     25.334490  26.693007  26.692993  0.003115\n",
       "21     45     25.514374     25.514360  26.698957  26.698948  0.006231\n",
       "22     42     25.830099     25.830090  26.702419  26.702414  0.006231\n",
       "23     33     26.337357     26.337341  26.708961  26.708948  0.012461\n",
       "24     52     25.212330     25.212320  26.735407  26.735392  0.003115\n",
       "25     23     27.145241     27.145231  26.736038  26.736027  0.024923\n",
       "26     50     25.294909     25.294903  26.748356  26.748346  0.003115\n",
       "27     47     24.967047     24.967041  26.803141  26.803133  0.003115\n",
       "28     27     27.780228     27.780216  26.823120  26.823109  0.024923\n",
       "29      1     30.660461     30.660456  26.845007  26.844994  0.099691\n",
       "30     48     25.334074     25.334057  26.850178  26.850168  0.003115\n",
       "31     51     25.154009     25.153992  26.858244  26.858229  0.003115\n",
       "32     44     25.428522     25.428509  26.881657  26.881649  0.006231\n",
       "33     12     30.881029     30.881016  27.061115  27.061104  0.049846\n",
       "34      0  22998.867188  22998.867188  27.080053  27.080040  0.099691\n",
       "35     30     26.375862     26.375849  27.261694  27.261684  0.024923\n",
       "36     28     26.886469     26.886457  27.288788  27.288774  0.024923\n",
       "37     35     26.281424     26.281406  27.360638  27.360626  0.012461\n",
       "38      5     31.231884     31.231871  27.425402  27.425394  0.099691\n",
       "39     18     27.825897     27.825886  27.443739  27.443726  0.049846\n",
       "40     31     26.192965     26.192955  27.729658  27.729645  0.012461\n",
       "41     29     26.816210     26.816195  27.767506  27.767498  0.024923\n",
       "42     46     25.473782     25.473764  27.780987  27.780977  0.006231\n",
       "43     41     25.825661     25.825647  27.896334  27.896320  0.006231\n",
       "44     13     29.038401     29.038389  27.968792  27.968777  0.049846\n",
       "45     22     29.708332     29.708323  29.100954  29.100939  0.049846\n",
       "46     11     28.578922     28.578913  29.220230  29.220221  0.049846\n",
       "47     26     27.275812     27.275806  29.372257  29.372244  0.024923\n",
       "48     43     25.388851     25.388844  29.845379  29.845371  0.006231\n",
       "49     15     28.934048     28.934034  30.570553  30.570541  0.049846\n",
       "50     21     27.243872     27.243855  31.161251  31.161243  0.049846\n",
       "51      9     31.757641     31.757626  31.471817  31.471807  0.099691\n",
       "52      8     32.492096     32.492092  31.608490  31.608480  0.099691\n",
       "53      4     31.668089     31.668083  35.686722  35.686707  0.099691\n",
       "54      3     30.957302     30.957289  36.636608  36.636597  0.099691"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menyusun rekam jejak model berdasarkan nilai MSE pada setiap epoch, diurutkan dari yang terbaik.\n",
    "history_df = pd.DataFrame(history.history).sort_values('val_mse').reset_index()\n",
    "history_df.rename(columns = {'index': 'epoch'}, inplace = True)\n",
    "history_df.to_csv('history_{}.csv'.format(codename), index = False)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5543b8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:24:42.869554Z",
     "iopub.status.busy": "2021-11-04T11:24:42.868908Z",
     "iopub.status.idle": "2021-11-04T11:24:43.206329Z",
     "shell.execute_reply": "2021-11-04T11:24:43.206908Z"
    },
    "papermill": {
     "duration": 0.512448,
     "end_time": "2021-11-04T11:24:43.207094",
     "exception": false,
     "start_time": "2021-11-04T11:24:42.694646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyimpan nilai prediksi validasi dan testing diurutkan berdasarkan nilai validasi MSE terbaik.\n",
    "best_valid_preds = pd.DataFrame()\n",
    "best_test_preds = pd.DataFrame()\n",
    "\n",
    "for temp_index in list(history_df.iloc[:, 0]):\n",
    "    temp_df_valid = pd.read_csv('./valid_preds_{}.csv'.format(temp_index))\n",
    "    temp_df_test = pd.read_csv('./test_preds_{}.csv'.format(temp_index))\n",
    "    best_valid_preds = pd.concat([best_valid_preds, temp_df_valid], axis = 1, ignore_index = True)\n",
    "    best_test_preds = pd.concat([best_test_preds, temp_df_test], axis = 1, ignore_index = True)\n",
    "\n",
    "best_valid_preds.to_csv('valid_preds_{}.csv'.format(codename), index = False)\n",
    "best_test_preds.to_csv('test_preds_{}.csv'.format(codename), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c12106a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:24:43.555152Z",
     "iopub.status.busy": "2021-11-04T11:24:43.554498Z",
     "iopub.status.idle": "2021-11-04T11:24:43.562220Z",
     "shell.execute_reply": "2021-11-04T11:24:43.562748Z"
    },
    "papermill": {
     "duration": 0.183794,
     "end_time": "2021-11-04T11:24:43.562945",
     "exception": false,
     "start_time": "2021-11-04T11:24:43.379151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Membuang file yang sudah tidak diperlukan.\n",
    "for temp_index in list(history_df.iloc[:, 0]):\n",
    "    os.remove('./valid_preds_{}.csv'.format(temp_index))\n",
    "    os.remove('./test_preds_{}.csv'.format(temp_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ac54d89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:24:43.911751Z",
     "iopub.status.busy": "2021-11-04T11:24:43.911106Z",
     "iopub.status.idle": "2021-11-04T11:24:43.944219Z",
     "shell.execute_reply": "2021-11-04T11:24:43.944827Z"
    },
    "papermill": {
     "duration": 0.208277,
     "end_time": "2021-11-04T11:24:43.945003",
     "exception": false,
     "start_time": "2021-11-04T11:24:43.736726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.914090</td>\n",
       "      <td>26.224445</td>\n",
       "      <td>27.405693</td>\n",
       "      <td>25.567408</td>\n",
       "      <td>26.993826</td>\n",
       "      <td>26.128948</td>\n",
       "      <td>27.510470</td>\n",
       "      <td>26.074177</td>\n",
       "      <td>25.602049</td>\n",
       "      <td>26.378817</td>\n",
       "      <td>...</td>\n",
       "      <td>27.803312</td>\n",
       "      <td>23.941364</td>\n",
       "      <td>24.663430</td>\n",
       "      <td>28.091198</td>\n",
       "      <td>28.419640</td>\n",
       "      <td>28.183455</td>\n",
       "      <td>27.768475</td>\n",
       "      <td>23.319538</td>\n",
       "      <td>22.801046</td>\n",
       "      <td>22.586636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.825960</td>\n",
       "      <td>24.529740</td>\n",
       "      <td>24.705244</td>\n",
       "      <td>25.179968</td>\n",
       "      <td>23.816510</td>\n",
       "      <td>23.316992</td>\n",
       "      <td>25.374767</td>\n",
       "      <td>23.054180</td>\n",
       "      <td>24.557817</td>\n",
       "      <td>23.403234</td>\n",
       "      <td>...</td>\n",
       "      <td>25.064945</td>\n",
       "      <td>22.742514</td>\n",
       "      <td>21.941536</td>\n",
       "      <td>24.372372</td>\n",
       "      <td>26.475212</td>\n",
       "      <td>24.791300</td>\n",
       "      <td>26.711056</td>\n",
       "      <td>22.327919</td>\n",
       "      <td>21.687737</td>\n",
       "      <td>22.100754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.370615</td>\n",
       "      <td>28.153381</td>\n",
       "      <td>28.570818</td>\n",
       "      <td>25.331295</td>\n",
       "      <td>28.998882</td>\n",
       "      <td>27.648457</td>\n",
       "      <td>28.523352</td>\n",
       "      <td>28.256567</td>\n",
       "      <td>26.254835</td>\n",
       "      <td>27.471817</td>\n",
       "      <td>...</td>\n",
       "      <td>29.686762</td>\n",
       "      <td>25.716593</td>\n",
       "      <td>25.845602</td>\n",
       "      <td>29.059717</td>\n",
       "      <td>30.017555</td>\n",
       "      <td>30.360968</td>\n",
       "      <td>28.763866</td>\n",
       "      <td>24.048367</td>\n",
       "      <td>22.729052</td>\n",
       "      <td>22.829643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.983595</td>\n",
       "      <td>26.206347</td>\n",
       "      <td>26.956488</td>\n",
       "      <td>25.521376</td>\n",
       "      <td>26.363081</td>\n",
       "      <td>25.303488</td>\n",
       "      <td>27.054316</td>\n",
       "      <td>25.316042</td>\n",
       "      <td>25.853370</td>\n",
       "      <td>25.378628</td>\n",
       "      <td>...</td>\n",
       "      <td>27.501709</td>\n",
       "      <td>24.430544</td>\n",
       "      <td>23.743530</td>\n",
       "      <td>26.663172</td>\n",
       "      <td>28.610321</td>\n",
       "      <td>27.859224</td>\n",
       "      <td>28.335014</td>\n",
       "      <td>23.816416</td>\n",
       "      <td>22.804403</td>\n",
       "      <td>22.480957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.256273</td>\n",
       "      <td>26.939350</td>\n",
       "      <td>27.035065</td>\n",
       "      <td>26.912119</td>\n",
       "      <td>26.223719</td>\n",
       "      <td>25.442380</td>\n",
       "      <td>27.119968</td>\n",
       "      <td>25.172360</td>\n",
       "      <td>26.565866</td>\n",
       "      <td>25.539171</td>\n",
       "      <td>...</td>\n",
       "      <td>27.337397</td>\n",
       "      <td>24.382437</td>\n",
       "      <td>23.576303</td>\n",
       "      <td>26.866861</td>\n",
       "      <td>28.226010</td>\n",
       "      <td>27.637201</td>\n",
       "      <td>28.558237</td>\n",
       "      <td>25.150928</td>\n",
       "      <td>23.845083</td>\n",
       "      <td>24.243640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>30.901848</td>\n",
       "      <td>30.367516</td>\n",
       "      <td>31.754793</td>\n",
       "      <td>26.135450</td>\n",
       "      <td>33.893044</td>\n",
       "      <td>32.627674</td>\n",
       "      <td>31.383173</td>\n",
       "      <td>35.426517</td>\n",
       "      <td>26.703445</td>\n",
       "      <td>35.469536</td>\n",
       "      <td>...</td>\n",
       "      <td>35.927700</td>\n",
       "      <td>27.934660</td>\n",
       "      <td>32.117344</td>\n",
       "      <td>39.317215</td>\n",
       "      <td>33.047990</td>\n",
       "      <td>37.443768</td>\n",
       "      <td>32.041046</td>\n",
       "      <td>24.566110</td>\n",
       "      <td>24.115667</td>\n",
       "      <td>23.803295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>26.193483</td>\n",
       "      <td>27.341831</td>\n",
       "      <td>26.751741</td>\n",
       "      <td>25.304117</td>\n",
       "      <td>26.278002</td>\n",
       "      <td>25.898876</td>\n",
       "      <td>27.193804</td>\n",
       "      <td>26.107500</td>\n",
       "      <td>25.249560</td>\n",
       "      <td>26.128674</td>\n",
       "      <td>...</td>\n",
       "      <td>27.534924</td>\n",
       "      <td>24.425528</td>\n",
       "      <td>24.443796</td>\n",
       "      <td>27.472263</td>\n",
       "      <td>28.783531</td>\n",
       "      <td>28.899664</td>\n",
       "      <td>28.982250</td>\n",
       "      <td>23.492973</td>\n",
       "      <td>23.016035</td>\n",
       "      <td>22.795162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>26.106016</td>\n",
       "      <td>26.454975</td>\n",
       "      <td>26.858831</td>\n",
       "      <td>25.130302</td>\n",
       "      <td>27.151220</td>\n",
       "      <td>26.228254</td>\n",
       "      <td>27.316486</td>\n",
       "      <td>26.428804</td>\n",
       "      <td>24.965588</td>\n",
       "      <td>26.614168</td>\n",
       "      <td>...</td>\n",
       "      <td>28.013514</td>\n",
       "      <td>23.553541</td>\n",
       "      <td>24.786404</td>\n",
       "      <td>28.462214</td>\n",
       "      <td>28.255877</td>\n",
       "      <td>28.303228</td>\n",
       "      <td>27.556770</td>\n",
       "      <td>23.255157</td>\n",
       "      <td>22.549623</td>\n",
       "      <td>21.970888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>25.777193</td>\n",
       "      <td>27.015823</td>\n",
       "      <td>27.050226</td>\n",
       "      <td>25.222510</td>\n",
       "      <td>26.496172</td>\n",
       "      <td>25.756985</td>\n",
       "      <td>27.087568</td>\n",
       "      <td>25.441736</td>\n",
       "      <td>25.574793</td>\n",
       "      <td>25.789003</td>\n",
       "      <td>...</td>\n",
       "      <td>27.664337</td>\n",
       "      <td>23.723090</td>\n",
       "      <td>24.053904</td>\n",
       "      <td>27.954725</td>\n",
       "      <td>28.447460</td>\n",
       "      <td>27.737750</td>\n",
       "      <td>27.833150</td>\n",
       "      <td>23.179192</td>\n",
       "      <td>23.087910</td>\n",
       "      <td>22.424513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>25.481440</td>\n",
       "      <td>26.422400</td>\n",
       "      <td>26.636583</td>\n",
       "      <td>25.528767</td>\n",
       "      <td>25.919146</td>\n",
       "      <td>25.498299</td>\n",
       "      <td>26.860018</td>\n",
       "      <td>25.413448</td>\n",
       "      <td>25.065811</td>\n",
       "      <td>25.558120</td>\n",
       "      <td>...</td>\n",
       "      <td>27.315504</td>\n",
       "      <td>24.041555</td>\n",
       "      <td>23.938150</td>\n",
       "      <td>27.162344</td>\n",
       "      <td>27.860218</td>\n",
       "      <td>27.484655</td>\n",
       "      <td>27.692703</td>\n",
       "      <td>23.523218</td>\n",
       "      <td>22.720146</td>\n",
       "      <td>22.438820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5   \\\n",
       "0    25.914090  26.224445  27.405693  25.567408  26.993826  26.128948   \n",
       "1    23.825960  24.529740  24.705244  25.179968  23.816510  23.316992   \n",
       "2    27.370615  28.153381  28.570818  25.331295  28.998882  27.648457   \n",
       "3    25.983595  26.206347  26.956488  25.521376  26.363081  25.303488   \n",
       "4    25.256273  26.939350  27.035065  26.912119  26.223719  25.442380   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "456  30.901848  30.367516  31.754793  26.135450  33.893044  32.627674   \n",
       "457  26.193483  27.341831  26.751741  25.304117  26.278002  25.898876   \n",
       "458  26.106016  26.454975  26.858831  25.130302  27.151220  26.228254   \n",
       "459  25.777193  27.015823  27.050226  25.222510  26.496172  25.756985   \n",
       "460  25.481440  26.422400  26.636583  25.528767  25.919146  25.498299   \n",
       "\n",
       "            6          7          8          9   ...         45         46  \\\n",
       "0    27.510470  26.074177  25.602049  26.378817  ...  27.803312  23.941364   \n",
       "1    25.374767  23.054180  24.557817  23.403234  ...  25.064945  22.742514   \n",
       "2    28.523352  28.256567  26.254835  27.471817  ...  29.686762  25.716593   \n",
       "3    27.054316  25.316042  25.853370  25.378628  ...  27.501709  24.430544   \n",
       "4    27.119968  25.172360  26.565866  25.539171  ...  27.337397  24.382437   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "456  31.383173  35.426517  26.703445  35.469536  ...  35.927700  27.934660   \n",
       "457  27.193804  26.107500  25.249560  26.128674  ...  27.534924  24.425528   \n",
       "458  27.316486  26.428804  24.965588  26.614168  ...  28.013514  23.553541   \n",
       "459  27.087568  25.441736  25.574793  25.789003  ...  27.664337  23.723090   \n",
       "460  26.860018  25.413448  25.065811  25.558120  ...  27.315504  24.041555   \n",
       "\n",
       "            47         48         49         50         51         52  \\\n",
       "0    24.663430  28.091198  28.419640  28.183455  27.768475  23.319538   \n",
       "1    21.941536  24.372372  26.475212  24.791300  26.711056  22.327919   \n",
       "2    25.845602  29.059717  30.017555  30.360968  28.763866  24.048367   \n",
       "3    23.743530  26.663172  28.610321  27.859224  28.335014  23.816416   \n",
       "4    23.576303  26.866861  28.226010  27.637201  28.558237  25.150928   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "456  32.117344  39.317215  33.047990  37.443768  32.041046  24.566110   \n",
       "457  24.443796  27.472263  28.783531  28.899664  28.982250  23.492973   \n",
       "458  24.786404  28.462214  28.255877  28.303228  27.556770  23.255157   \n",
       "459  24.053904  27.954725  28.447460  27.737750  27.833150  23.179192   \n",
       "460  23.938150  27.162344  27.860218  27.484655  27.692703  23.523218   \n",
       "\n",
       "            53         54  \n",
       "0    22.801046  22.586636  \n",
       "1    21.687737  22.100754  \n",
       "2    22.729052  22.829643  \n",
       "3    22.804403  22.480957  \n",
       "4    23.845083  24.243640  \n",
       "..         ...        ...  \n",
       "456  24.115667  23.803295  \n",
       "457  23.016035  22.795162  \n",
       "458  22.549623  21.970888  \n",
       "459  23.087910  22.424513  \n",
       "460  22.720146  22.438820  \n",
       "\n",
       "[461 rows x 55 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan prediksi data validasi diurutkan berdasarkan nilai validasi MSE terbaik.\n",
    "best_valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffd2db06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:24:44.300226Z",
     "iopub.status.busy": "2021-11-04T11:24:44.298149Z",
     "iopub.status.idle": "2021-11-04T11:24:44.332971Z",
     "shell.execute_reply": "2021-11-04T11:24:44.333468Z"
    },
    "papermill": {
     "duration": 0.214705,
     "end_time": "2021-11-04T11:24:44.333668",
     "exception": false,
     "start_time": "2021-11-04T11:24:44.118963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.655466</td>\n",
       "      <td>25.094954</td>\n",
       "      <td>26.294676</td>\n",
       "      <td>25.660166</td>\n",
       "      <td>25.286947</td>\n",
       "      <td>25.290878</td>\n",
       "      <td>25.696959</td>\n",
       "      <td>25.899706</td>\n",
       "      <td>26.148458</td>\n",
       "      <td>24.905860</td>\n",
       "      <td>...</td>\n",
       "      <td>27.310791</td>\n",
       "      <td>24.372976</td>\n",
       "      <td>23.727970</td>\n",
       "      <td>26.786797</td>\n",
       "      <td>27.937164</td>\n",
       "      <td>28.106250</td>\n",
       "      <td>28.752030</td>\n",
       "      <td>23.897400</td>\n",
       "      <td>23.083649</td>\n",
       "      <td>23.489280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.799063</td>\n",
       "      <td>28.158709</td>\n",
       "      <td>28.032427</td>\n",
       "      <td>25.741758</td>\n",
       "      <td>27.425951</td>\n",
       "      <td>26.467800</td>\n",
       "      <td>28.040276</td>\n",
       "      <td>26.903505</td>\n",
       "      <td>25.601133</td>\n",
       "      <td>26.561888</td>\n",
       "      <td>...</td>\n",
       "      <td>28.575085</td>\n",
       "      <td>24.582426</td>\n",
       "      <td>24.830060</td>\n",
       "      <td>28.679468</td>\n",
       "      <td>29.457775</td>\n",
       "      <td>29.302202</td>\n",
       "      <td>28.656214</td>\n",
       "      <td>24.299118</td>\n",
       "      <td>23.395117</td>\n",
       "      <td>22.621962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.437029</td>\n",
       "      <td>26.960693</td>\n",
       "      <td>27.436010</td>\n",
       "      <td>24.957075</td>\n",
       "      <td>27.357435</td>\n",
       "      <td>26.040224</td>\n",
       "      <td>27.355839</td>\n",
       "      <td>26.338425</td>\n",
       "      <td>24.966146</td>\n",
       "      <td>26.354620</td>\n",
       "      <td>...</td>\n",
       "      <td>28.168194</td>\n",
       "      <td>24.595540</td>\n",
       "      <td>24.580720</td>\n",
       "      <td>28.281054</td>\n",
       "      <td>28.919888</td>\n",
       "      <td>28.656630</td>\n",
       "      <td>28.396114</td>\n",
       "      <td>23.133633</td>\n",
       "      <td>22.493593</td>\n",
       "      <td>22.056501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.722140</td>\n",
       "      <td>28.030193</td>\n",
       "      <td>28.152830</td>\n",
       "      <td>26.953142</td>\n",
       "      <td>28.597464</td>\n",
       "      <td>26.903835</td>\n",
       "      <td>28.302208</td>\n",
       "      <td>26.791600</td>\n",
       "      <td>26.644766</td>\n",
       "      <td>26.972440</td>\n",
       "      <td>...</td>\n",
       "      <td>29.115568</td>\n",
       "      <td>25.909838</td>\n",
       "      <td>25.269747</td>\n",
       "      <td>28.668242</td>\n",
       "      <td>30.075193</td>\n",
       "      <td>30.334085</td>\n",
       "      <td>29.645655</td>\n",
       "      <td>24.694778</td>\n",
       "      <td>24.130552</td>\n",
       "      <td>24.026222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.416120</td>\n",
       "      <td>25.202541</td>\n",
       "      <td>25.587008</td>\n",
       "      <td>25.897331</td>\n",
       "      <td>24.561785</td>\n",
       "      <td>24.065779</td>\n",
       "      <td>25.537210</td>\n",
       "      <td>24.063831</td>\n",
       "      <td>26.262728</td>\n",
       "      <td>23.818476</td>\n",
       "      <td>...</td>\n",
       "      <td>26.494839</td>\n",
       "      <td>23.274488</td>\n",
       "      <td>22.056976</td>\n",
       "      <td>25.989260</td>\n",
       "      <td>27.580456</td>\n",
       "      <td>26.307467</td>\n",
       "      <td>28.200914</td>\n",
       "      <td>23.675207</td>\n",
       "      <td>23.013664</td>\n",
       "      <td>22.925660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>25.198900</td>\n",
       "      <td>26.447490</td>\n",
       "      <td>26.208221</td>\n",
       "      <td>26.093348</td>\n",
       "      <td>26.131233</td>\n",
       "      <td>25.436356</td>\n",
       "      <td>26.611506</td>\n",
       "      <td>25.719187</td>\n",
       "      <td>25.930050</td>\n",
       "      <td>25.751910</td>\n",
       "      <td>...</td>\n",
       "      <td>27.558163</td>\n",
       "      <td>23.994410</td>\n",
       "      <td>24.123108</td>\n",
       "      <td>27.751133</td>\n",
       "      <td>27.859330</td>\n",
       "      <td>27.193949</td>\n",
       "      <td>27.530090</td>\n",
       "      <td>23.821438</td>\n",
       "      <td>22.648390</td>\n",
       "      <td>22.849560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>25.248188</td>\n",
       "      <td>25.094997</td>\n",
       "      <td>26.449550</td>\n",
       "      <td>25.245188</td>\n",
       "      <td>26.786474</td>\n",
       "      <td>25.393768</td>\n",
       "      <td>26.457030</td>\n",
       "      <td>25.747013</td>\n",
       "      <td>25.642569</td>\n",
       "      <td>25.640343</td>\n",
       "      <td>...</td>\n",
       "      <td>28.024069</td>\n",
       "      <td>24.315040</td>\n",
       "      <td>23.838232</td>\n",
       "      <td>27.766638</td>\n",
       "      <td>27.756413</td>\n",
       "      <td>28.144491</td>\n",
       "      <td>28.954212</td>\n",
       "      <td>22.170410</td>\n",
       "      <td>22.815233</td>\n",
       "      <td>22.824090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>26.336412</td>\n",
       "      <td>26.559044</td>\n",
       "      <td>26.964308</td>\n",
       "      <td>25.415690</td>\n",
       "      <td>26.668457</td>\n",
       "      <td>25.494770</td>\n",
       "      <td>26.945866</td>\n",
       "      <td>26.422830</td>\n",
       "      <td>25.100840</td>\n",
       "      <td>26.025356</td>\n",
       "      <td>...</td>\n",
       "      <td>27.859547</td>\n",
       "      <td>24.644667</td>\n",
       "      <td>24.256080</td>\n",
       "      <td>26.882930</td>\n",
       "      <td>28.453999</td>\n",
       "      <td>28.243204</td>\n",
       "      <td>28.144222</td>\n",
       "      <td>23.429620</td>\n",
       "      <td>22.507576</td>\n",
       "      <td>22.320908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>25.104937</td>\n",
       "      <td>24.598946</td>\n",
       "      <td>24.869108</td>\n",
       "      <td>25.646326</td>\n",
       "      <td>23.025540</td>\n",
       "      <td>23.366997</td>\n",
       "      <td>24.536583</td>\n",
       "      <td>22.100390</td>\n",
       "      <td>25.816545</td>\n",
       "      <td>22.022780</td>\n",
       "      <td>...</td>\n",
       "      <td>25.438710</td>\n",
       "      <td>22.755370</td>\n",
       "      <td>20.967380</td>\n",
       "      <td>23.112505</td>\n",
       "      <td>26.818111</td>\n",
       "      <td>25.433462</td>\n",
       "      <td>28.760075</td>\n",
       "      <td>23.434730</td>\n",
       "      <td>22.938782</td>\n",
       "      <td>23.125801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>26.597425</td>\n",
       "      <td>27.132610</td>\n",
       "      <td>27.317768</td>\n",
       "      <td>25.672628</td>\n",
       "      <td>26.752287</td>\n",
       "      <td>26.097042</td>\n",
       "      <td>27.282122</td>\n",
       "      <td>26.330729</td>\n",
       "      <td>25.644484</td>\n",
       "      <td>26.445070</td>\n",
       "      <td>...</td>\n",
       "      <td>28.359130</td>\n",
       "      <td>24.764978</td>\n",
       "      <td>24.777397</td>\n",
       "      <td>28.179350</td>\n",
       "      <td>28.583649</td>\n",
       "      <td>28.498884</td>\n",
       "      <td>28.786343</td>\n",
       "      <td>23.991367</td>\n",
       "      <td>23.119886</td>\n",
       "      <td>22.586334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5   \\\n",
       "0    25.655466  25.094954  26.294676  25.660166  25.286947  25.290878   \n",
       "1    26.799063  28.158709  28.032427  25.741758  27.425951  26.467800   \n",
       "2    26.437029  26.960693  27.436010  24.957075  27.357435  26.040224   \n",
       "3    27.722140  28.030193  28.152830  26.953142  28.597464  26.903835   \n",
       "4    25.416120  25.202541  25.587008  25.897331  24.561785  24.065779   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "985  25.198900  26.447490  26.208221  26.093348  26.131233  25.436356   \n",
       "986  25.248188  25.094997  26.449550  25.245188  26.786474  25.393768   \n",
       "987  26.336412  26.559044  26.964308  25.415690  26.668457  25.494770   \n",
       "988  25.104937  24.598946  24.869108  25.646326  23.025540  23.366997   \n",
       "989  26.597425  27.132610  27.317768  25.672628  26.752287  26.097042   \n",
       "\n",
       "            6          7          8          9   ...         45         46  \\\n",
       "0    25.696959  25.899706  26.148458  24.905860  ...  27.310791  24.372976   \n",
       "1    28.040276  26.903505  25.601133  26.561888  ...  28.575085  24.582426   \n",
       "2    27.355839  26.338425  24.966146  26.354620  ...  28.168194  24.595540   \n",
       "3    28.302208  26.791600  26.644766  26.972440  ...  29.115568  25.909838   \n",
       "4    25.537210  24.063831  26.262728  23.818476  ...  26.494839  23.274488   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "985  26.611506  25.719187  25.930050  25.751910  ...  27.558163  23.994410   \n",
       "986  26.457030  25.747013  25.642569  25.640343  ...  28.024069  24.315040   \n",
       "987  26.945866  26.422830  25.100840  26.025356  ...  27.859547  24.644667   \n",
       "988  24.536583  22.100390  25.816545  22.022780  ...  25.438710  22.755370   \n",
       "989  27.282122  26.330729  25.644484  26.445070  ...  28.359130  24.764978   \n",
       "\n",
       "            47         48         49         50         51         52  \\\n",
       "0    23.727970  26.786797  27.937164  28.106250  28.752030  23.897400   \n",
       "1    24.830060  28.679468  29.457775  29.302202  28.656214  24.299118   \n",
       "2    24.580720  28.281054  28.919888  28.656630  28.396114  23.133633   \n",
       "3    25.269747  28.668242  30.075193  30.334085  29.645655  24.694778   \n",
       "4    22.056976  25.989260  27.580456  26.307467  28.200914  23.675207   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "985  24.123108  27.751133  27.859330  27.193949  27.530090  23.821438   \n",
       "986  23.838232  27.766638  27.756413  28.144491  28.954212  22.170410   \n",
       "987  24.256080  26.882930  28.453999  28.243204  28.144222  23.429620   \n",
       "988  20.967380  23.112505  26.818111  25.433462  28.760075  23.434730   \n",
       "989  24.777397  28.179350  28.583649  28.498884  28.786343  23.991367   \n",
       "\n",
       "            53         54  \n",
       "0    23.083649  23.489280  \n",
       "1    23.395117  22.621962  \n",
       "2    22.493593  22.056501  \n",
       "3    24.130552  24.026222  \n",
       "4    23.013664  22.925660  \n",
       "..         ...        ...  \n",
       "985  22.648390  22.849560  \n",
       "986  22.815233  22.824090  \n",
       "987  22.507576  22.320908  \n",
       "988  22.938782  23.125801  \n",
       "989  23.119886  22.586334  \n",
       "\n",
       "[990 rows x 55 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan prediksi data testing diurutkan berdasarkan nilai validasi MSE terbaik.\n",
    "best_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63cfd0b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:24:44.686222Z",
     "iopub.status.busy": "2021-11-04T11:24:44.685597Z",
     "iopub.status.idle": "2021-11-04T11:24:44.691745Z",
     "shell.execute_reply": "2021-11-04T11:24:44.692317Z"
    },
    "papermill": {
     "duration": 0.184427,
     "end_time": "2021-11-04T11:24:44.692503",
     "exception": false,
     "start_time": "2021-11-04T11:24:44.508076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nilai MSE pada data validasi:  25.485681617653942\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan nilai MSE terbaik pada data validasi.\n",
    "error = MSE(y_valid, best_valid_preds[0])\n",
    "print('nilai MSE pada data validasi: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a996e805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:24:45.043867Z",
     "iopub.status.busy": "2021-11-04T11:24:45.043157Z",
     "iopub.status.idle": "2021-11-04T11:24:45.048250Z",
     "shell.execute_reply": "2021-11-04T11:24:45.048877Z"
    },
    "papermill": {
     "duration": 0.181561,
     "end_time": "2021-11-04T11:24:45.049046",
     "exception": false,
     "start_time": "2021-11-04T11:24:44.867485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total execution time: 0:11:16.682518\n"
     ]
    }
   ],
   "source": [
    "# Mencatat waktu berakhirnya keseluruhan program model dan prediksi data.\n",
    "global_end_time = time.time()\n",
    "\n",
    "# Menampilkan waktu eksekusi dari keseluruhan program model dan prediksi data.\n",
    "total_execution_time = datetime.timedelta(seconds = global_end_time - global_start_time)\n",
    "print(\"total execution time: %s\" % (total_execution_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 698.224801,
   "end_time": "2021-11-04T11:24:48.652874",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-04T11:13:10.428073",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
