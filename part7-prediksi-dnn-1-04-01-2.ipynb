{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6151f725",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-04T11:14:08.180857Z",
     "iopub.status.busy": "2021-11-04T11:14:08.179660Z",
     "iopub.status.idle": "2021-11-04T11:14:15.981184Z",
     "shell.execute_reply": "2021-11-04T11:14:15.980451Z",
     "shell.execute_reply.started": "2021-11-04T10:48:34.207266Z"
    },
    "papermill": {
     "duration": 7.831265,
     "end_time": "2021-11-04T11:14:15.981362",
     "exception": false,
     "start_time": "2021-11-04T11:14:08.150097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Melakukan impor libraries yang diperlukan untuk membangun model dan prediksi data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9207a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:14:16.032748Z",
     "iopub.status.busy": "2021-11-04T11:14:16.031961Z",
     "iopub.status.idle": "2021-11-04T11:14:16.034974Z",
     "shell.execute_reply": "2021-11-04T11:14:16.034333Z",
     "shell.execute_reply.started": "2021-11-04T04:01:49.258697Z"
    },
    "papermill": {
     "duration": 0.030559,
     "end_time": "2021-11-04T11:14:16.035113",
     "exception": false,
     "start_time": "2021-11-04T11:14:16.004554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mencatat waktu dimulainya keseluruhan program model dan prediksi data.\n",
    "global_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "960dc9ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:14:16.083551Z",
     "iopub.status.busy": "2021-11-04T11:14:16.082868Z",
     "iopub.status.idle": "2021-11-04T11:14:16.088516Z",
     "shell.execute_reply": "2021-11-04T11:14:16.089038Z",
     "shell.execute_reply.started": "2021-11-04T10:04:54.282612Z"
    },
    "papermill": {
     "duration": 0.03154,
     "end_time": "2021-11-04T11:14:16.089206",
     "exception": false,
     "start_time": "2021-11-04T11:14:16.057666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menetapkan nilai seed untuk reproduksi model.\n",
    "seed = 2021\n",
    "def set_seed(seed = seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = str(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e24622d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:14:16.139664Z",
     "iopub.status.busy": "2021-11-04T11:14:16.137645Z",
     "iopub.status.idle": "2021-11-04T11:14:16.142571Z",
     "shell.execute_reply": "2021-11-04T11:14:16.142076Z",
     "shell.execute_reply.started": "2021-11-04T10:04:57.579289Z"
    },
    "papermill": {
     "duration": 0.030596,
     "end_time": "2021-11-04T11:14:16.142704",
     "exception": false,
     "start_time": "2021-11-04T11:14:16.112108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menentukan indeks fold, kode penamaan program, banyak epoch, dan ukuran batch.\n",
    "fold_index = 2\n",
    "codename = '1_04_01_{}'.format(fold_index)\n",
    "epochs = 128\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af2f82da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:14:16.195348Z",
     "iopub.status.busy": "2021-11-04T11:14:16.194598Z",
     "iopub.status.idle": "2021-11-04T11:15:21.453114Z",
     "shell.execute_reply": "2021-11-04T11:15:21.454047Z",
     "shell.execute_reply.started": "2021-11-04T10:05:01.137768Z"
    },
    "papermill": {
     "duration": 65.289215,
     "end_time": "2021-11-04T11:15:21.454585",
     "exception": false,
     "start_time": "2021-11-04T11:14:16.165370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyusun data training.\n",
    "df_train = pd.read_csv('../input/bdc-sd2021-train-tabular-data/train_gray.csv')\n",
    "fake_train = pd.DataFrame(np.array(df_train).reshape((2305, 128, 128))[:, :, ::-1].reshape((2305, 128*128)))\n",
    "fake_train.columns = df_train.columns\n",
    "df_train = pd.concat([df_train, fake_train], ignore_index = True)\n",
    "del fake_train\n",
    "\n",
    "# Menyusun data testing.\n",
    "df_test = pd.read_csv('../input/bdc-sd2021-test-tabular-data/test_gray.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07ddb9f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:21.509449Z",
     "iopub.status.busy": "2021-11-04T11:15:21.508575Z",
     "iopub.status.idle": "2021-11-04T11:15:22.266151Z",
     "shell.execute_reply": "2021-11-04T11:15:22.266977Z",
     "shell.execute_reply.started": "2021-11-04T10:06:09.166332Z"
    },
    "papermill": {
     "duration": 0.786603,
     "end_time": "2021-11-04T11:15:22.267187",
     "exception": false,
     "start_time": "2021-11-04T11:15:21.480584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16374</th>\n",
       "      <th>16375</th>\n",
       "      <th>16376</th>\n",
       "      <th>16377</th>\n",
       "      <th>16378</th>\n",
       "      <th>16379</th>\n",
       "      <th>16380</th>\n",
       "      <th>16381</th>\n",
       "      <th>16382</th>\n",
       "      <th>16383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.183857</td>\n",
       "      <td>0.139013</td>\n",
       "      <td>0.098655</td>\n",
       "      <td>0.116592</td>\n",
       "      <td>0.121076</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.116592</td>\n",
       "      <td>0.094170</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>0.076233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242152</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.121076</td>\n",
       "      <td>0.134529</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.174888</td>\n",
       "      <td>0.152466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.827411</td>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.827411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319797</td>\n",
       "      <td>0.294416</td>\n",
       "      <td>0.253807</td>\n",
       "      <td>0.208122</td>\n",
       "      <td>0.147208</td>\n",
       "      <td>0.116751</td>\n",
       "      <td>0.096447</td>\n",
       "      <td>0.065990</td>\n",
       "      <td>0.055838</td>\n",
       "      <td>0.040609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.559091</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>0.486364</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.368182</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.154167</td>\n",
       "      <td>0.154167</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.893023</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.804651</td>\n",
       "      <td>0.879070</td>\n",
       "      <td>0.869767</td>\n",
       "      <td>0.637209</td>\n",
       "      <td>0.479070</td>\n",
       "      <td>0.269767</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106977</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.018605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.356828</td>\n",
       "      <td>0.370044</td>\n",
       "      <td>0.396476</td>\n",
       "      <td>0.409692</td>\n",
       "      <td>0.396476</td>\n",
       "      <td>0.422907</td>\n",
       "      <td>0.471366</td>\n",
       "      <td>0.515419</td>\n",
       "      <td>0.480176</td>\n",
       "      <td>0.436123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.039648</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.035242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.306977</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.339535</td>\n",
       "      <td>0.330233</td>\n",
       "      <td>0.320930</td>\n",
       "      <td>0.367442</td>\n",
       "      <td>0.367442</td>\n",
       "      <td>0.316279</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>0.339535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060465</td>\n",
       "      <td>0.074419</td>\n",
       "      <td>0.065116</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.083721</td>\n",
       "      <td>0.065116</td>\n",
       "      <td>0.055814</td>\n",
       "      <td>0.097674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>0.157258</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.137097</td>\n",
       "      <td>0.108871</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.068548</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.060484</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100806</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.044355</td>\n",
       "      <td>0.044355</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.052419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4610 rows × 16384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.183857  0.139013  0.098655  0.116592  0.121076  0.103139  0.116592   \n",
       "1     0.857868  0.857868  0.857868  0.857868  0.857868  0.857868  0.842640   \n",
       "2     0.018182  0.013636  0.013636  0.018182  0.018182  0.018182  0.018182   \n",
       "3     0.162500  0.162500  0.154167  0.154167  0.166667  0.187500  0.216667   \n",
       "4     0.893023  0.860465  0.804651  0.879070  0.869767  0.637209  0.479070   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4605  0.090476  0.076190  0.095238  0.114286  0.090476  0.109524  0.076190   \n",
       "4606  0.356828  0.370044  0.396476  0.409692  0.396476  0.422907  0.471366   \n",
       "4607  0.306977  0.279070  0.339535  0.330233  0.320930  0.367442  0.367442   \n",
       "4608  0.145000  0.240000  0.290000  0.295000  0.230000  0.170000  0.185000   \n",
       "4609  0.157258  0.161290  0.137097  0.108871  0.112903  0.096774  0.068548   \n",
       "\n",
       "             7         8         9  ...     16374     16375     16376  \\\n",
       "0     0.094170  0.089686  0.076233  ...  0.242152  0.089686  0.103139   \n",
       "1     0.827411  0.842640  0.827411  ...  0.319797  0.294416  0.253807   \n",
       "2     0.018182  0.013636  0.018182  ...  0.568182  0.559091  0.536364   \n",
       "3     0.254167  0.233333  0.183333  ...  0.666667  0.675000  0.745833   \n",
       "4     0.269767  0.186047  0.186047  ...  0.106977  0.032558  0.027907   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4605  0.061905  0.052381  0.076190  ...  0.157143  0.114286  0.133333   \n",
       "4606  0.515419  0.480176  0.436123  ...  0.030837  0.035242  0.030837   \n",
       "4607  0.316279  0.283721  0.339535  ...  0.060465  0.074419  0.065116   \n",
       "4608  0.200000  0.200000  0.230000  ...  0.015000  0.015000  0.015000   \n",
       "4609  0.072581  0.060484  0.072581  ...  0.100806  0.064516  0.044355   \n",
       "\n",
       "         16377     16378     16379     16380     16381     16382     16383  \n",
       "0     0.121076  0.134529  0.156951  0.156951  0.156951  0.174888  0.152466  \n",
       "1     0.208122  0.147208  0.116751  0.096447  0.065990  0.055838  0.040609  \n",
       "2     0.518182  0.486364  0.436364  0.368182  0.254545  0.113636  0.045455  \n",
       "3     0.887500  0.908333  0.900000  0.916667  0.945833  0.966667  0.966667  \n",
       "4     0.018605  0.004651  0.000000  0.000000  0.004651  0.009302  0.018605  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4605  0.047619  0.061905  0.061905  0.052381  0.042857  0.042857  0.042857  \n",
       "4606  0.026432  0.022026  0.017621  0.039648  0.026432  0.017621  0.035242  \n",
       "4607  0.051163  0.051163  0.046512  0.083721  0.065116  0.055814  0.097674  \n",
       "4608  0.015000  0.015000  0.015000  0.015000  0.010000  0.010000  0.010000  \n",
       "4609  0.044355  0.040323  0.032258  0.020161  0.012097  0.016129  0.052419  \n",
       "\n",
       "[4610 rows x 16384 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan normalisasi pada data training.\n",
    "scaler = MinMaxScaler(copy = False)\n",
    "scaler.fit_transform(df_train.T)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8936aff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:22.324017Z",
     "iopub.status.busy": "2021-11-04T11:15:22.323009Z",
     "iopub.status.idle": "2021-11-04T11:15:22.482631Z",
     "shell.execute_reply": "2021-11-04T11:15:22.481923Z",
     "shell.execute_reply.started": "2021-11-04T10:06:14.713247Z"
    },
    "papermill": {
     "duration": 0.189458,
     "end_time": "2021-11-04T11:15:22.482772",
     "exception": false,
     "start_time": "2021-11-04T11:15:22.293314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16374</th>\n",
       "      <th>16375</th>\n",
       "      <th>16376</th>\n",
       "      <th>16377</th>\n",
       "      <th>16378</th>\n",
       "      <th>16379</th>\n",
       "      <th>16380</th>\n",
       "      <th>16381</th>\n",
       "      <th>16382</th>\n",
       "      <th>16383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347619</td>\n",
       "      <td>0.361905</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.257143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417355</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.471074</td>\n",
       "      <td>0.508264</td>\n",
       "      <td>0.475207</td>\n",
       "      <td>0.541322</td>\n",
       "      <td>0.644628</td>\n",
       "      <td>0.611570</td>\n",
       "      <td>0.512397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.531120</td>\n",
       "      <td>0.493776</td>\n",
       "      <td>0.485477</td>\n",
       "      <td>0.427386</td>\n",
       "      <td>0.402490</td>\n",
       "      <td>0.356846</td>\n",
       "      <td>0.340249</td>\n",
       "      <td>0.356846</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.340249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190871</td>\n",
       "      <td>0.112033</td>\n",
       "      <td>0.062241</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.053942</td>\n",
       "      <td>0.045643</td>\n",
       "      <td>0.053942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.796703</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.763736</td>\n",
       "      <td>0.763736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>0.906593</td>\n",
       "      <td>0.879121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.248677</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.248677</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>0.243386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>0.608466</td>\n",
       "      <td>0.608466</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.566138</td>\n",
       "      <td>0.502646</td>\n",
       "      <td>0.470899</td>\n",
       "      <td>0.449735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.844898</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.963265</td>\n",
       "      <td>0.987755</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.722449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.848980</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.832653</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.820408</td>\n",
       "      <td>0.783673</td>\n",
       "      <td>0.767347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.077236</td>\n",
       "      <td>0.105691</td>\n",
       "      <td>0.117886</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.126016</td>\n",
       "      <td>0.069106</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.052846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186992</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.223577</td>\n",
       "      <td>0.239837</td>\n",
       "      <td>0.260163</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.321138</td>\n",
       "      <td>0.337398</td>\n",
       "      <td>0.357724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.037915</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.890995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.109244</td>\n",
       "      <td>0.155462</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.121849</td>\n",
       "      <td>0.113445</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>0.084034</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525210</td>\n",
       "      <td>0.281513</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.037815</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.042017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.156398</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.165877</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.127962</td>\n",
       "      <td>0.109005</td>\n",
       "      <td>0.118483</td>\n",
       "      <td>0.127962</td>\n",
       "      <td>0.123223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.127962</td>\n",
       "      <td>0.151659</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>0.080569</td>\n",
       "      <td>0.142180</td>\n",
       "      <td>0.156398</td>\n",
       "      <td>0.132701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 16384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.095238  0.100000  0.100000  0.095238  0.095238  0.100000  0.109524   \n",
       "1    0.061983  0.061983  0.061983  0.061983  0.061983  0.061983  0.061983   \n",
       "2    0.531120  0.493776  0.485477  0.427386  0.402490  0.356846  0.340249   \n",
       "3    0.796703  0.796703  0.791209  0.791209  0.796703  0.818681  0.818681   \n",
       "4    0.222222  0.232804  0.232804  0.248677  0.253968  0.259259  0.248677   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "985  0.828571  0.844898  0.804082  0.824490  0.918367  0.963265  0.987755   \n",
       "986  0.048780  0.065041  0.077236  0.105691  0.117886  0.121951  0.126016   \n",
       "987  0.056872  0.056872  0.061611  0.061611  0.071090  0.056872  0.037915   \n",
       "988  0.109244  0.155462  0.168067  0.121849  0.113445  0.088235  0.079832   \n",
       "989  0.156398  0.146919  0.151659  0.165877  0.151659  0.127962  0.109005   \n",
       "\n",
       "            7         8         9  ...     16374     16375     16376  \\\n",
       "0    0.114286  0.119048  0.104762  ...  0.347619  0.361905  0.314286   \n",
       "1    0.061983  0.066116  0.066116  ...  0.417355  0.322314  0.285124   \n",
       "2    0.356846  0.336100  0.340249  ...  0.190871  0.112033  0.062241   \n",
       "3    0.785714  0.763736  0.763736  ...  0.961538  0.950549  0.950549   \n",
       "4    0.243386  0.243386  0.243386  ...  0.619048  0.613757  0.608466   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "985  0.959184  0.873469  0.722449  ...  0.857143  0.848980  0.828571   \n",
       "986  0.069106  0.060976  0.052846  ...  0.186992  0.207317  0.223577   \n",
       "987  0.023697  0.009479  0.018957  ...  0.900474  0.890995  0.895735   \n",
       "988  0.084034  0.079832  0.067227  ...  0.525210  0.281513  0.050420   \n",
       "989  0.118483  0.127962  0.123223  ...  0.146919  0.151659  0.146919   \n",
       "\n",
       "        16377     16378     16379     16380     16381     16382     16383  \n",
       "0    0.400000  0.419048  0.261905  0.233333  0.300000  0.266667  0.257143  \n",
       "1    0.471074  0.508264  0.475207  0.541322  0.644628  0.611570  0.512397  \n",
       "2    0.058091  0.074689  0.066390  0.058091  0.053942  0.045643  0.053942  \n",
       "3    0.945055  0.939560  0.928571  0.923077  0.917582  0.906593  0.879121  \n",
       "4    0.608466  0.613757  0.592593  0.566138  0.502646  0.470899  0.449735  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "985  0.832653  0.840816  0.840816  0.816327  0.820408  0.783673  0.767347  \n",
       "986  0.239837  0.260163  0.284553  0.304878  0.321138  0.337398  0.357724  \n",
       "987  0.900474  0.895735  0.895735  0.890995  0.890995  0.890995  0.890995  \n",
       "988  0.033613  0.037815  0.033613  0.033613  0.042017  0.042017  0.042017  \n",
       "989  0.127962  0.151659  0.071090  0.080569  0.142180  0.156398  0.132701  \n",
       "\n",
       "[990 rows x 16384 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan normalisasi pada data testing.\n",
    "scaler.fit_transform(df_test.T)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fc9271e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:22.538619Z",
     "iopub.status.busy": "2021-11-04T11:15:22.537834Z",
     "iopub.status.idle": "2021-11-04T11:15:22.567648Z",
     "shell.execute_reply": "2021-11-04T11:15:22.568174Z",
     "shell.execute_reply.started": "2021-11-04T10:06:18.909964Z"
    },
    "papermill": {
     "duration": 0.060506,
     "end_time": "2021-11-04T11:15:22.568359",
     "exception": false,
     "start_time": "2021-11-04T11:15:22.507853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usia</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4610 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      usia  fold\n",
       "0       27     3\n",
       "1       27     3\n",
       "2       27     3\n",
       "3       24     0\n",
       "4       24     0\n",
       "...    ...   ...\n",
       "4605    23     4\n",
       "4606    23     4\n",
       "4607    27     4\n",
       "4608    27     4\n",
       "4609    27     4\n",
       "\n",
       "[4610 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Memunculkan target prediksi.\n",
    "target_0 = pd.read_csv('../input/bdc-sd2021-data-tambahan/train_target_and_fold.csv')[['usia', 'fold']]\n",
    "target_1 = pd.concat([target_0 for iteration in range(2)], ignore_index = True)\n",
    "target_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f4b7c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:22.622369Z",
     "iopub.status.busy": "2021-11-04T11:15:22.621468Z",
     "iopub.status.idle": "2021-11-04T11:15:22.730663Z",
     "shell.execute_reply": "2021-11-04T11:15:22.730113Z",
     "shell.execute_reply.started": "2021-11-04T10:06:23.078369Z"
    },
    "papermill": {
     "duration": 0.136832,
     "end_time": "2021-11-04T11:15:22.730820",
     "exception": false,
     "start_time": "2021-11-04T11:15:22.593988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_le</th>\n",
       "      <th>y_le</th>\n",
       "      <th>x_re</th>\n",
       "      <th>y_re</th>\n",
       "      <th>x_n</th>\n",
       "      <th>y_n</th>\n",
       "      <th>x_ml</th>\n",
       "      <th>y_ml</th>\n",
       "      <th>x_mr</th>\n",
       "      <th>y_mr</th>\n",
       "      <th>...</th>\n",
       "      <th>adj_n_ml</th>\n",
       "      <th>sym_le_mr</th>\n",
       "      <th>adj_le_mr</th>\n",
       "      <th>sym_re_mr</th>\n",
       "      <th>adj_re_mr</th>\n",
       "      <th>sym_n_mr</th>\n",
       "      <th>adj_n_mr</th>\n",
       "      <th>sym_ml_mr</th>\n",
       "      <th>adj_ml_mr</th>\n",
       "      <th>abs_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>0.698052</td>\n",
       "      <td>0.392694</td>\n",
       "      <td>0.405844</td>\n",
       "      <td>0.618721</td>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249515</td>\n",
       "      <td>0.615908</td>\n",
       "      <td>0.693416</td>\n",
       "      <td>0.314818</td>\n",
       "      <td>0.446237</td>\n",
       "      <td>0.339205</td>\n",
       "      <td>0.350364</td>\n",
       "      <td>0.539005</td>\n",
       "      <td>0.539049</td>\n",
       "      <td>0.061566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179724</td>\n",
       "      <td>0.397351</td>\n",
       "      <td>0.589862</td>\n",
       "      <td>0.403974</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.619205</td>\n",
       "      <td>0.202765</td>\n",
       "      <td>0.725166</td>\n",
       "      <td>0.635945</td>\n",
       "      <td>0.728477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171500</td>\n",
       "      <td>0.563722</td>\n",
       "      <td>0.648461</td>\n",
       "      <td>0.327759</td>\n",
       "      <td>0.453958</td>\n",
       "      <td>0.362484</td>\n",
       "      <td>0.377599</td>\n",
       "      <td>0.433192</td>\n",
       "      <td>0.433204</td>\n",
       "      <td>0.134023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195946</td>\n",
       "      <td>0.404878</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.404878</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.614634</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.682432</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239078</td>\n",
       "      <td>0.586077</td>\n",
       "      <td>0.664537</td>\n",
       "      <td>0.327457</td>\n",
       "      <td>0.453156</td>\n",
       "      <td>0.325814</td>\n",
       "      <td>0.344595</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.479730</td>\n",
       "      <td>0.174672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266055</td>\n",
       "      <td>0.373239</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.373239</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.238532</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272772</td>\n",
       "      <td>0.565660</td>\n",
       "      <td>0.629561</td>\n",
       "      <td>0.331113</td>\n",
       "      <td>0.431290</td>\n",
       "      <td>0.323865</td>\n",
       "      <td>0.348745</td>\n",
       "      <td>0.486442</td>\n",
       "      <td>0.486585</td>\n",
       "      <td>0.121842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.244565</td>\n",
       "      <td>0.389764</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.393701</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.578740</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.696850</td>\n",
       "      <td>0.706522</td>\n",
       "      <td>0.712598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254682</td>\n",
       "      <td>0.563583</td>\n",
       "      <td>0.641880</td>\n",
       "      <td>0.319083</td>\n",
       "      <td>0.440352</td>\n",
       "      <td>0.322564</td>\n",
       "      <td>0.346806</td>\n",
       "      <td>0.489384</td>\n",
       "      <td>0.489613</td>\n",
       "      <td>0.012195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.362934</td>\n",
       "      <td>0.401146</td>\n",
       "      <td>0.803089</td>\n",
       "      <td>0.383954</td>\n",
       "      <td>0.660232</td>\n",
       "      <td>0.616046</td>\n",
       "      <td>0.389961</td>\n",
       "      <td>0.759312</td>\n",
       "      <td>0.737452</td>\n",
       "      <td>0.753582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327708</td>\n",
       "      <td>0.530242</td>\n",
       "      <td>0.629355</td>\n",
       "      <td>0.364131</td>\n",
       "      <td>0.487068</td>\n",
       "      <td>0.162752</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.347538</td>\n",
       "      <td>0.347576</td>\n",
       "      <td>0.540420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.386256</td>\n",
       "      <td>0.744108</td>\n",
       "      <td>0.398104</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.649289</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.772512</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.779621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274054</td>\n",
       "      <td>0.612584</td>\n",
       "      <td>0.719783</td>\n",
       "      <td>0.387194</td>\n",
       "      <td>0.549482</td>\n",
       "      <td>0.236635</td>\n",
       "      <td>0.267332</td>\n",
       "      <td>0.404103</td>\n",
       "      <td>0.404167</td>\n",
       "      <td>0.552494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.274869</td>\n",
       "      <td>0.400372</td>\n",
       "      <td>0.759162</td>\n",
       "      <td>0.396648</td>\n",
       "      <td>0.523560</td>\n",
       "      <td>0.616387</td>\n",
       "      <td>0.324607</td>\n",
       "      <td>0.780261</td>\n",
       "      <td>0.685864</td>\n",
       "      <td>0.780261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304386</td>\n",
       "      <td>0.562206</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.386895</td>\n",
       "      <td>0.539038</td>\n",
       "      <td>0.230645</td>\n",
       "      <td>0.281800</td>\n",
       "      <td>0.361257</td>\n",
       "      <td>0.361257</td>\n",
       "      <td>0.162489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>0.323887</td>\n",
       "      <td>0.405836</td>\n",
       "      <td>0.801619</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.668016</td>\n",
       "      <td>0.631300</td>\n",
       "      <td>0.425101</td>\n",
       "      <td>0.801061</td>\n",
       "      <td>0.785425</td>\n",
       "      <td>0.814324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370196</td>\n",
       "      <td>0.602490</td>\n",
       "      <td>0.749939</td>\n",
       "      <td>0.395557</td>\n",
       "      <td>0.603456</td>\n",
       "      <td>0.206407</td>\n",
       "      <td>0.284469</td>\n",
       "      <td>0.360568</td>\n",
       "      <td>0.360892</td>\n",
       "      <td>0.456213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>0.357488</td>\n",
       "      <td>0.393750</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>0.384375</td>\n",
       "      <td>0.632850</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>0.314010</td>\n",
       "      <td>0.753125</td>\n",
       "      <td>0.830918</td>\n",
       "      <td>0.753125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405912</td>\n",
       "      <td>0.600094</td>\n",
       "      <td>0.741007</td>\n",
       "      <td>0.362607</td>\n",
       "      <td>0.557652</td>\n",
       "      <td>0.256197</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.378831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4610 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x_le      y_le      x_re      y_re       x_n       y_n      x_ml  \\\n",
       "0     0.204545  0.390411  0.698052  0.392694  0.405844  0.618721  0.194805   \n",
       "1     0.179724  0.397351  0.589862  0.403974  0.290323  0.619205  0.202765   \n",
       "2     0.195946  0.404878  0.662162  0.404878  0.378378  0.614634  0.202703   \n",
       "3     0.266055  0.373239  0.715596  0.373239  0.440367  0.549296  0.238532   \n",
       "4     0.244565  0.389764  0.695652  0.393701  0.413043  0.578740  0.217391   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4605  0.362934  0.401146  0.803089  0.383954  0.660232  0.616046  0.389961   \n",
       "4606  0.232323  0.386256  0.744108  0.398104  0.515152  0.649289  0.313131   \n",
       "4607  0.274869  0.400372  0.759162  0.396648  0.523560  0.616387  0.324607   \n",
       "4608  0.323887  0.405836  0.801619  0.413793  0.668016  0.631300  0.425101   \n",
       "4609  0.357488  0.393750  0.879227  0.384375  0.632850  0.590625  0.314010   \n",
       "\n",
       "          y_ml      x_mr      y_mr  ...  adj_n_ml  sym_le_mr  adj_le_mr  \\\n",
       "0     0.712329  0.733766  0.705479  ...  0.249515   0.615908   0.693416   \n",
       "1     0.725166  0.635945  0.728477  ...  0.171500   0.563722   0.648461   \n",
       "2     0.731707  0.682432  0.731707  ...  0.239078   0.586077   0.664537   \n",
       "3     0.690141  0.724771  0.704225  ...  0.272772   0.565660   0.629561   \n",
       "4     0.696850  0.706522  0.712598  ...  0.254682   0.563583   0.641880   \n",
       "...        ...       ...       ...  ...       ...        ...        ...   \n",
       "4605  0.759312  0.737452  0.753582  ...  0.327708   0.530242   0.629355   \n",
       "4606  0.772512  0.717172  0.779621  ...  0.274054   0.612584   0.719783   \n",
       "4607  0.780261  0.685864  0.780261  ...  0.304386   0.562206   0.678031   \n",
       "4608  0.801061  0.785425  0.814324  ...  0.370196   0.602490   0.749939   \n",
       "4609  0.753125  0.830918  0.753125  ...  0.405912   0.600094   0.741007   \n",
       "\n",
       "      sym_re_mr  adj_re_mr  sym_n_mr  adj_n_mr  sym_ml_mr  adj_ml_mr  \\\n",
       "0      0.314818   0.446237  0.339205  0.350364   0.539005   0.539049   \n",
       "1      0.327759   0.453958  0.362484  0.377599   0.433192   0.433204   \n",
       "2      0.327457   0.453156  0.325814  0.344595   0.479730   0.479730   \n",
       "3      0.331113   0.431290  0.323865  0.348745   0.486442   0.486585   \n",
       "4      0.319083   0.440352  0.322564  0.346806   0.489384   0.489613   \n",
       "...         ...        ...       ...       ...        ...        ...   \n",
       "4605   0.364131   0.487068  0.162752  0.207921   0.347538   0.347576   \n",
       "4606   0.387194   0.549482  0.236635  0.267332   0.404103   0.404167   \n",
       "4607   0.386895   0.539038  0.230645  0.281800   0.361257   0.361257   \n",
       "4608   0.395557   0.603456  0.206407  0.284469   0.360568   0.360892   \n",
       "4609   0.362607   0.557652  0.256197  0.319900   0.516908   0.516908   \n",
       "\n",
       "      abs_angle  \n",
       "0      0.061566  \n",
       "1      0.134023  \n",
       "2      0.174672  \n",
       "3      0.121842  \n",
       "4      0.012195  \n",
       "...         ...  \n",
       "4605   0.540420  \n",
       "4606   0.552494  \n",
       "4607   0.162489  \n",
       "4608   0.456213  \n",
       "4609   0.378831  \n",
       "\n",
       "[4610 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan penambahan data training yang berkaitan dengan posisi relatif fitur pada wajah.\n",
    "df_train_1 = pd.read_csv('../input/bdc-sd2021-data-tambahan/train_facial_relative.csv')\n",
    "fake_train_1 = df_train_1.copy()\n",
    "fake_train_1['x_le'] = 1 - df_train_1['x_re']\n",
    "fake_train_1['x_re'] = 1 - df_train_1['x_le']\n",
    "fake_train_1['x_n'] = 1 - df_train_1['x_n']\n",
    "fake_train_1['x_ml'] = 1 - df_train_1['x_mr']\n",
    "fake_train_1['x_mr'] = 1 - df_train_1['x_ml']\n",
    "fake_train_1[['sym_le_n', 'adj_le_n', 'sym_re_n', 'adj_re_n']] = df_train_1[['sym_re_n', 'adj_re_n', 'sym_le_n', 'adj_le_n']]\n",
    "fake_train_1[['sym_le_ml', 'adj_le_ml', 'sym_re_mr', 'adj_re_mr']] = df_train_1[['sym_re_mr', 'adj_re_mr', 'sym_le_ml', 'adj_le_ml']]\n",
    "fake_train_1[['sym_le_mr', 'adj_le_mr', 'sym_re_ml', 'adj_re_ml']] = df_train_1[['sym_re_ml', 'adj_re_ml', 'sym_le_mr', 'adj_le_mr']]\n",
    "fake_train_1[['sym_n_ml', 'adj_n_ml', 'sym_n_mr', 'adj_n_mr']] = df_train_1[['sym_n_mr', 'adj_n_mr', 'sym_n_ml', 'adj_n_ml']]\n",
    "\n",
    "df_train_1 = pd.concat([df_train_1, fake_train_1], ignore_index = True)\n",
    "del fake_train_1\n",
    "\n",
    "df_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1c6846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:22.787186Z",
     "iopub.status.busy": "2021-11-04T11:15:22.786443Z",
     "iopub.status.idle": "2021-11-04T11:15:22.836682Z",
     "shell.execute_reply": "2021-11-04T11:15:22.837231Z",
     "shell.execute_reply.started": "2021-11-04T10:06:27.057874Z"
    },
    "papermill": {
     "duration": 0.080849,
     "end_time": "2021-11-04T11:15:22.837403",
     "exception": false,
     "start_time": "2021-11-04T11:15:22.756554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_le</th>\n",
       "      <th>y_le</th>\n",
       "      <th>x_re</th>\n",
       "      <th>y_re</th>\n",
       "      <th>x_n</th>\n",
       "      <th>y_n</th>\n",
       "      <th>x_ml</th>\n",
       "      <th>y_ml</th>\n",
       "      <th>x_mr</th>\n",
       "      <th>y_mr</th>\n",
       "      <th>...</th>\n",
       "      <th>adj_n_ml</th>\n",
       "      <th>sym_le_mr</th>\n",
       "      <th>adj_le_mr</th>\n",
       "      <th>sym_re_mr</th>\n",
       "      <th>adj_re_mr</th>\n",
       "      <th>sym_n_mr</th>\n",
       "      <th>adj_n_mr</th>\n",
       "      <th>sym_ml_mr</th>\n",
       "      <th>adj_ml_mr</th>\n",
       "      <th>abs_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.291209</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>0.521978</td>\n",
       "      <td>0.516432</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.737089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338570</td>\n",
       "      <td>0.596852</td>\n",
       "      <td>0.645365</td>\n",
       "      <td>0.400006</td>\n",
       "      <td>0.467840</td>\n",
       "      <td>0.303782</td>\n",
       "      <td>0.332088</td>\n",
       "      <td>0.434091</td>\n",
       "      <td>0.434101</td>\n",
       "      <td>0.070471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.405128</td>\n",
       "      <td>0.753521</td>\n",
       "      <td>0.394872</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.625641</td>\n",
       "      <td>0.260563</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318229</td>\n",
       "      <td>0.554593</td>\n",
       "      <td>0.623428</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.429635</td>\n",
       "      <td>0.213573</td>\n",
       "      <td>0.227106</td>\n",
       "      <td>0.486159</td>\n",
       "      <td>0.486375</td>\n",
       "      <td>0.029403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214533</td>\n",
       "      <td>0.403023</td>\n",
       "      <td>0.660900</td>\n",
       "      <td>0.397985</td>\n",
       "      <td>0.366782</td>\n",
       "      <td>0.612091</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.727960</td>\n",
       "      <td>0.692042</td>\n",
       "      <td>0.722922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206456</td>\n",
       "      <td>0.574761</td>\n",
       "      <td>0.648943</td>\n",
       "      <td>0.326426</td>\n",
       "      <td>0.447452</td>\n",
       "      <td>0.343624</td>\n",
       "      <td>0.359129</td>\n",
       "      <td>0.456775</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.022553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.365517</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.402062</td>\n",
       "      <td>0.648276</td>\n",
       "      <td>0.597938</td>\n",
       "      <td>0.393103</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.757732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346547</td>\n",
       "      <td>0.537095</td>\n",
       "      <td>0.627927</td>\n",
       "      <td>0.356271</td>\n",
       "      <td>0.476312</td>\n",
       "      <td>0.194191</td>\n",
       "      <td>0.240590</td>\n",
       "      <td>0.365844</td>\n",
       "      <td>0.366102</td>\n",
       "      <td>0.064427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.381323</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.369650</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.603113</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.747082</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.735409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279993</td>\n",
       "      <td>0.575064</td>\n",
       "      <td>0.655712</td>\n",
       "      <td>0.366092</td>\n",
       "      <td>0.489833</td>\n",
       "      <td>0.255644</td>\n",
       "      <td>0.281443</td>\n",
       "      <td>0.422036</td>\n",
       "      <td>0.422164</td>\n",
       "      <td>0.044914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.356364</td>\n",
       "      <td>0.398892</td>\n",
       "      <td>0.821818</td>\n",
       "      <td>0.398892</td>\n",
       "      <td>0.650909</td>\n",
       "      <td>0.617729</td>\n",
       "      <td>0.374545</td>\n",
       "      <td>0.739612</td>\n",
       "      <td>0.785455</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319338</td>\n",
       "      <td>0.546195</td>\n",
       "      <td>0.617197</td>\n",
       "      <td>0.339901</td>\n",
       "      <td>0.445124</td>\n",
       "      <td>0.179696</td>\n",
       "      <td>0.206282</td>\n",
       "      <td>0.410918</td>\n",
       "      <td>0.410925</td>\n",
       "      <td>0.124355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.373016</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.563492</td>\n",
       "      <td>0.362637</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369237</td>\n",
       "      <td>0.602016</td>\n",
       "      <td>0.700027</td>\n",
       "      <td>0.381111</td>\n",
       "      <td>0.527587</td>\n",
       "      <td>0.251896</td>\n",
       "      <td>0.311010</td>\n",
       "      <td>0.385352</td>\n",
       "      <td>0.386026</td>\n",
       "      <td>0.047583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.289855</td>\n",
       "      <td>0.373737</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328573</td>\n",
       "      <td>0.573337</td>\n",
       "      <td>0.690348</td>\n",
       "      <td>0.364790</td>\n",
       "      <td>0.522544</td>\n",
       "      <td>0.259399</td>\n",
       "      <td>0.308120</td>\n",
       "      <td>0.449389</td>\n",
       "      <td>0.449509</td>\n",
       "      <td>0.031240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.338403</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.338403</td>\n",
       "      <td>0.319048</td>\n",
       "      <td>0.593156</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.779468</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.779468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261948</td>\n",
       "      <td>0.605120</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.444751</td>\n",
       "      <td>0.555329</td>\n",
       "      <td>0.302327</td>\n",
       "      <td>0.333367</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.020199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.280255</td>\n",
       "      <td>0.414596</td>\n",
       "      <td>0.787686</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.556263</td>\n",
       "      <td>0.639752</td>\n",
       "      <td>0.280255</td>\n",
       "      <td>0.729814</td>\n",
       "      <td>0.755839</td>\n",
       "      <td>0.734472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302233</td>\n",
       "      <td>0.573150</td>\n",
       "      <td>0.646119</td>\n",
       "      <td>0.323002</td>\n",
       "      <td>0.440643</td>\n",
       "      <td>0.220912</td>\n",
       "      <td>0.237915</td>\n",
       "      <td>0.475607</td>\n",
       "      <td>0.475627</td>\n",
       "      <td>0.145516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_le      y_le      x_re      y_re       x_n       y_n      x_ml  \\\n",
       "0    0.291209  0.333333  0.758242  0.338028  0.521978  0.516432  0.296703   \n",
       "1    0.281690  0.405128  0.753521  0.394872  0.549296  0.625641  0.260563   \n",
       "2    0.214533  0.403023  0.660900  0.397985  0.366782  0.612091  0.235294   \n",
       "3    0.365517  0.391753  0.779310  0.402062  0.648276  0.597938  0.393103   \n",
       "4    0.265625  0.381323  0.734375  0.369650  0.500000  0.603113  0.296875   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "985  0.356364  0.398892  0.821818  0.398892  0.650909  0.617729  0.374545   \n",
       "986  0.274725  0.380952  0.758242  0.373016  0.582418  0.563492  0.362637   \n",
       "987  0.289855  0.373737  0.753623  0.383838  0.521739  0.585859  0.275362   \n",
       "988  0.142857  0.338403  0.614286  0.338403  0.319048  0.593156  0.200000   \n",
       "989  0.280255  0.414596  0.787686  0.413043  0.556263  0.639752  0.280255   \n",
       "\n",
       "         y_ml      x_mr      y_mr  ...  adj_n_ml  sym_le_mr  adj_le_mr  \\\n",
       "0    0.732394  0.730769  0.737089  ...  0.338570   0.596852   0.645365   \n",
       "1    0.723077  0.746479  0.707692  ...  0.318229   0.554593   0.623428   \n",
       "2    0.727960  0.692042  0.722922  ...  0.206456   0.574761   0.648943   \n",
       "3    0.773196  0.758621  0.757732  ...  0.346547   0.537095   0.627927   \n",
       "4    0.747082  0.718750  0.735409  ...  0.279993   0.575064   0.655712   \n",
       "..        ...       ...       ...  ...       ...        ...        ...   \n",
       "985  0.739612  0.785455  0.736842  ...  0.319338   0.546195   0.617197   \n",
       "986  0.777778  0.747253  0.753968  ...  0.369237   0.602016   0.700027   \n",
       "987  0.737374  0.724638  0.747475  ...  0.328573   0.573337   0.690348   \n",
       "988  0.779468  0.557143  0.779468  ...  0.261948   0.605120   0.690476   \n",
       "989  0.729814  0.755839  0.734472  ...  0.302233   0.573150   0.646119   \n",
       "\n",
       "     sym_re_mr  adj_re_mr  sym_n_mr  adj_n_mr  sym_ml_mr  adj_ml_mr  abs_angle  \n",
       "0     0.400006   0.467840  0.303782  0.332088   0.434091   0.434101   0.070471  \n",
       "1     0.312900   0.429635  0.213573  0.227106   0.486159   0.486375   0.029403  \n",
       "2     0.326426   0.447452  0.343624  0.359129   0.456775   0.456800   0.022553  \n",
       "3     0.356271   0.476312  0.194191  0.240590   0.365844   0.366102   0.064427  \n",
       "4     0.366092   0.489833  0.255644  0.281443   0.422036   0.422164   0.044914  \n",
       "..         ...        ...       ...       ...        ...        ...        ...  \n",
       "985   0.339901   0.445124  0.179696  0.206282   0.410918   0.410925   0.124355  \n",
       "986   0.381111   0.527587  0.251896  0.311010   0.385352   0.386026   0.047583  \n",
       "987   0.364790   0.522544  0.259399  0.308120   0.449389   0.449509   0.031240  \n",
       "988   0.444751   0.555329  0.302327  0.333367   0.357143   0.357143   0.020199  \n",
       "989   0.323002   0.440643  0.220912  0.237915   0.475607   0.475627   0.145516  \n",
       "\n",
       "[990 rows x 37 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melakukan penambahan data testing yang berkaitan dengan posisi relatif fitur pada wajah.\n",
    "df_test_1 = pd.read_csv('../input/bdc-sd2021-data-tambahan/test_facial_relative.csv')\n",
    "df_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c116ca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:15:22.895625Z",
     "iopub.status.busy": "2021-11-04T11:15:22.894956Z",
     "iopub.status.idle": "2021-11-04T11:16:24.389891Z",
     "shell.execute_reply": "2021-11-04T11:16:24.390901Z",
     "shell.execute_reply.started": "2021-11-04T10:10:05.524524Z"
    },
    "papermill": {
     "duration": 61.526874,
     "end_time": "2021-11-04T11:16:24.391318",
     "exception": false,
     "start_time": "2021-11-04T11:15:22.864444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyusun indeks untuk data training dan melakukan shuffle.\n",
    "train_index = list(target_1[target_1['fold'] != fold_index].index)\n",
    "random.seed(seed)\n",
    "random.shuffle(train_index)\n",
    "\n",
    "# Menyusun indeks untuk data validasi.\n",
    "valid_index = list(target_0[target_0['fold'] == fold_index].index)\n",
    "\n",
    "# Memisahkan data validasi dari data training, serta menginisiasi data testing.\n",
    "X_train = df_train.iloc[train_index]\n",
    "X_valid = df_train.iloc[valid_index]\n",
    "X_test = df_test.copy()\n",
    "\n",
    "X_train_1 = df_train_1.iloc[train_index]\n",
    "X_valid_1 = df_train_1.iloc[valid_index]\n",
    "X_test_1 = df_test_1.copy()\n",
    "\n",
    "# Melakukan reduksi dimensi dengan menggunakan PCA.\n",
    "pca = PCA(0.95)\n",
    "X_train = pd.DataFrame(pca.fit_transform(X_train))\n",
    "X_valid = pd.DataFrame(pca.transform(X_valid))\n",
    "X_test = pd.DataFrame(pca.transform(X_test))\n",
    "\n",
    "pca = PCA(0.95)\n",
    "X_train_1 = pd.DataFrame(pca.fit_transform(X_train_1))\n",
    "X_valid_1 = pd.DataFrame(pca.transform(X_valid_1))\n",
    "X_test_1 = pd.DataFrame(pca.transform(X_test_1))\n",
    "\n",
    "# Menggabungkan informasi pada data training, validasi, dan testing.\n",
    "X_train = pd.concat([X_train, X_train_1], axis = 1, ignore_index = True)\n",
    "X_valid = pd.concat([X_valid, X_valid_1], axis = 1, ignore_index = True)\n",
    "X_test = pd.concat([X_test, X_test_1], axis = 1, ignore_index = True)\n",
    "del X_train_1, X_valid_1, X_test_1\n",
    "\n",
    "# Mengubah ukuran data agar sesuai dengan input yang diharapkan oleh model.\n",
    "X_train = X_train.values.reshape(-1, X_train.shape[1], 1).astype('float64')\n",
    "X_valid = X_valid.values.reshape(-1, X_valid.shape[1], 1).astype('float64')\n",
    "X_test = X_test.values.reshape(-1, X_test.shape[1], 1).astype('float64')\n",
    "\n",
    "# Memisahkan target validasi dari target training.\n",
    "y_train = target_1.iloc[train_index, 0].astype('int64')\n",
    "y_valid = target_0.iloc[valid_index, 0].astype('int64')\n",
    "\n",
    "# Membuang informasi yang sudah tidak diperlukan lagi.\n",
    "del df_train, df_test, df_train_1, df_test_1, pca, target_0, target_1, train_index, valid_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59694908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:16:24.484054Z",
     "iopub.status.busy": "2021-11-04T11:16:24.482610Z",
     "iopub.status.idle": "2021-11-04T11:16:24.499463Z",
     "shell.execute_reply": "2021-11-04T11:16:24.498712Z",
     "shell.execute_reply.started": "2021-11-04T10:34:04.234056Z"
    },
    "papermill": {
     "duration": 0.056576,
     "end_time": "2021-11-04T11:16:24.499687",
     "exception": false,
     "start_time": "2021-11-04T11:16:24.443111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mendefinisikan fungsi untuk mencari parameter terbaik dengan nilai error terkecil.\n",
    "def create_model(trial):\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 5)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-10, 1e-3, log = True)\n",
    "    dropout = trial.suggest_float('dropout', 0.2, 0.5, log = True)\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers-1):\n",
    "        num_hidden = trial.suggest_int('n_units_l{}'.format(i), 32, 256, log = True)\n",
    "        if i:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "            model.add(Dropout(dropout))\n",
    "        else:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(weight_decay),\n",
    "                            input_shape = (X_train.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    num_hidden = trial.suggest_int('n_units_l{}'.format(n_layers-1), 32, 256, log = True)\n",
    "    model.add(Dense(num_hidden,\n",
    "                    activation = 'relu',\n",
    "                    kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "    model.add(Dense(1,\n",
    "                    activation = 'linear',\n",
    "                    kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "    return model\n",
    "\n",
    "def create_optimizer(trial):\n",
    "    kwargs = {}\n",
    "    optimizer_options = ['RMSprop', 'Adam', 'SGD']\n",
    "    optimizer_selected = trial.suggest_categorical('optimizer', optimizer_options)\n",
    "    if optimizer_selected == 'RMSprop':\n",
    "        kwargs['learning_rate'] = trial.suggest_float(\n",
    "            'rmsprop_learning_rate', 1e-5, 1e-1, log=True)\n",
    "        kwargs['decay'] = trial.suggest_float('rmsprop_decay', 0.85, 0.99)\n",
    "        kwargs['momentum'] = trial.suggest_float('rmsprop_momentum', 1e-5, 1e-1, log = True)\n",
    "    elif optimizer_selected == 'Adam':\n",
    "        kwargs['learning_rate'] = trial.suggest_float('adam_learning_rate', 1e-5, 1e-1, log = True)\n",
    "    elif optimizer_selected == 'SGD':\n",
    "        kwargs['learning_rate'] = trial.suggest_float(\n",
    "            'sgd_opt_learning_rate', 1e-5, 1e-1, log=True)\n",
    "        kwargs['momentum'] = trial.suggest_float('sgd_opt_momentum', 1e-5, 1e-1, log = True)\n",
    "    \n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "    return optimizer\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    optimizer = create_optimizer(trial)\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = 'mean_squared_error',\n",
    "                  metrics = ['mse'])\n",
    "    set_seed()\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs = 3,\n",
    "                        validation_data = (X_valid, y_valid),\n",
    "                        verbose = 2,\n",
    "                        steps_per_epoch = X_train.shape[0] // batch_size)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    try:\n",
    "        mse = MSE(y_valid, y_valid_pred)\n",
    "    except ValueError:\n",
    "        mse = 1e+32\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b691be26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:16:24.567615Z",
     "iopub.status.busy": "2021-11-04T11:16:24.566288Z",
     "iopub.status.idle": "2021-11-04T11:29:40.977325Z",
     "shell.execute_reply": "2021-11-04T11:29:40.978043Z"
    },
    "papermill": {
     "duration": 796.449288,
     "end_time": "2021-11-04T11:29:40.978233",
     "exception": false,
     "start_time": "2021-11-04T11:16:24.528945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:16:24,563]\u001b[0m A new study created in memory with name: no-name-048c9744-a5ed-441a-a450-731b3f43e3c9\u001b[0m\n",
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   KMP_WARNINGS=0\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_ENABLE_TASK_THROTTLING=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=4\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=false\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=1\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED: deprecated; max-active-levels-var=1\n",
      "   OMP_NUM_THREADS: value is not defined\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2021-11-04 11:16:24.635555: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-11-04 11:16:24.954030: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 634.3820 - mse: 634.3783 - val_loss: 430.9827 - val_mse: 430.9791\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 124.5637 - mse: 124.5601 - val_loss: 38.0582 - val_mse: 38.0546\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 39.8494 - mse: 39.8458 - val_loss: 36.3946 - val_mse: 36.3910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:16:40,504]\u001b[0m Trial 0 finished with value: 36.39095615456834 and parameters: {'n_layers': 4, 'weight_decay': 1.3601459990500093e-05, 'dropout': 0.22715517141780636, 'n_units_l0': 61, 'n_units_l1': 255, 'n_units_l2': 41, 'n_units_l3': 46, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 2.4410551066709827e-05, 'sgd_opt_momentum': 1.7150829926878746e-05}. Best is trial 0 with value: 36.39095615456834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 10s - loss: 249.3298 - mse: 249.3288 - val_loss: 37.6007 - val_mse: 37.5996\n",
      "Epoch 2/3\n",
      "57/57 - 9s - loss: 36.3569 - mse: 36.3557 - val_loss: 34.2951 - val_mse: 34.2940\n",
      "Epoch 3/3\n",
      "57/57 - 9s - loss: 33.9318 - mse: 33.9306 - val_loss: 33.0318 - val_mse: 33.0306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:17:09,180]\u001b[0m Trial 1 finished with value: 33.03063651834235 and parameters: {'n_layers': 5, 'weight_decay': 2.069674778352553e-06, 'dropout': 0.2165227444547113, 'n_units_l0': 102, 'n_units_l1': 115, 'n_units_l2': 238, 'n_units_l3': 105, 'n_units_l4': 69, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 6.0309245793449296e-05, 'sgd_opt_momentum': 0.0021618027516387694}. Best is trial 1 with value: 33.03063651834235.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 76.0461 - mse: 76.0460 - val_loss: 32.9636 - val_mse: 32.9634\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 29.9909 - mse: 29.9907 - val_loss: 31.5774 - val_mse: 31.5772\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 27.7061 - mse: 27.7059 - val_loss: 28.2552 - val_mse: 28.2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:17:16,742]\u001b[0m Trial 2 finished with value: 28.254984416565467 and parameters: {'n_layers': 3, 'weight_decay': 4.2140608469491625e-07, 'dropout': 0.425181023662834, 'n_units_l0': 146, 'n_units_l1': 36, 'n_units_l2': 129, 'optimizer': 'Adam', 'adam_learning_rate': 0.0029509089780652155}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 7s - loss: nan - mse: 124020365769740924768747520.0000 - val_loss: nan - val_mse: 244555097469420505661440.0000\n",
      "Epoch 2/3\n",
      "57/57 - 6s - loss: nan - mse: 122488938694019769171968.0000 - val_loss: nan - val_mse: 47678595945055282790400.0000\n",
      "Epoch 3/3\n",
      "57/57 - 6s - loss: nan - mse: 23880523923516590915584.0000 - val_loss: nan - val_mse: 9295447082341259804672.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:17:36,465]\u001b[0m Trial 3 finished with value: 9.295445977134576e+21 and parameters: {'n_layers': 4, 'weight_decay': 1.280797128821542e-08, 'dropout': 0.4445600696908863, 'n_units_l0': 108, 'n_units_l1': 247, 'n_units_l2': 80, 'n_units_l3': 41, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.006855869932485577, 'sgd_opt_momentum': 0.03652763447965056}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 153.9311 - mse: 153.9304 - val_loss: 34.7028 - val_mse: 34.7020\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 35.0141 - mse: 35.0133 - val_loss: 33.9452 - val_mse: 33.9444\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 32.6712 - mse: 32.6704 - val_loss: 36.2151 - val_mse: 36.2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:17:47,399]\u001b[0m Trial 4 finished with value: 36.214382642256304 and parameters: {'n_layers': 4, 'weight_decay': 2.869521426120942e-06, 'dropout': 0.2736582989224417, 'n_units_l0': 177, 'n_units_l1': 60, 'n_units_l2': 60, 'n_units_l3': 48, 'optimizer': 'Adam', 'adam_learning_rate': 0.0003587550277569686}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:18:01,955]\u001b[0m Trial 5 finished with value: 1e+32 and parameters: {'n_layers': 4, 'weight_decay': 8.671491605192508e-05, 'dropout': 0.2120474687506201, 'n_units_l0': 75, 'n_units_l1': 63, 'n_units_l2': 143, 'n_units_l3': 85, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.012820573397259222, 'sgd_opt_momentum': 0.01219735525440408}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 98.3330 - mse: 98.3328 - val_loss: 54.3417 - val_mse: 54.3415\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 48.3332 - mse: 48.3330 - val_loss: 44.3379 - val_mse: 44.3377\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 43.4031 - mse: 43.4028 - val_loss: 41.6493 - val_mse: 41.6491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:18:05,507]\u001b[0m Trial 6 finished with value: 41.64906302287618 and parameters: {'n_layers': 2, 'weight_decay': 1.4490033299339797e-06, 'dropout': 0.4134236878013778, 'n_units_l0': 56, 'n_units_l1': 69, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.0004666904757351211, 'rmsprop_decay': 0.894925822839254, 'rmsprop_momentum': 0.000308450498248823}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 53890.2109 - mse: 53890.2070 - val_loss: 105.8944 - val_mse: 105.8758\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 122.9632 - mse: 122.9446 - val_loss: 77.6858 - val_mse: 77.6672\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 93.8504 - mse: 93.8319 - val_loss: 58.3081 - val_mse: 58.2896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:18:17,068]\u001b[0m Trial 7 finished with value: 58.2895667388164 and parameters: {'n_layers': 3, 'weight_decay': 5.713328696681321e-06, 'dropout': 0.3407865362809055, 'n_units_l0': 241, 'n_units_l1': 75, 'n_units_l2': 63, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.019638650422524002, 'rmsprop_decay': 0.9279674621367233, 'rmsprop_momentum': 0.007481765717358807}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 352859.6562 - mse: 352859.6562 - val_loss: 360.6382 - val_mse: 360.6376\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 56.1614 - mse: 56.1607 - val_loss: 486.1512 - val_mse: 486.1505\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 49.5775 - mse: 49.5767 - val_loss: 473.2077 - val_mse: 473.2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:18:33,479]\u001b[0m Trial 8 finished with value: 473.2069585497242 and parameters: {'n_layers': 5, 'weight_decay': 2.9653117862224153e-07, 'dropout': 0.3197493177048565, 'n_units_l0': 123, 'n_units_l1': 65, 'n_units_l2': 116, 'n_units_l3': 83, 'n_units_l4': 41, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.019054962911205356, 'rmsprop_decay': 0.874518227528278, 'rmsprop_momentum': 8.371297680962848e-05}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 10s - loss: 3447.1152 - mse: 3447.0938 - val_loss: 44.8890 - val_mse: 44.8677\n",
      "Epoch 2/3\n",
      "57/57 - 9s - loss: 47.1135 - mse: 47.0922 - val_loss: 51.3701 - val_mse: 51.3488\n",
      "Epoch 3/3\n",
      "57/57 - 9s - loss: 44.0832 - mse: 44.0618 - val_loss: 50.1709 - val_mse: 50.1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:19:02,953]\u001b[0m Trial 9 finished with value: 50.14955840551965 and parameters: {'n_layers': 4, 'weight_decay': 1.0556840099451229e-05, 'dropout': 0.22909938508654398, 'n_units_l0': 72, 'n_units_l1': 170, 'n_units_l2': 172, 'n_units_l3': 167, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.005553572385099785, 'rmsprop_decay': 0.9526963318618572, 'rmsprop_momentum': 3.908613352528237e-05}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 1s - loss: 2770.6665 - mse: 2770.6663 - val_loss: 649.1117 - val_mse: 649.1108\n",
      "Epoch 2/3\n",
      "57/57 - 0s - loss: 596.0320 - mse: 596.0311 - val_loss: 535.2243 - val_mse: 535.2233\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 482.2611 - mse: 482.2599 - val_loss: 424.8442 - val_mse: 424.8432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:19:05,461]\u001b[0m Trial 10 finished with value: 424.8432315449747 and parameters: {'n_layers': 2, 'weight_decay': 1.5303673965817338e-08, 'dropout': 0.36337622618058174, 'n_units_l0': 37, 'n_units_l1': 38, 'optimizer': 'Adam', 'adam_learning_rate': 0.07687620678695332}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 18s - loss: 1651.3342 - mse: 1640.5842 - val_loss: 709.2704 - val_mse: 696.6928\n",
      "Epoch 2/3\n",
      "57/57 - 15s - loss: 422.3993 - mse: 411.1902 - val_loss: 42.3622 - val_mse: 32.2718\n",
      "Epoch 3/3\n",
      "57/57 - 16s - loss: 43.1872 - mse: 33.8785 - val_loss: 37.1302 - val_mse: 28.5459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:19:54,851]\u001b[0m Trial 11 finished with value: 28.545921175968235 and parameters: {'n_layers': 5, 'weight_decay': 0.0008338016434700748, 'dropout': 0.4953827096246268, 'n_units_l0': 141, 'n_units_l1': 121, 'n_units_l2': 253, 'n_units_l3': 245, 'n_units_l4': 142, 'optimizer': 'Adam', 'adam_learning_rate': 0.008983185806335612}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 57.6600 - mse: 56.3507 - val_loss: 31.6973 - val_mse: 30.2483\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 29.4225 - mse: 28.1324 - val_loss: 30.8941 - val_mse: 29.7353\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 31.2268 - mse: 30.1410 - val_loss: 30.5199 - val_mse: 29.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:03,228]\u001b[0m Trial 12 finished with value: 29.49806306796871 and parameters: {'n_layers': 3, 'weight_decay': 0.000695990869779388, 'dropout': 0.4909028434074908, 'n_units_l0': 158, 'n_units_l1': 35, 'n_units_l2': 249, 'optimizer': 'Adam', 'adam_learning_rate': 0.00755110127673275}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 50.3094 - mse: 50.3094 - val_loss: 36.1515 - val_mse: 36.1515\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 28.3009 - mse: 28.3009 - val_loss: 28.7501 - val_mse: 28.7501\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 26.2831 - mse: 26.2831 - val_loss: 29.8600 - val_mse: 29.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:20:18,524]\u001b[0m Trial 13 finished with value: 29.86000111848165 and parameters: {'n_layers': 3, 'weight_decay': 2.2300489272818375e-10, 'dropout': 0.4065930680741262, 'n_units_l0': 157, 'n_units_l1': 112, 'n_units_l2': 165, 'optimizer': 'Adam', 'adam_learning_rate': 0.00444376159519675}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 18s - loss: 500.6820 - mse: 499.9070 - val_loss: 429.3051 - val_mse: 428.5290\n",
      "Epoch 2/3\n",
      "57/57 - 16s - loss: 135.7867 - mse: 135.0086 - val_loss: 178.5393 - val_mse: 177.7594\n",
      "Epoch 3/3\n",
      "57/57 - 16s - loss: 41.0178 - mse: 40.2377 - val_loss: 128.8468 - val_mse: 128.0672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:08,766]\u001b[0m Trial 14 finished with value: 128.06719664654884 and parameters: {'n_layers': 5, 'weight_decay': 0.0008458907912218102, 'dropout': 0.49894630341746804, 'n_units_l0': 226, 'n_units_l1': 142, 'n_units_l2': 101, 'n_units_l3': 247, 'n_units_l4': 239, 'optimizer': 'Adam', 'adam_learning_rate': 1.1372062448678147e-05}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 80.9233 - mse: 80.9232 - val_loss: 35.4760 - val_mse: 35.4760\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 33.3580 - mse: 33.3579 - val_loss: 31.8423 - val_mse: 31.8422\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 27.5976 - mse: 27.5976 - val_loss: 29.3794 - val_mse: 29.3793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:17,369]\u001b[0m Trial 15 finished with value: 29.379326810046393 and parameters: {'n_layers': 3, 'weight_decay': 8.338686452279643e-08, 'dropout': 0.388802369072987, 'n_units_l0': 137, 'n_units_l1': 46, 'n_units_l2': 196, 'optimizer': 'Adam', 'adam_learning_rate': 0.0013696260166765222}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 2867.4824 - mse: 2867.4824 - val_loss: 689.4162 - val_mse: 689.4162\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 673.1593 - mse: 673.1593 - val_loss: 650.2180 - val_mse: 650.2180\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 631.3121 - mse: 631.3121 - val_loss: 606.5437 - val_mse: 606.5437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:21:26,852]\u001b[0m Trial 16 finished with value: 606.5436673768583 and parameters: {'n_layers': 2, 'weight_decay': 1.9772332223061944e-10, 'dropout': 0.4426731258175413, 'n_units_l0': 188, 'n_units_l1': 92, 'optimizer': 'Adam', 'adam_learning_rate': 0.02394270393204498}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 13s - loss: 82.5312 - mse: 82.4750 - val_loss: 57.8815 - val_mse: 57.8249\n",
      "Epoch 2/3\n",
      "57/57 - 11s - loss: 34.8612 - mse: 34.8049 - val_loss: 55.2454 - val_mse: 55.1890\n",
      "Epoch 3/3\n",
      "57/57 - 11s - loss: 29.5894 - mse: 29.5323 - val_loss: 43.6965 - val_mse: 43.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:02,756]\u001b[0m Trial 17 finished with value: 43.638649585545885 and parameters: {'n_layers': 5, 'weight_decay': 8.216996498690948e-05, 'dropout': 0.28196079728961937, 'n_units_l0': 86, 'n_units_l1': 48, 'n_units_l2': 128, 'n_units_l3': 256, 'n_units_l4': 170, 'optimizer': 'Adam', 'adam_learning_rate': 0.00039066303299003456}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 61.6411 - mse: 61.6411 - val_loss: 32.8593 - val_mse: 32.8593\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 27.6336 - mse: 27.6336 - val_loss: 28.3325 - val_mse: 28.3325\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 26.4130 - mse: 26.4130 - val_loss: 29.1114 - val_mse: 29.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:15,651]\u001b[0m Trial 18 finished with value: 29.111418623157356 and parameters: {'n_layers': 3, 'weight_decay': 2.054742568659157e-09, 'dropout': 0.45710366263024144, 'n_units_l0': 126, 'n_units_l1': 170, 'n_units_l2': 33, 'optimizer': 'Adam', 'adam_learning_rate': 0.003201632483320692}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 2140.1375 - mse: 2135.7104 - val_loss: 693.2656 - val_mse: 687.5241\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 676.6662 - mse: 671.1623 - val_loss: 653.5881 - val_mse: 648.3418\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 634.9263 - mse: 629.9004 - val_loss: 610.5805 - val_mse: 605.7706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:26,671]\u001b[0m Trial 19 finished with value: 605.7706593376925 and parameters: {'n_layers': 2, 'weight_decay': 9.461140346895783e-05, 'dropout': 0.37602704313862817, 'n_units_l0': 202, 'n_units_l1': 98, 'optimizer': 'Adam', 'adam_learning_rate': 0.021103643524652636}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 9s - loss: 196.6569 - mse: 196.6567 - val_loss: 70.2782 - val_mse: 70.2780\n",
      "Epoch 2/3\n",
      "57/57 - 7s - loss: 38.7361 - mse: 38.7359 - val_loss: 56.6035 - val_mse: 56.6033\n",
      "Epoch 3/3\n",
      "57/57 - 7s - loss: 36.4752 - mse: 36.4750 - val_loss: 55.7984 - val_mse: 55.7982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:22:50,632]\u001b[0m Trial 20 finished with value: 55.798253132713306 and parameters: {'n_layers': 5, 'weight_decay': 3.675608617804447e-07, 'dropout': 0.2758830291760725, 'n_units_l0': 34, 'n_units_l1': 140, 'n_units_l2': 87, 'n_units_l3': 144, 'n_units_l4': 113, 'optimizer': 'Adam', 'adam_learning_rate': 9.596974441162018e-05}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 81.7442 - mse: 81.7442 - val_loss: 34.3258 - val_mse: 34.3258\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 31.2114 - mse: 31.2114 - val_loss: 34.6698 - val_mse: 34.6698\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 27.0908 - mse: 27.0908 - val_loss: 29.7779 - val_mse: 29.7779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:06,018]\u001b[0m Trial 21 finished with value: 29.777889398461728 and parameters: {'n_layers': 3, 'weight_decay': 3.1732510618198037e-09, 'dropout': 0.452178879146484, 'n_units_l0': 130, 'n_units_l1': 197, 'n_units_l2': 33, 'optimizer': 'Adam', 'adam_learning_rate': 0.002316274151803358}. Best is trial 2 with value: 28.254984416565467.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 138.7737 - mse: 138.7737 - val_loss: 28.9294 - val_mse: 28.9294\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 27.7768 - mse: 27.7767 - val_loss: 31.2142 - val_mse: 31.2142\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 27.5862 - mse: 27.5862 - val_loss: 27.9788 - val_mse: 27.9788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:19,851]\u001b[0m Trial 22 finished with value: 27.978829375675037 and parameters: {'n_layers': 3, 'weight_decay': 2.5708886545439426e-09, 'dropout': 0.4727970804211236, 'n_units_l0': 107, 'n_units_l1': 179, 'n_units_l2': 52, 'optimizer': 'Adam', 'adam_learning_rate': 0.009678567808334761}. Best is trial 22 with value: 27.978829375675037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 170.2288 - mse: 170.2288 - val_loss: 28.2349 - val_mse: 28.2349\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 29.2907 - mse: 29.2907 - val_loss: 32.4857 - val_mse: 32.4857\n",
      "Epoch 3/3\n",
      "57/57 - 3s - loss: 29.5218 - mse: 29.5218 - val_loss: 28.0499 - val_mse: 28.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:30,575]\u001b[0m Trial 23 finished with value: 28.049881821066517 and parameters: {'n_layers': 3, 'weight_decay': 1.059997296351158e-09, 'dropout': 0.4914789815861243, 'n_units_l0': 93, 'n_units_l1': 131, 'n_units_l2': 53, 'optimizer': 'Adam', 'adam_learning_rate': 0.01300293140183376}. Best is trial 22 with value: 27.978829375675037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 9193.4033 - mse: 9193.4033 - val_loss: 27.8859 - val_mse: 27.8858\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 28.2492 - mse: 28.2491 - val_loss: 30.1537 - val_mse: 30.1536\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 29.5559 - mse: 29.5558 - val_loss: 27.8416 - val_mse: 27.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:44,250]\u001b[0m Trial 24 finished with value: 27.841527005258172 and parameters: {'n_layers': 3, 'weight_decay': 8.729089720517217e-10, 'dropout': 0.42323817551994997, 'n_units_l0': 97, 'n_units_l1': 182, 'n_units_l2': 47, 'optimizer': 'Adam', 'adam_learning_rate': 0.042482576564781424}. Best is trial 24 with value: 27.841527005258172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 422056.2500 - mse: 422056.2500 - val_loss: 30.5675 - val_mse: 30.5670\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 30.6746 - mse: 30.6741 - val_loss: 27.5096 - val_mse: 27.5092\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 30.0503 - mse: 30.0498 - val_loss: 27.3311 - val_mse: 27.3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:23:58,661]\u001b[0m Trial 25 finished with value: 27.330630826631783 and parameters: {'n_layers': 3, 'weight_decay': 9.910329572923246e-10, 'dropout': 0.46847223886509404, 'n_units_l0': 92, 'n_units_l1': 211, 'n_units_l2': 49, 'optimizer': 'Adam', 'adam_learning_rate': 0.08168401117609635}. Best is trial 25 with value: 27.330630826631783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 53715.5352 - mse: 53715.5352 - val_loss: 710.1827 - val_mse: 710.1823\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 693.6389 - mse: 693.6382 - val_loss: 669.4763 - val_mse: 669.4760\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 647.9984 - mse: 647.9979 - val_loss: 619.7678 - val_mse: 619.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:24:04,201]\u001b[0m Trial 26 finished with value: 619.7673593697936 and parameters: {'n_layers': 2, 'weight_decay': 5.673060444657546e-10, 'dropout': 0.3535685200595091, 'n_units_l0': 50, 'n_units_l1': 196, 'optimizer': 'Adam', 'adam_learning_rate': 0.0991091488031583}. Best is trial 25 with value: 27.330630826631783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 10358.8955 - mse: 10358.8955 - val_loss: 693.3735 - val_mse: 693.3720\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 675.0618 - mse: 675.0600 - val_loss: 649.2720 - val_mse: 649.2704\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 626.4964 - mse: 626.4948 - val_loss: 597.2244 - val_mse: 597.2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:24:18,380]\u001b[0m Trial 27 finished with value: 597.222833458968 and parameters: {'n_layers': 3, 'weight_decay': 9.777106165732721e-09, 'dropout': 0.39569971102854773, 'n_units_l0': 80, 'n_units_l1': 214, 'n_units_l2': 45, 'optimizer': 'Adam', 'adam_learning_rate': 0.048893151681758014}. Best is trial 25 with value: 27.330630826631783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 705.7847 - mse: 705.7847 - val_loss: 702.2695 - val_mse: 702.2695\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 703.0002 - mse: 703.0002 - val_loss: 701.3283 - val_mse: 701.3283\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 702.0391 - mse: 702.0391 - val_loss: 700.7772 - val_mse: 700.7772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:24:31,954]\u001b[0m Trial 28 finished with value: 700.777153898819 and parameters: {'n_layers': 4, 'weight_decay': 1.0084889637154194e-10, 'dropout': 0.47031654736480816, 'n_units_l0': 108, 'n_units_l1': 167, 'n_units_l2': 44, 'n_units_l3': 62, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 1.5615704622353126e-05, 'rmsprop_decay': 0.9873015011632789, 'rmsprop_momentum': 0.09967324124151511}. Best is trial 25 with value: 27.330630826631783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 74.7981 - mse: 74.7981 - val_loss: 35.9552 - val_mse: 35.9552\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 37.8162 - mse: 37.8162 - val_loss: 30.2833 - val_mse: 30.2833\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 32.0687 - mse: 32.0687 - val_loss: 29.4195 - val_mse: 29.4195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:24:48,106]\u001b[0m Trial 29 finished with value: 29.419479286799138 and parameters: {'n_layers': 3, 'weight_decay': 4.359905523336647e-08, 'dropout': 0.33378176285774325, 'n_units_l0': 62, 'n_units_l1': 224, 'n_units_l2': 72, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.00043958897116046816, 'sgd_opt_momentum': 2.2595767956338383e-05}. Best is trial 25 with value: 27.330630826631783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 2s - loss: 37385.2188 - mse: 37324.2383 - val_loss: 91.5345 - val_mse: 28.3231\n",
      "Epoch 2/3\n",
      "57/57 - 1s - loss: 91.2394 - mse: 28.0280 - val_loss: 91.4083 - val_mse: 28.1969\n",
      "Epoch 3/3\n",
      "57/57 - 1s - loss: 91.2567 - mse: 28.0453 - val_loss: 91.3771 - val_mse: 28.1657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:24:53,322]\u001b[0m Trial 30 finished with value: 28.165718094913107 and parameters: {'n_layers': 2, 'weight_decay': 4.462771952723796e-09, 'dropout': 0.42823706039262344, 'n_units_l0': 64, 'n_units_l1': 156, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.047678744242537624, 'sgd_opt_momentum': 0.00035794519291020753}. Best is trial 25 with value: 27.330630826631783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 4751.7788 - mse: 4751.7788 - val_loss: 27.9910 - val_mse: 27.9909\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 29.6912 - mse: 29.6911 - val_loss: 28.9960 - val_mse: 28.9959\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 30.4304 - mse: 30.4303 - val_loss: 27.6732 - val_mse: 27.6731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:25:10,385]\u001b[0m Trial 31 finished with value: 27.67307773156889 and parameters: {'n_layers': 3, 'weight_decay': 1.1210690250433873e-09, 'dropout': 0.4689257079145155, 'n_units_l0': 92, 'n_units_l1': 255, 'n_units_l2': 53, 'optimizer': 'Adam', 'adam_learning_rate': 0.028183113695264345}. Best is trial 25 with value: 27.330630826631783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 10125.5615 - mse: 10125.5615 - val_loss: 28.9099 - val_mse: 28.9099\n",
      "Epoch 2/3\n",
      "57/57 - 6s - loss: 29.9481 - mse: 29.9480 - val_loss: 28.4800 - val_mse: 28.4799\n",
      "Epoch 3/3\n",
      "57/57 - 6s - loss: 30.7147 - mse: 30.7146 - val_loss: 28.5543 - val_mse: 28.5542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:25:28,928]\u001b[0m Trial 32 finished with value: 28.554216196876066 and parameters: {'n_layers': 3, 'weight_decay': 5.954004180388517e-10, 'dropout': 0.4528172314997274, 'n_units_l0': 96, 'n_units_l1': 237, 'n_units_l2': 52, 'optimizer': 'Adam', 'adam_learning_rate': 0.03483088456574335}. Best is trial 25 with value: 27.330630826631783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 9429.9482 - mse: 9429.9482 - val_loss: 27.8138 - val_mse: 27.8138\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 28.1957 - mse: 28.1957 - val_loss: 27.5488 - val_mse: 27.5488\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 29.3753 - mse: 29.3752 - val_loss: 27.7722 - val_mse: 27.7722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:25:43,621]\u001b[0m Trial 33 finished with value: 27.772146821118785 and parameters: {'n_layers': 3, 'weight_decay': 7.084899527718513e-10, 'dropout': 0.47126238301681367, 'n_units_l0': 110, 'n_units_l1': 195, 'n_units_l2': 37, 'optimizer': 'Adam', 'adam_learning_rate': 0.03538035871698444}. Best is trial 25 with value: 27.330630826631783.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 73080.6797 - mse: 73080.6797 - val_loss: 28.4073 - val_mse: 28.4071\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 27.5571 - mse: 27.5569 - val_loss: 30.1193 - val_mse: 30.1192\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 30.0229 - mse: 30.0228 - val_loss: 27.2853 - val_mse: 27.2852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:25:59,628]\u001b[0m Trial 34 finished with value: 27.2851779355128 and parameters: {'n_layers': 3, 'weight_decay': 8.558289493680922e-10, 'dropout': 0.4281567473969501, 'n_units_l0': 84, 'n_units_l1': 255, 'n_units_l2': 38, 'optimizer': 'Adam', 'adam_learning_rate': 0.05544189687127445}. Best is trial 34 with value: 27.2851779355128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 129.7722 - mse: 129.7722 - val_loss: 33.6911 - val_mse: 33.6911\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 48.4659 - mse: 48.4659 - val_loss: 32.9842 - val_mse: 32.9842\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 33.4079 - mse: 33.4079 - val_loss: 29.3860 - val_mse: 29.3860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:26:14,761]\u001b[0m Trial 35 finished with value: 29.38599172518123 and parameters: {'n_layers': 4, 'weight_decay': 3.121698937773043e-10, 'dropout': 0.43384695275399127, 'n_units_l0': 83, 'n_units_l1': 255, 'n_units_l2': 38, 'n_units_l3': 32, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.0005265951483741977, 'sgd_opt_momentum': 0.00023702585672794616}. Best is trial 34 with value: 27.2851779355128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 924162.0625 - mse: 924162.0625 - val_loss: 728.0449 - val_mse: 728.0406\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 725.9607 - mse: 725.9567 - val_loss: 718.1260 - val_mse: 718.1219\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 714.4075 - mse: 714.4033 - val_loss: 705.1311 - val_mse: 705.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:26:36,412]\u001b[0m Trial 36 finished with value: 705.126998975301 and parameters: {'n_layers': 3, 'weight_decay': 8.035282644936049e-09, 'dropout': 0.4111186791829031, 'n_units_l0': 72, 'n_units_l1': 207, 'n_units_l2': 38, 'optimizer': 'Adam', 'adam_learning_rate': 0.09668358837089477}. Best is trial 34 with value: 27.2851779355128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 7s - loss: 822.0500 - mse: 822.0491 - val_loss: 35.3255 - val_mse: 35.3245\n",
      "Epoch 2/3\n",
      "57/57 - 6s - loss: 29.8811 - mse: 29.8802 - val_loss: 30.3839 - val_mse: 30.3830\n",
      "Epoch 3/3\n",
      "57/57 - 6s - loss: 29.7699 - mse: 29.7690 - val_loss: 27.9608 - val_mse: 27.9598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:26:58,377]\u001b[0m Trial 37 finished with value: 27.959815076003274 and parameters: {'n_layers': 4, 'weight_decay': 4.403078317981426e-08, 'dropout': 0.2979153877118896, 'n_units_l0': 114, 'n_units_l1': 255, 'n_units_l2': 39, 'n_units_l3': 130, 'optimizer': 'Adam', 'adam_learning_rate': 0.023049341199354107}. Best is trial 34 with value: 27.2851779355128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 596.7861 - mse: 596.7861 - val_loss: 451.0679 - val_mse: 451.0679\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 278.0437 - mse: 278.0437 - val_loss: 127.5567 - val_mse: 127.5567\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 72.1498 - mse: 72.1498 - val_loss: 51.2622 - val_mse: 51.2622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:27:14,058]\u001b[0m Trial 38 finished with value: 51.262174184627284 and parameters: {'n_layers': 3, 'weight_decay': 1.0531120401176046e-10, 'dropout': 0.23819945377557403, 'n_units_l0': 51, 'n_units_l1': 225, 'n_units_l2': 66, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 1.0372258609259324e-05, 'sgd_opt_momentum': 0.0029273788505651144}. Best is trial 34 with value: 27.2851779355128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 6719.6880 - mse: 6719.6880 - val_loss: 30.2873 - val_mse: 30.2873\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 34.4450 - mse: 34.4449 - val_loss: 32.6751 - val_mse: 32.6751\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 32.3826 - mse: 32.3826 - val_loss: 28.0513 - val_mse: 28.0513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:27:27,396]\u001b[0m Trial 39 finished with value: 28.051275980872823 and parameters: {'n_layers': 4, 'weight_decay': 1.1839948404605603e-09, 'dropout': 0.4742151547976146, 'n_units_l0': 65, 'n_units_l1': 193, 'n_units_l2': 33, 'n_units_l3': 65, 'optimizer': 'Adam', 'adam_learning_rate': 0.046454870329442406}. Best is trial 34 with value: 27.2851779355128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 614.1625 - mse: 614.1625 - val_loss: 595.8076 - val_mse: 595.8076\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 591.5405 - mse: 591.5405 - val_loss: 586.0079 - val_mse: 586.0079\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 584.0381 - mse: 584.0381 - val_loss: 580.3391 - val_mse: 580.3391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:27:39,228]\u001b[0m Trial 40 finished with value: 580.339086868718 and parameters: {'n_layers': 2, 'weight_decay': 2.5827809194860022e-08, 'dropout': 0.3780127681534681, 'n_units_l0': 115, 'n_units_l1': 230, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 2.134449116632509e-05, 'rmsprop_decay': 0.8505419139772782, 'rmsprop_momentum': 0.0032027896063013426}. Best is trial 34 with value: 27.2851779355128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 8785.1328 - mse: 8785.1328 - val_loss: 30.1725 - val_mse: 30.1724\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 28.2682 - mse: 28.2682 - val_loss: 30.3636 - val_mse: 30.3636\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 29.2257 - mse: 29.2256 - val_loss: 28.2705 - val_mse: 28.2705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:27:52,228]\u001b[0m Trial 41 finished with value: 28.270471658238222 and parameters: {'n_layers': 3, 'weight_decay': 6.246222601409647e-10, 'dropout': 0.42376156664144216, 'n_units_l0': 98, 'n_units_l1': 184, 'n_units_l2': 45, 'optimizer': 'Adam', 'adam_learning_rate': 0.046485665381118355}. Best is trial 34 with value: 27.2851779355128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 4s - loss: 326.4826 - mse: 326.4826 - val_loss: 27.7033 - val_mse: 27.7033\n",
      "Epoch 2/3\n",
      "57/57 - 3s - loss: 28.1951 - mse: 28.1951 - val_loss: 29.1268 - val_mse: 29.1268\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 30.4702 - mse: 30.4702 - val_loss: 29.7782 - val_mse: 29.7781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:28:04,043]\u001b[0m Trial 42 finished with value: 29.778139624756594 and parameters: {'n_layers': 3, 'weight_decay': 1.5377784289363773e-09, 'dropout': 0.4679989169805244, 'n_units_l0': 87, 'n_units_l1': 150, 'n_units_l2': 49, 'optimizer': 'Adam', 'adam_learning_rate': 0.018311059189200715}. Best is trial 34 with value: 27.2851779355128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 5s - loss: 21239.5156 - mse: 21239.5156 - val_loss: 29.0988 - val_mse: 29.0979\n",
      "Epoch 2/3\n",
      "57/57 - 4s - loss: 31.1462 - mse: 31.1452 - val_loss: 28.9352 - val_mse: 28.9343\n",
      "Epoch 3/3\n",
      "57/57 - 4s - loss: 31.0843 - mse: 31.0834 - val_loss: 28.3606 - val_mse: 28.3597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:28:18,156]\u001b[0m Trial 43 finished with value: 28.359664340881242 and parameters: {'n_layers': 3, 'weight_decay': 4.629892775550506e-09, 'dropout': 0.4384517613895958, 'n_units_l0': 74, 'n_units_l1': 211, 'n_units_l2': 56, 'optimizer': 'Adam', 'adam_learning_rate': 0.048926594716150476}. Best is trial 34 with value: 27.2851779355128.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 5910.5132 - mse: 5910.5132 - val_loss: 27.9318 - val_mse: 27.9317\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 28.7470 - mse: 28.7470 - val_loss: 32.2382 - val_mse: 32.2382\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 29.3983 - mse: 29.3983 - val_loss: 27.2274 - val_mse: 27.2274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:28:35,072]\u001b[0m Trial 44 finished with value: 27.227378186785227 and parameters: {'n_layers': 3, 'weight_decay': 3.37892125327874e-10, 'dropout': 0.4011325919110404, 'n_units_l0': 101, 'n_units_l1': 252, 'n_units_l2': 41, 'optimizer': 'Adam', 'adam_learning_rate': 0.03185205571299494}. Best is trial 44 with value: 27.227378186785227.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 569.7445 - mse: 569.7445 - val_loss: 28.0197 - val_mse: 28.0197\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 30.4067 - mse: 30.4066 - val_loss: 31.2955 - val_mse: 31.2955\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 31.9062 - mse: 31.9062 - val_loss: 27.8861 - val_mse: 27.8861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:28:52,487]\u001b[0m Trial 45 finished with value: 27.886111729088647 and parameters: {'n_layers': 4, 'weight_decay': 3.748621403265139e-10, 'dropout': 0.40774569724616805, 'n_units_l0': 78, 'n_units_l1': 256, 'n_units_l2': 41, 'n_units_l3': 193, 'optimizer': 'Adam', 'adam_learning_rate': 0.01666092617348301}. Best is trial 44 with value: 27.227378186785227.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 104.4859 - mse: 104.4858 - val_loss: 51.1065 - val_mse: 51.1064\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 44.7739 - mse: 44.7738 - val_loss: 40.1385 - val_mse: 40.1385\n",
      "Epoch 3/3\n",
      "57/57 - 5s - loss: 39.9762 - mse: 39.9762 - val_loss: 38.0564 - val_mse: 38.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:29:08,691]\u001b[0m Trial 46 finished with value: 38.056365320863954 and parameters: {'n_layers': 3, 'weight_decay': 1.6180421025007889e-07, 'dropout': 0.24913944326167498, 'n_units_l0': 120, 'n_units_l1': 230, 'n_units_l2': 36, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.00038287445037056696, 'rmsprop_decay': 0.9898084361993617, 'rmsprop_momentum': 1.2460731995193027e-05}. Best is trial 44 with value: 27.227378186785227.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 23603.5566 - mse: 23603.5566 - val_loss: 29.0147 - val_mse: 29.0147\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 28.7561 - mse: 28.7560 - val_loss: 27.7916 - val_mse: 27.7915\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 29.9658 - mse: 29.9658 - val_loss: 28.2818 - val_mse: 28.2817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:29:16,587]\u001b[0m Trial 47 finished with value: 28.281742859911475 and parameters: {'n_layers': 3, 'weight_decay': 2.576211004294938e-10, 'dropout': 0.3885743509799957, 'n_units_l0': 105, 'n_units_l1': 77, 'n_units_l2': 42, 'optimizer': 'Adam', 'adam_learning_rate': 0.06910904308426333}. Best is trial 44 with value: 27.227378186785227.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 3s - loss: 3109.0295 - mse: 3109.0291 - val_loss: 683.4346 - val_mse: 683.4338\n",
      "Epoch 2/3\n",
      "57/57 - 2s - loss: 661.1122 - mse: 661.1113 - val_loss: 631.6107 - val_mse: 631.6097\n",
      "Epoch 3/3\n",
      "57/57 - 2s - loss: 606.1624 - mse: 606.1614 - val_loss: 574.7182 - val_mse: 574.7174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:29:23,446]\u001b[0m Trial 48 finished with value: 574.7173915517458 and parameters: {'n_layers': 2, 'weight_decay': 7.037809448508662e-09, 'dropout': 0.4851232106938493, 'n_units_l0': 69, 'n_units_l1': 208, 'optimizer': 'Adam', 'adam_learning_rate': 0.03330227337096342}. Best is trial 44 with value: 27.227378186785227.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "57/57 - 6s - loss: 84.3646 - mse: 84.3646 - val_loss: 32.0145 - val_mse: 32.0145\n",
      "Epoch 2/3\n",
      "57/57 - 5s - loss: 28.3573 - mse: 28.3573 - val_loss: 28.6048 - val_mse: 28.6048\n",
      "Epoch 3/3\n",
      "57/57 - 6s - loss: 27.7443 - mse: 27.7442 - val_loss: 31.8377 - val_mse: 31.8377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-04 11:29:40,972]\u001b[0m Trial 49 finished with value: 31.83766332006469 and parameters: {'n_layers': 3, 'weight_decay': 1.7062205535735276e-08, 'dropout': 0.45311125865801727, 'n_units_l0': 90, 'n_units_l1': 244, 'n_units_l2': 59, 'optimizer': 'Adam', 'adam_learning_rate': 0.005888201939562859}. Best is trial 44 with value: 27.227378186785227.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Mencari hyperparameters terbaik.\n",
    "try:\n",
    "    study = optuna.create_study(sampler = TPESampler(seed = seed), direction = 'minimize')\n",
    "    study.optimize(objective, n_trials = 50)\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12e81c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:41.247147Z",
     "iopub.status.busy": "2021-11-04T11:29:41.246438Z",
     "iopub.status.idle": "2021-11-04T11:29:41.252137Z",
     "shell.execute_reply": "2021-11-04T11:29:41.252733Z",
     "shell.execute_reply.started": "2021-11-04T10:25:54.753997Z"
    },
    "papermill": {
     "duration": 0.140419,
     "end_time": "2021-11-04T11:29:41.252924",
     "exception": false,
     "start_time": "2021-11-04T11:29:41.112505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 3,\n",
       " 'weight_decay': 3.37892125327874e-10,\n",
       " 'dropout': 0.4011325919110404,\n",
       " 'n_units_l0': 101,\n",
       " 'n_units_l1': 252,\n",
       " 'n_units_l2': 41,\n",
       " 'optimizer': 'Adam',\n",
       " 'adam_learning_rate': 0.03185205571299494}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan parameter-parameter terbaik.\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8757efe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:41.519930Z",
     "iopub.status.busy": "2021-11-04T11:29:41.518886Z",
     "iopub.status.idle": "2021-11-04T11:29:41.533973Z",
     "shell.execute_reply": "2021-11-04T11:29:41.534471Z",
     "shell.execute_reply.started": "2021-11-04T10:26:02.784876Z"
    },
    "papermill": {
     "duration": 0.150224,
     "end_time": "2021-11-04T11:29:41.534653",
     "exception": false,
     "start_time": "2021-11-04T11:29:41.384429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Membangun model.\n",
    "def prepare_model():\n",
    "    model = Sequential(name = 'Sequential')\n",
    "    n_layers = study.best_params['n_layers']\n",
    "    for i in range(n_layers-1):\n",
    "        num_hidden = study.best_params['n_units_l{}'.format(i)]\n",
    "        if i:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                            name = 'Dense_{}'.format(i)))\n",
    "            model.add(Dropout(study.best_params['dropout'],\n",
    "                              name = 'Dropout_{}'.format(i)))\n",
    "        else:\n",
    "            model.add(Dense(num_hidden,\n",
    "                            activation = 'relu',\n",
    "                            kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                            input_shape = (X_train.shape[1], 1),\n",
    "                            name = 'Dense_{}'.format(i)))\n",
    "    model.add(Flatten(name = 'Flatten'))\n",
    "    num_hidden = study.best_params['n_units_l{}'.format(n_layers-1)]\n",
    "    model.add(Dense(num_hidden,\n",
    "                    activation = 'relu',\n",
    "                    kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                    name = 'Dense_{}'.format(n_layers-1)))\n",
    "    model.add(Dense(1,\n",
    "                    activation = 'linear',\n",
    "                    kernel_regularizer = regularizers.l2(study.best_params['weight_decay']),\n",
    "                    name = 'Final_Dense'))\n",
    "    \n",
    "    # Mendefinisikan optimizer.\n",
    "    kwargs = {}\n",
    "    optimizer_selected = study.best_params['optimizer']\n",
    "    if optimizer_selected == 'RMSprop':\n",
    "        kwargs['learning_rate'] = study.best_params['rmsprop_learning_rate']\n",
    "        kwargs['decay'] = study.best_params['rmsprop_decay']\n",
    "        kwargs['momentum'] = study.best_params['rmsprop_momentum']\n",
    "    elif optimizer_selected == 'Adam':\n",
    "        kwargs['learning_rate'] = study.best_params['adam_learning_rate']\n",
    "    elif optimizer_selected == 'SGD':\n",
    "        kwargs['learning_rate'] = study.best_params['sgd_opt_learning_rate']\n",
    "        kwargs['momentum'] = study.best_params['sgd_opt_momentum']    \n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "    \n",
    "    # Mengkompilasi model.\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = 'mean_squared_error',\n",
    "                  metrics = ['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51606a89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:41.810121Z",
     "iopub.status.busy": "2021-11-04T11:29:41.809387Z",
     "iopub.status.idle": "2021-11-04T11:29:41.908531Z",
     "shell.execute_reply": "2021-11-04T11:29:41.907995Z",
     "shell.execute_reply.started": "2021-11-04T10:26:07.607163Z"
    },
    "papermill": {
     "duration": 0.236325,
     "end_time": "2021-11-04T11:29:41.908679",
     "exception": false,
     "start_time": "2021-11-04T11:29:41.672354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_0 (Dense)              (None, 265, 101)          202       \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 265, 252)          25704     \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 265, 252)          0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 66780)             0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 41)                2738021   \n",
      "_________________________________________________________________\n",
      "Final_Dense (Dense)          (None, 1)                 42        \n",
      "=================================================================\n",
      "Total params: 2,763,969\n",
      "Trainable params: 2,763,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan ringkasan dari model.\n",
    "model = prepare_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "031ccf5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:42.179649Z",
     "iopub.status.busy": "2021-11-04T11:29:42.178969Z",
     "iopub.status.idle": "2021-11-04T11:29:42.182157Z",
     "shell.execute_reply": "2021-11-04T11:29:42.181601Z",
     "shell.execute_reply.started": "2021-11-04T10:26:14.472587Z"
    },
    "papermill": {
     "duration": 0.139909,
     "end_time": "2021-11-04T11:29:42.182303",
     "exception": false,
     "start_time": "2021-11-04T11:29:42.042394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menetapkan batasan untuk berhenti melanjutkan epoch lebih awal.\n",
    "earlystop = EarlyStopping(patience = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f70a85f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:42.455822Z",
     "iopub.status.busy": "2021-11-04T11:29:42.455130Z",
     "iopub.status.idle": "2021-11-04T11:29:42.459383Z",
     "shell.execute_reply": "2021-11-04T11:29:42.459911Z",
     "shell.execute_reply.started": "2021-11-04T10:26:17.623786Z"
    },
    "papermill": {
     "duration": 0.139224,
     "end_time": "2021-11-04T11:29:42.460085",
     "exception": false,
     "start_time": "2021-11-04T11:29:42.320861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menetapkan batasan untuk learning rate.\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_mse', \n",
    "                                            patience = 8,\n",
    "                                            verbose = 1,\n",
    "                                            factor = 0.5,\n",
    "                                            mode = 'min',\n",
    "                                            min_lr = 1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d80e1255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:42.736521Z",
     "iopub.status.busy": "2021-11-04T11:29:42.731917Z",
     "iopub.status.idle": "2021-11-04T11:29:42.738625Z",
     "shell.execute_reply": "2021-11-04T11:29:42.739272Z",
     "shell.execute_reply.started": "2021-11-04T10:26:20.705731Z"
    },
    "papermill": {
     "duration": 0.144868,
     "end_time": "2021-11-04T11:29:42.739452",
     "exception": false,
     "start_time": "2021-11-04T11:29:42.594584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Membentuk kelas guna menyimpan output prediksi validasi dan testing untuk setiap epoch.\n",
    "class Metrics(Callback):\n",
    "    def __init__(self, valid_data, test_data):\n",
    "        super().__init__()\n",
    "        self.valid_data = valid_data\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_valid_pred = self.model.predict(self.valid_data)\n",
    "        y_test_pred = self.model.predict(self.test_data)\n",
    "        pd.DataFrame(y_valid_pred).to_csv('valid_preds_{}.csv'.format(epoch), index = False)\n",
    "        pd.DataFrame(y_test_pred).to_csv('test_preds_{}.csv'.format(epoch), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85086318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:29:43.040920Z",
     "iopub.status.busy": "2021-11-04T11:29:43.040233Z",
     "iopub.status.idle": "2021-11-04T11:33:47.579526Z",
     "shell.execute_reply": "2021-11-04T11:33:47.580086Z",
     "shell.execute_reply.started": "2021-11-04T10:26:23.335319Z"
    },
    "papermill": {
     "duration": 244.704956,
     "end_time": "2021-11-04T11:33:47.580284",
     "exception": false,
     "start_time": "2021-11-04T11:29:42.875328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "57/57 - 6s - loss: 5910.5132 - mse: 5910.5132 - val_loss: 27.9318 - val_mse: 27.9317\n",
      "Epoch 2/128\n",
      "57/57 - 5s - loss: 28.7470 - mse: 28.7470 - val_loss: 32.2382 - val_mse: 32.2382\n",
      "Epoch 3/128\n",
      "57/57 - 5s - loss: 29.3983 - mse: 29.3983 - val_loss: 27.2274 - val_mse: 27.2274\n",
      "Epoch 4/128\n",
      "57/57 - 5s - loss: 28.5980 - mse: 28.5980 - val_loss: 29.2852 - val_mse: 29.2852\n",
      "Epoch 5/128\n",
      "57/57 - 5s - loss: 27.4400 - mse: 27.4400 - val_loss: 29.0428 - val_mse: 29.0427\n",
      "Epoch 6/128\n",
      "57/57 - 5s - loss: 27.8282 - mse: 27.8282 - val_loss: 27.8795 - val_mse: 27.8794\n",
      "Epoch 7/128\n",
      "57/57 - 5s - loss: 26.8945 - mse: 26.8945 - val_loss: 28.8298 - val_mse: 28.8298\n",
      "Epoch 8/128\n",
      "57/57 - 5s - loss: 27.3276 - mse: 27.3276 - val_loss: 28.5040 - val_mse: 28.5040\n",
      "Epoch 9/128\n",
      "57/57 - 5s - loss: 27.3573 - mse: 27.3573 - val_loss: 28.3811 - val_mse: 28.3810\n",
      "Epoch 10/128\n",
      "57/57 - 5s - loss: 26.6301 - mse: 26.6300 - val_loss: 28.9831 - val_mse: 28.9831\n",
      "Epoch 11/128\n",
      "57/57 - 5s - loss: 26.9543 - mse: 26.9542 - val_loss: 30.2159 - val_mse: 30.2159\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.015926027670502663.\n",
      "Epoch 12/128\n",
      "57/57 - 5s - loss: 24.6274 - mse: 24.6273 - val_loss: 29.0357 - val_mse: 29.0357\n",
      "Epoch 13/128\n",
      "57/57 - 5s - loss: 24.9453 - mse: 24.9453 - val_loss: 32.0834 - val_mse: 32.0833\n",
      "Epoch 14/128\n",
      "57/57 - 5s - loss: 24.5045 - mse: 24.5045 - val_loss: 29.4866 - val_mse: 29.4865\n",
      "Epoch 15/128\n",
      "57/57 - 5s - loss: 25.3714 - mse: 25.3714 - val_loss: 29.9299 - val_mse: 29.9299\n",
      "Epoch 16/128\n",
      "57/57 - 5s - loss: 24.0599 - mse: 24.0599 - val_loss: 29.5737 - val_mse: 29.5736\n",
      "Epoch 17/128\n",
      "57/57 - 5s - loss: 24.5813 - mse: 24.5813 - val_loss: 36.6389 - val_mse: 36.6389\n",
      "Epoch 18/128\n",
      "57/57 - 5s - loss: 25.6816 - mse: 25.6816 - val_loss: 29.4480 - val_mse: 29.4479\n",
      "Epoch 19/128\n",
      "57/57 - 5s - loss: 24.8644 - mse: 24.8644 - val_loss: 30.2336 - val_mse: 30.2336\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.007963013835251331.\n",
      "Epoch 20/128\n",
      "57/57 - 5s - loss: 24.1962 - mse: 24.1962 - val_loss: 29.8012 - val_mse: 29.8012\n",
      "Epoch 21/128\n",
      "57/57 - 5s - loss: 23.9857 - mse: 23.9857 - val_loss: 30.0396 - val_mse: 30.0396\n",
      "Epoch 22/128\n",
      "57/57 - 5s - loss: 24.3260 - mse: 24.3259 - val_loss: 31.2733 - val_mse: 31.2732\n",
      "Epoch 23/128\n",
      "57/57 - 5s - loss: 23.9085 - mse: 23.9085 - val_loss: 29.7017 - val_mse: 29.7016\n",
      "Epoch 24/128\n",
      "57/57 - 5s - loss: 23.9694 - mse: 23.9694 - val_loss: 33.4372 - val_mse: 33.4371\n",
      "Epoch 25/128\n",
      "57/57 - 5s - loss: 23.8347 - mse: 23.8347 - val_loss: 30.8542 - val_mse: 30.8542\n",
      "Epoch 26/128\n",
      "57/57 - 5s - loss: 23.3500 - mse: 23.3500 - val_loss: 29.7263 - val_mse: 29.7263\n",
      "Epoch 27/128\n",
      "57/57 - 5s - loss: 23.1147 - mse: 23.1147 - val_loss: 29.8275 - val_mse: 29.8274\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.003981506917625666.\n",
      "Epoch 28/128\n",
      "57/57 - 6s - loss: 22.8243 - mse: 22.8242 - val_loss: 29.9705 - val_mse: 29.9705\n",
      "Epoch 29/128\n",
      "57/57 - 5s - loss: 22.6721 - mse: 22.6721 - val_loss: 29.9846 - val_mse: 29.9846\n",
      "Epoch 30/128\n",
      "57/57 - 5s - loss: 22.8474 - mse: 22.8474 - val_loss: 29.9288 - val_mse: 29.9288\n",
      "Epoch 31/128\n",
      "57/57 - 5s - loss: 22.7327 - mse: 22.7327 - val_loss: 29.6973 - val_mse: 29.6973\n",
      "Epoch 32/128\n",
      "57/57 - 5s - loss: 22.8164 - mse: 22.8164 - val_loss: 29.8461 - val_mse: 29.8461\n",
      "Epoch 33/128\n",
      "57/57 - 5s - loss: 22.8728 - mse: 22.8728 - val_loss: 30.0950 - val_mse: 30.0950\n",
      "Epoch 34/128\n",
      "57/57 - 5s - loss: 22.3048 - mse: 22.3047 - val_loss: 30.0395 - val_mse: 30.0395\n",
      "Epoch 35/128\n",
      "57/57 - 5s - loss: 22.5615 - mse: 22.5615 - val_loss: 31.7353 - val_mse: 31.7353\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.001990753458812833.\n",
      "Epoch 36/128\n",
      "57/57 - 5s - loss: 22.2246 - mse: 22.2246 - val_loss: 30.0243 - val_mse: 30.0242\n",
      "Epoch 37/128\n",
      "57/57 - 5s - loss: 22.0632 - mse: 22.0632 - val_loss: 30.3391 - val_mse: 30.3390\n",
      "Epoch 38/128\n",
      "57/57 - 5s - loss: 22.5261 - mse: 22.5261 - val_loss: 29.8293 - val_mse: 29.8293\n",
      "Epoch 39/128\n",
      "57/57 - 5s - loss: 22.3548 - mse: 22.3548 - val_loss: 29.8785 - val_mse: 29.8785\n",
      "Epoch 40/128\n",
      "57/57 - 5s - loss: 22.1250 - mse: 22.1250 - val_loss: 30.1753 - val_mse: 30.1753\n",
      "Epoch 41/128\n",
      "57/57 - 5s - loss: 22.4196 - mse: 22.4196 - val_loss: 29.7240 - val_mse: 29.7239\n",
      "Epoch 42/128\n",
      "57/57 - 5s - loss: 22.0510 - mse: 22.0510 - val_loss: 29.8580 - val_mse: 29.8579\n",
      "Epoch 43/128\n",
      "57/57 - 5s - loss: 22.4262 - mse: 22.4262 - val_loss: 30.0174 - val_mse: 30.0174\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0009953767294064164.\n"
     ]
    }
   ],
   "source": [
    "# Melakukan fitting model.\n",
    "set_seed()\n",
    "model = prepare_model()\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                    verbose = 2,\n",
    "                    steps_per_epoch = X_train.shape[0] // batch_size,\n",
    "                    callbacks = [earlystop,\n",
    "                                 learning_rate_reduction,\n",
    "                                 Metrics(X_valid,\n",
    "                                         X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb4ecd14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:33:47.901048Z",
     "iopub.status.busy": "2021-11-04T11:33:47.900392Z",
     "iopub.status.idle": "2021-11-04T11:33:49.209375Z",
     "shell.execute_reply": "2021-11-04T11:33:49.208755Z",
     "shell.execute_reply.started": "2021-11-04T08:32:50.263585Z"
    },
    "papermill": {
     "duration": 1.470579,
     "end_time": "2021-11-04T11:33:49.209518",
     "exception": false,
     "start_time": "2021-11-04T11:33:47.738939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Melakukan visualisasi nilai MSE pada data training dan testing.\n",
    "fig, ax = plt.subplots(1, 1, figsize = (12, 12))\n",
    "ax.plot(history.history['mse'], color='b', label = 'training MSE')\n",
    "ax.plot(history.history['val_mse'], color='r', label = 'validation MSE')\n",
    "ax.set_xticks(np.arange(1, epochs, 1))\n",
    "legend = plt.legend(loc = 'best', shadow = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3694342f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:33:49.535632Z",
     "iopub.status.busy": "2021-11-04T11:33:49.535004Z",
     "iopub.status.idle": "2021-11-04T11:33:49.560645Z",
     "shell.execute_reply": "2021-11-04T11:33:49.561321Z",
     "shell.execute_reply.started": "2021-11-04T05:26:23.068789Z"
    },
    "papermill": {
     "duration": 0.189931,
     "end_time": "2021-11-04T11:33:49.561503",
     "exception": false,
     "start_time": "2021-11-04T11:33:49.371572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>29.398306</td>\n",
       "      <td>29.398285</td>\n",
       "      <td>27.227404</td>\n",
       "      <td>27.227379</td>\n",
       "      <td>0.031852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>27.828239</td>\n",
       "      <td>27.828220</td>\n",
       "      <td>27.879478</td>\n",
       "      <td>27.879450</td>\n",
       "      <td>0.031852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5910.513184</td>\n",
       "      <td>5910.513184</td>\n",
       "      <td>27.931767</td>\n",
       "      <td>27.931740</td>\n",
       "      <td>0.031852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>27.357334</td>\n",
       "      <td>27.357319</td>\n",
       "      <td>28.381067</td>\n",
       "      <td>28.381046</td>\n",
       "      <td>0.031852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>27.327631</td>\n",
       "      <td>27.327610</td>\n",
       "      <td>28.504025</td>\n",
       "      <td>28.504002</td>\n",
       "      <td>0.031852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>26.894548</td>\n",
       "      <td>26.894533</td>\n",
       "      <td>28.829845</td>\n",
       "      <td>28.829821</td>\n",
       "      <td>0.031852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>26.630066</td>\n",
       "      <td>26.630039</td>\n",
       "      <td>28.983091</td>\n",
       "      <td>28.983061</td>\n",
       "      <td>0.031852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>24.627363</td>\n",
       "      <td>24.627323</td>\n",
       "      <td>29.035677</td>\n",
       "      <td>29.035652</td>\n",
       "      <td>0.015926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>27.440033</td>\n",
       "      <td>27.440004</td>\n",
       "      <td>29.042770</td>\n",
       "      <td>29.042744</td>\n",
       "      <td>0.031852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>28.598036</td>\n",
       "      <td>28.598013</td>\n",
       "      <td>29.285194</td>\n",
       "      <td>29.285173</td>\n",
       "      <td>0.031852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "      <td>25.681602</td>\n",
       "      <td>25.681570</td>\n",
       "      <td>29.447960</td>\n",
       "      <td>29.447933</td>\n",
       "      <td>0.015926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>24.504501</td>\n",
       "      <td>24.504475</td>\n",
       "      <td>29.486563</td>\n",
       "      <td>29.486536</td>\n",
       "      <td>0.015926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>24.059938</td>\n",
       "      <td>24.059904</td>\n",
       "      <td>29.573658</td>\n",
       "      <td>29.573629</td>\n",
       "      <td>0.015926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>22.732725</td>\n",
       "      <td>22.732704</td>\n",
       "      <td>29.697323</td>\n",
       "      <td>29.697296</td>\n",
       "      <td>0.003982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>23.908516</td>\n",
       "      <td>23.908489</td>\n",
       "      <td>29.701668</td>\n",
       "      <td>29.701643</td>\n",
       "      <td>0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>22.419641</td>\n",
       "      <td>22.419611</td>\n",
       "      <td>29.723967</td>\n",
       "      <td>29.723938</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>23.350046</td>\n",
       "      <td>23.350019</td>\n",
       "      <td>29.726282</td>\n",
       "      <td>29.726257</td>\n",
       "      <td>0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>24.196211</td>\n",
       "      <td>24.196175</td>\n",
       "      <td>29.801182</td>\n",
       "      <td>29.801151</td>\n",
       "      <td>0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>23.114685</td>\n",
       "      <td>23.114656</td>\n",
       "      <td>29.827456</td>\n",
       "      <td>29.827429</td>\n",
       "      <td>0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>37</td>\n",
       "      <td>22.526140</td>\n",
       "      <td>22.526106</td>\n",
       "      <td>29.829334</td>\n",
       "      <td>29.829309</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>22.816433</td>\n",
       "      <td>22.816401</td>\n",
       "      <td>29.846138</td>\n",
       "      <td>29.846107</td>\n",
       "      <td>0.003982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>41</td>\n",
       "      <td>22.051027</td>\n",
       "      <td>22.050999</td>\n",
       "      <td>29.857973</td>\n",
       "      <td>29.857944</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>38</td>\n",
       "      <td>22.354839</td>\n",
       "      <td>22.354807</td>\n",
       "      <td>29.878489</td>\n",
       "      <td>29.878464</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>29</td>\n",
       "      <td>22.847410</td>\n",
       "      <td>22.847387</td>\n",
       "      <td>29.928818</td>\n",
       "      <td>29.928789</td>\n",
       "      <td>0.003982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14</td>\n",
       "      <td>25.371428</td>\n",
       "      <td>25.371414</td>\n",
       "      <td>29.929905</td>\n",
       "      <td>29.929884</td>\n",
       "      <td>0.015926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>22.824268</td>\n",
       "      <td>22.824244</td>\n",
       "      <td>29.970486</td>\n",
       "      <td>29.970455</td>\n",
       "      <td>0.003982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>22.672132</td>\n",
       "      <td>22.672104</td>\n",
       "      <td>29.984617</td>\n",
       "      <td>29.984592</td>\n",
       "      <td>0.003982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>42</td>\n",
       "      <td>22.426224</td>\n",
       "      <td>22.426195</td>\n",
       "      <td>30.017410</td>\n",
       "      <td>30.017385</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>35</td>\n",
       "      <td>22.224602</td>\n",
       "      <td>22.224571</td>\n",
       "      <td>30.024265</td>\n",
       "      <td>30.024240</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>33</td>\n",
       "      <td>22.304762</td>\n",
       "      <td>22.304737</td>\n",
       "      <td>30.039528</td>\n",
       "      <td>30.039507</td>\n",
       "      <td>0.003982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20</td>\n",
       "      <td>23.985748</td>\n",
       "      <td>23.985723</td>\n",
       "      <td>30.039616</td>\n",
       "      <td>30.039587</td>\n",
       "      <td>0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>22.872826</td>\n",
       "      <td>22.872795</td>\n",
       "      <td>30.095037</td>\n",
       "      <td>30.095013</td>\n",
       "      <td>0.003982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>39</td>\n",
       "      <td>22.125002</td>\n",
       "      <td>22.124975</td>\n",
       "      <td>30.175314</td>\n",
       "      <td>30.175285</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10</td>\n",
       "      <td>26.954260</td>\n",
       "      <td>26.954233</td>\n",
       "      <td>30.215918</td>\n",
       "      <td>30.215895</td>\n",
       "      <td>0.031852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>18</td>\n",
       "      <td>24.864429</td>\n",
       "      <td>24.864403</td>\n",
       "      <td>30.233625</td>\n",
       "      <td>30.233601</td>\n",
       "      <td>0.015926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>22.063190</td>\n",
       "      <td>22.063166</td>\n",
       "      <td>30.339052</td>\n",
       "      <td>30.339024</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>24</td>\n",
       "      <td>23.834696</td>\n",
       "      <td>23.834675</td>\n",
       "      <td>30.854246</td>\n",
       "      <td>30.854219</td>\n",
       "      <td>0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>21</td>\n",
       "      <td>24.325954</td>\n",
       "      <td>24.325930</td>\n",
       "      <td>31.273264</td>\n",
       "      <td>31.273235</td>\n",
       "      <td>0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>34</td>\n",
       "      <td>22.561497</td>\n",
       "      <td>22.561472</td>\n",
       "      <td>31.735327</td>\n",
       "      <td>31.735298</td>\n",
       "      <td>0.003982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>12</td>\n",
       "      <td>24.945326</td>\n",
       "      <td>24.945301</td>\n",
       "      <td>32.083378</td>\n",
       "      <td>32.083347</td>\n",
       "      <td>0.015926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>28.747015</td>\n",
       "      <td>28.746994</td>\n",
       "      <td>32.238186</td>\n",
       "      <td>32.238159</td>\n",
       "      <td>0.031852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>23</td>\n",
       "      <td>23.969419</td>\n",
       "      <td>23.969385</td>\n",
       "      <td>33.437180</td>\n",
       "      <td>33.437149</td>\n",
       "      <td>0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16</td>\n",
       "      <td>24.581305</td>\n",
       "      <td>24.581284</td>\n",
       "      <td>36.638912</td>\n",
       "      <td>36.638889</td>\n",
       "      <td>0.015926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch         loss          mse   val_loss    val_mse        lr\n",
       "0       2    29.398306    29.398285  27.227404  27.227379  0.031852\n",
       "1       5    27.828239    27.828220  27.879478  27.879450  0.031852\n",
       "2       0  5910.513184  5910.513184  27.931767  27.931740  0.031852\n",
       "3       8    27.357334    27.357319  28.381067  28.381046  0.031852\n",
       "4       7    27.327631    27.327610  28.504025  28.504002  0.031852\n",
       "5       6    26.894548    26.894533  28.829845  28.829821  0.031852\n",
       "6       9    26.630066    26.630039  28.983091  28.983061  0.031852\n",
       "7      11    24.627363    24.627323  29.035677  29.035652  0.015926\n",
       "8       4    27.440033    27.440004  29.042770  29.042744  0.031852\n",
       "9       3    28.598036    28.598013  29.285194  29.285173  0.031852\n",
       "10     17    25.681602    25.681570  29.447960  29.447933  0.015926\n",
       "11     13    24.504501    24.504475  29.486563  29.486536  0.015926\n",
       "12     15    24.059938    24.059904  29.573658  29.573629  0.015926\n",
       "13     30    22.732725    22.732704  29.697323  29.697296  0.003982\n",
       "14     22    23.908516    23.908489  29.701668  29.701643  0.007963\n",
       "15     40    22.419641    22.419611  29.723967  29.723938  0.001991\n",
       "16     25    23.350046    23.350019  29.726282  29.726257  0.007963\n",
       "17     19    24.196211    24.196175  29.801182  29.801151  0.007963\n",
       "18     26    23.114685    23.114656  29.827456  29.827429  0.007963\n",
       "19     37    22.526140    22.526106  29.829334  29.829309  0.001991\n",
       "20     31    22.816433    22.816401  29.846138  29.846107  0.003982\n",
       "21     41    22.051027    22.050999  29.857973  29.857944  0.001991\n",
       "22     38    22.354839    22.354807  29.878489  29.878464  0.001991\n",
       "23     29    22.847410    22.847387  29.928818  29.928789  0.003982\n",
       "24     14    25.371428    25.371414  29.929905  29.929884  0.015926\n",
       "25     27    22.824268    22.824244  29.970486  29.970455  0.003982\n",
       "26     28    22.672132    22.672104  29.984617  29.984592  0.003982\n",
       "27     42    22.426224    22.426195  30.017410  30.017385  0.001991\n",
       "28     35    22.224602    22.224571  30.024265  30.024240  0.001991\n",
       "29     33    22.304762    22.304737  30.039528  30.039507  0.003982\n",
       "30     20    23.985748    23.985723  30.039616  30.039587  0.007963\n",
       "31     32    22.872826    22.872795  30.095037  30.095013  0.003982\n",
       "32     39    22.125002    22.124975  30.175314  30.175285  0.001991\n",
       "33     10    26.954260    26.954233  30.215918  30.215895  0.031852\n",
       "34     18    24.864429    24.864403  30.233625  30.233601  0.015926\n",
       "35     36    22.063190    22.063166  30.339052  30.339024  0.001991\n",
       "36     24    23.834696    23.834675  30.854246  30.854219  0.007963\n",
       "37     21    24.325954    24.325930  31.273264  31.273235  0.007963\n",
       "38     34    22.561497    22.561472  31.735327  31.735298  0.003982\n",
       "39     12    24.945326    24.945301  32.083378  32.083347  0.015926\n",
       "40      1    28.747015    28.746994  32.238186  32.238159  0.031852\n",
       "41     23    23.969419    23.969385  33.437180  33.437149  0.007963\n",
       "42     16    24.581305    24.581284  36.638912  36.638889  0.015926"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menyusun rekam jejak model berdasarkan nilai MSE pada setiap epoch, diurutkan dari yang terbaik.\n",
    "history_df = pd.DataFrame(history.history).sort_values('val_mse').reset_index()\n",
    "history_df.rename(columns = {'index': 'epoch'}, inplace = True)\n",
    "history_df.to_csv('history_{}.csv'.format(codename), index = False)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da23e7d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:33:49.886043Z",
     "iopub.status.busy": "2021-11-04T11:33:49.885412Z",
     "iopub.status.idle": "2021-11-04T11:33:50.157730Z",
     "shell.execute_reply": "2021-11-04T11:33:50.157147Z"
    },
    "papermill": {
     "duration": 0.435568,
     "end_time": "2021-11-04T11:33:50.157898",
     "exception": false,
     "start_time": "2021-11-04T11:33:49.722330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Menyimpan nilai prediksi validasi dan testing diurutkan berdasarkan nilai validasi MSE terbaik.\n",
    "best_valid_preds = pd.DataFrame()\n",
    "best_test_preds = pd.DataFrame()\n",
    "\n",
    "for temp_index in list(history_df.iloc[:, 0]):\n",
    "    temp_df_valid = pd.read_csv('./valid_preds_{}.csv'.format(temp_index))\n",
    "    temp_df_test = pd.read_csv('./test_preds_{}.csv'.format(temp_index))\n",
    "    best_valid_preds = pd.concat([best_valid_preds, temp_df_valid], axis = 1, ignore_index = True)\n",
    "    best_test_preds = pd.concat([best_test_preds, temp_df_test], axis = 1, ignore_index = True)\n",
    "\n",
    "best_valid_preds.to_csv('valid_preds_{}.csv'.format(codename), index = False)\n",
    "best_test_preds.to_csv('test_preds_{}.csv'.format(codename), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39bcaadd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:33:50.485113Z",
     "iopub.status.busy": "2021-11-04T11:33:50.484451Z",
     "iopub.status.idle": "2021-11-04T11:33:50.492989Z",
     "shell.execute_reply": "2021-11-04T11:33:50.492402Z"
    },
    "papermill": {
     "duration": 0.173188,
     "end_time": "2021-11-04T11:33:50.493151",
     "exception": false,
     "start_time": "2021-11-04T11:33:50.319963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Membuang file yang sudah tidak diperlukan.\n",
    "for temp_index in list(history_df.iloc[:, 0]):\n",
    "    os.remove('./valid_preds_{}.csv'.format(temp_index))\n",
    "    os.remove('./test_preds_{}.csv'.format(temp_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db8b71ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:33:50.816933Z",
     "iopub.status.busy": "2021-11-04T11:33:50.816245Z",
     "iopub.status.idle": "2021-11-04T11:33:50.850850Z",
     "shell.execute_reply": "2021-11-04T11:33:50.851363Z"
    },
    "papermill": {
     "duration": 0.197994,
     "end_time": "2021-11-04T11:33:50.851534",
     "exception": false,
     "start_time": "2021-11-04T11:33:50.653540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.637604</td>\n",
       "      <td>28.117357</td>\n",
       "      <td>26.004679</td>\n",
       "      <td>27.655016</td>\n",
       "      <td>28.665780</td>\n",
       "      <td>27.519726</td>\n",
       "      <td>30.071318</td>\n",
       "      <td>28.924578</td>\n",
       "      <td>27.897972</td>\n",
       "      <td>29.341675</td>\n",
       "      <td>...</td>\n",
       "      <td>29.718182</td>\n",
       "      <td>29.973950</td>\n",
       "      <td>29.467155</td>\n",
       "      <td>27.726460</td>\n",
       "      <td>27.422060</td>\n",
       "      <td>30.153042</td>\n",
       "      <td>30.834421</td>\n",
       "      <td>28.337545</td>\n",
       "      <td>30.745184</td>\n",
       "      <td>26.601946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.688211</td>\n",
       "      <td>26.426899</td>\n",
       "      <td>26.111639</td>\n",
       "      <td>25.761957</td>\n",
       "      <td>25.223494</td>\n",
       "      <td>25.260588</td>\n",
       "      <td>25.967344</td>\n",
       "      <td>25.543987</td>\n",
       "      <td>24.172924</td>\n",
       "      <td>27.380220</td>\n",
       "      <td>...</td>\n",
       "      <td>26.771608</td>\n",
       "      <td>25.785257</td>\n",
       "      <td>26.938179</td>\n",
       "      <td>25.003088</td>\n",
       "      <td>24.394222</td>\n",
       "      <td>27.756042</td>\n",
       "      <td>27.120502</td>\n",
       "      <td>27.664284</td>\n",
       "      <td>27.801070</td>\n",
       "      <td>23.039782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.310623</td>\n",
       "      <td>27.909264</td>\n",
       "      <td>26.862146</td>\n",
       "      <td>26.969212</td>\n",
       "      <td>27.676025</td>\n",
       "      <td>27.755926</td>\n",
       "      <td>28.543736</td>\n",
       "      <td>27.727266</td>\n",
       "      <td>27.057482</td>\n",
       "      <td>29.094389</td>\n",
       "      <td>...</td>\n",
       "      <td>28.894686</td>\n",
       "      <td>29.133940</td>\n",
       "      <td>29.601313</td>\n",
       "      <td>27.946877</td>\n",
       "      <td>27.617220</td>\n",
       "      <td>30.430000</td>\n",
       "      <td>29.964441</td>\n",
       "      <td>29.056028</td>\n",
       "      <td>30.975372</td>\n",
       "      <td>26.080479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.071915</td>\n",
       "      <td>26.555843</td>\n",
       "      <td>26.429771</td>\n",
       "      <td>26.234629</td>\n",
       "      <td>25.023033</td>\n",
       "      <td>24.855778</td>\n",
       "      <td>26.890554</td>\n",
       "      <td>26.102520</td>\n",
       "      <td>24.713118</td>\n",
       "      <td>26.597990</td>\n",
       "      <td>...</td>\n",
       "      <td>27.659143</td>\n",
       "      <td>26.559692</td>\n",
       "      <td>26.782053</td>\n",
       "      <td>25.282887</td>\n",
       "      <td>25.081484</td>\n",
       "      <td>27.835110</td>\n",
       "      <td>28.070595</td>\n",
       "      <td>27.726720</td>\n",
       "      <td>28.645582</td>\n",
       "      <td>24.096401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.591867</td>\n",
       "      <td>24.890882</td>\n",
       "      <td>26.431067</td>\n",
       "      <td>24.276987</td>\n",
       "      <td>22.885195</td>\n",
       "      <td>23.993977</td>\n",
       "      <td>24.476284</td>\n",
       "      <td>23.656921</td>\n",
       "      <td>23.548700</td>\n",
       "      <td>26.112106</td>\n",
       "      <td>...</td>\n",
       "      <td>24.908169</td>\n",
       "      <td>23.567759</td>\n",
       "      <td>23.166605</td>\n",
       "      <td>22.439762</td>\n",
       "      <td>22.371180</td>\n",
       "      <td>24.353514</td>\n",
       "      <td>24.948156</td>\n",
       "      <td>27.860880</td>\n",
       "      <td>25.308973</td>\n",
       "      <td>20.850916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>27.199207</td>\n",
       "      <td>27.046242</td>\n",
       "      <td>26.757582</td>\n",
       "      <td>27.105196</td>\n",
       "      <td>27.115826</td>\n",
       "      <td>25.969442</td>\n",
       "      <td>28.049020</td>\n",
       "      <td>27.115091</td>\n",
       "      <td>26.137133</td>\n",
       "      <td>28.452415</td>\n",
       "      <td>...</td>\n",
       "      <td>28.096720</td>\n",
       "      <td>27.651144</td>\n",
       "      <td>28.250656</td>\n",
       "      <td>26.257530</td>\n",
       "      <td>26.364439</td>\n",
       "      <td>29.251890</td>\n",
       "      <td>29.053074</td>\n",
       "      <td>28.894728</td>\n",
       "      <td>29.497019</td>\n",
       "      <td>24.807331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>26.465351</td>\n",
       "      <td>25.526050</td>\n",
       "      <td>26.318027</td>\n",
       "      <td>25.149324</td>\n",
       "      <td>25.419890</td>\n",
       "      <td>24.931023</td>\n",
       "      <td>26.137100</td>\n",
       "      <td>25.582771</td>\n",
       "      <td>25.106047</td>\n",
       "      <td>27.505249</td>\n",
       "      <td>...</td>\n",
       "      <td>26.503153</td>\n",
       "      <td>24.569300</td>\n",
       "      <td>24.188778</td>\n",
       "      <td>22.952110</td>\n",
       "      <td>22.655663</td>\n",
       "      <td>25.361902</td>\n",
       "      <td>26.858742</td>\n",
       "      <td>28.007309</td>\n",
       "      <td>25.881308</td>\n",
       "      <td>21.904520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>28.086267</td>\n",
       "      <td>27.605988</td>\n",
       "      <td>27.132082</td>\n",
       "      <td>27.589708</td>\n",
       "      <td>27.655561</td>\n",
       "      <td>27.856623</td>\n",
       "      <td>28.656034</td>\n",
       "      <td>28.212324</td>\n",
       "      <td>27.602068</td>\n",
       "      <td>30.007603</td>\n",
       "      <td>...</td>\n",
       "      <td>29.145819</td>\n",
       "      <td>28.881603</td>\n",
       "      <td>28.533972</td>\n",
       "      <td>27.083721</td>\n",
       "      <td>27.002108</td>\n",
       "      <td>29.458176</td>\n",
       "      <td>30.386208</td>\n",
       "      <td>29.723207</td>\n",
       "      <td>30.233156</td>\n",
       "      <td>26.146114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>26.942587</td>\n",
       "      <td>27.931377</td>\n",
       "      <td>26.595820</td>\n",
       "      <td>29.061728</td>\n",
       "      <td>28.250883</td>\n",
       "      <td>27.604996</td>\n",
       "      <td>29.267874</td>\n",
       "      <td>29.006062</td>\n",
       "      <td>26.128918</td>\n",
       "      <td>28.604803</td>\n",
       "      <td>...</td>\n",
       "      <td>30.197302</td>\n",
       "      <td>29.729044</td>\n",
       "      <td>29.367842</td>\n",
       "      <td>28.080463</td>\n",
       "      <td>27.538868</td>\n",
       "      <td>30.195920</td>\n",
       "      <td>31.141127</td>\n",
       "      <td>28.434996</td>\n",
       "      <td>31.153177</td>\n",
       "      <td>26.798021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>27.833296</td>\n",
       "      <td>26.566689</td>\n",
       "      <td>27.195988</td>\n",
       "      <td>25.679987</td>\n",
       "      <td>25.594725</td>\n",
       "      <td>25.870708</td>\n",
       "      <td>26.537386</td>\n",
       "      <td>25.633470</td>\n",
       "      <td>25.426570</td>\n",
       "      <td>28.790483</td>\n",
       "      <td>...</td>\n",
       "      <td>26.777462</td>\n",
       "      <td>25.981833</td>\n",
       "      <td>26.778515</td>\n",
       "      <td>25.711780</td>\n",
       "      <td>24.960848</td>\n",
       "      <td>27.681921</td>\n",
       "      <td>28.178068</td>\n",
       "      <td>30.094618</td>\n",
       "      <td>28.484346</td>\n",
       "      <td>23.308920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5   \\\n",
       "0    27.637604  28.117357  26.004679  27.655016  28.665780  27.519726   \n",
       "1    26.688211  26.426899  26.111639  25.761957  25.223494  25.260588   \n",
       "2    28.310623  27.909264  26.862146  26.969212  27.676025  27.755926   \n",
       "3    26.071915  26.555843  26.429771  26.234629  25.023033  24.855778   \n",
       "4    25.591867  24.890882  26.431067  24.276987  22.885195  23.993977   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "456  27.199207  27.046242  26.757582  27.105196  27.115826  25.969442   \n",
       "457  26.465351  25.526050  26.318027  25.149324  25.419890  24.931023   \n",
       "458  28.086267  27.605988  27.132082  27.589708  27.655561  27.856623   \n",
       "459  26.942587  27.931377  26.595820  29.061728  28.250883  27.604996   \n",
       "460  27.833296  26.566689  27.195988  25.679987  25.594725  25.870708   \n",
       "\n",
       "            6          7          8          9   ...         33         34  \\\n",
       "0    30.071318  28.924578  27.897972  29.341675  ...  29.718182  29.973950   \n",
       "1    25.967344  25.543987  24.172924  27.380220  ...  26.771608  25.785257   \n",
       "2    28.543736  27.727266  27.057482  29.094389  ...  28.894686  29.133940   \n",
       "3    26.890554  26.102520  24.713118  26.597990  ...  27.659143  26.559692   \n",
       "4    24.476284  23.656921  23.548700  26.112106  ...  24.908169  23.567759   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "456  28.049020  27.115091  26.137133  28.452415  ...  28.096720  27.651144   \n",
       "457  26.137100  25.582771  25.106047  27.505249  ...  26.503153  24.569300   \n",
       "458  28.656034  28.212324  27.602068  30.007603  ...  29.145819  28.881603   \n",
       "459  29.267874  29.006062  26.128918  28.604803  ...  30.197302  29.729044   \n",
       "460  26.537386  25.633470  25.426570  28.790483  ...  26.777462  25.981833   \n",
       "\n",
       "            35         36         37         38         39         40  \\\n",
       "0    29.467155  27.726460  27.422060  30.153042  30.834421  28.337545   \n",
       "1    26.938179  25.003088  24.394222  27.756042  27.120502  27.664284   \n",
       "2    29.601313  27.946877  27.617220  30.430000  29.964441  29.056028   \n",
       "3    26.782053  25.282887  25.081484  27.835110  28.070595  27.726720   \n",
       "4    23.166605  22.439762  22.371180  24.353514  24.948156  27.860880   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "456  28.250656  26.257530  26.364439  29.251890  29.053074  28.894728   \n",
       "457  24.188778  22.952110  22.655663  25.361902  26.858742  28.007309   \n",
       "458  28.533972  27.083721  27.002108  29.458176  30.386208  29.723207   \n",
       "459  29.367842  28.080463  27.538868  30.195920  31.141127  28.434996   \n",
       "460  26.778515  25.711780  24.960848  27.681921  28.178068  30.094618   \n",
       "\n",
       "            41         42  \n",
       "0    30.745184  26.601946  \n",
       "1    27.801070  23.039782  \n",
       "2    30.975372  26.080479  \n",
       "3    28.645582  24.096401  \n",
       "4    25.308973  20.850916  \n",
       "..         ...        ...  \n",
       "456  29.497019  24.807331  \n",
       "457  25.881308  21.904520  \n",
       "458  30.233156  26.146114  \n",
       "459  31.153177  26.798021  \n",
       "460  28.484346  23.308920  \n",
       "\n",
       "[461 rows x 43 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan prediksi data validasi diurutkan berdasarkan nilai validasi MSE terbaik.\n",
    "best_valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c173af5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:33:51.180549Z",
     "iopub.status.busy": "2021-11-04T11:33:51.179899Z",
     "iopub.status.idle": "2021-11-04T11:33:51.213993Z",
     "shell.execute_reply": "2021-11-04T11:33:51.214535Z"
    },
    "papermill": {
     "duration": 0.200561,
     "end_time": "2021-11-04T11:33:51.214703",
     "exception": false,
     "start_time": "2021-11-04T11:33:51.014142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.341003</td>\n",
       "      <td>26.656830</td>\n",
       "      <td>26.352552</td>\n",
       "      <td>25.491250</td>\n",
       "      <td>24.819984</td>\n",
       "      <td>24.827883</td>\n",
       "      <td>25.827549</td>\n",
       "      <td>24.683477</td>\n",
       "      <td>24.523853</td>\n",
       "      <td>27.709467</td>\n",
       "      <td>...</td>\n",
       "      <td>26.509752</td>\n",
       "      <td>23.898682</td>\n",
       "      <td>23.211130</td>\n",
       "      <td>21.625038</td>\n",
       "      <td>22.033453</td>\n",
       "      <td>24.113054</td>\n",
       "      <td>26.333778</td>\n",
       "      <td>28.235796</td>\n",
       "      <td>24.908257</td>\n",
       "      <td>20.624952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.881073</td>\n",
       "      <td>27.993652</td>\n",
       "      <td>26.099710</td>\n",
       "      <td>27.935818</td>\n",
       "      <td>27.565756</td>\n",
       "      <td>26.752098</td>\n",
       "      <td>29.119207</td>\n",
       "      <td>28.774595</td>\n",
       "      <td>27.237530</td>\n",
       "      <td>28.858723</td>\n",
       "      <td>...</td>\n",
       "      <td>29.536540</td>\n",
       "      <td>29.410208</td>\n",
       "      <td>29.846620</td>\n",
       "      <td>27.975157</td>\n",
       "      <td>27.681910</td>\n",
       "      <td>30.598830</td>\n",
       "      <td>30.957146</td>\n",
       "      <td>27.624504</td>\n",
       "      <td>30.912327</td>\n",
       "      <td>26.412512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.414585</td>\n",
       "      <td>27.126595</td>\n",
       "      <td>26.828447</td>\n",
       "      <td>26.385307</td>\n",
       "      <td>25.922752</td>\n",
       "      <td>26.600958</td>\n",
       "      <td>26.962290</td>\n",
       "      <td>26.229030</td>\n",
       "      <td>26.019272</td>\n",
       "      <td>28.679815</td>\n",
       "      <td>...</td>\n",
       "      <td>27.617813</td>\n",
       "      <td>27.505373</td>\n",
       "      <td>26.628490</td>\n",
       "      <td>25.453218</td>\n",
       "      <td>25.478966</td>\n",
       "      <td>27.470240</td>\n",
       "      <td>28.148418</td>\n",
       "      <td>29.334232</td>\n",
       "      <td>28.301601</td>\n",
       "      <td>23.627237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.745600</td>\n",
       "      <td>26.774225</td>\n",
       "      <td>26.553062</td>\n",
       "      <td>26.910463</td>\n",
       "      <td>26.352129</td>\n",
       "      <td>25.544851</td>\n",
       "      <td>27.169287</td>\n",
       "      <td>26.221462</td>\n",
       "      <td>25.431541</td>\n",
       "      <td>28.292162</td>\n",
       "      <td>...</td>\n",
       "      <td>27.375883</td>\n",
       "      <td>26.176968</td>\n",
       "      <td>26.735678</td>\n",
       "      <td>24.759596</td>\n",
       "      <td>24.792559</td>\n",
       "      <td>27.608810</td>\n",
       "      <td>28.038498</td>\n",
       "      <td>29.231600</td>\n",
       "      <td>28.211113</td>\n",
       "      <td>23.501852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.757060</td>\n",
       "      <td>27.358963</td>\n",
       "      <td>26.543670</td>\n",
       "      <td>27.177164</td>\n",
       "      <td>26.990850</td>\n",
       "      <td>26.231775</td>\n",
       "      <td>28.325802</td>\n",
       "      <td>27.858091</td>\n",
       "      <td>26.216870</td>\n",
       "      <td>28.708954</td>\n",
       "      <td>...</td>\n",
       "      <td>28.719084</td>\n",
       "      <td>29.340620</td>\n",
       "      <td>29.888842</td>\n",
       "      <td>28.091690</td>\n",
       "      <td>27.664377</td>\n",
       "      <td>30.876875</td>\n",
       "      <td>29.685616</td>\n",
       "      <td>28.151577</td>\n",
       "      <td>31.054663</td>\n",
       "      <td>25.942402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>27.378551</td>\n",
       "      <td>27.368256</td>\n",
       "      <td>25.883772</td>\n",
       "      <td>26.820885</td>\n",
       "      <td>28.309027</td>\n",
       "      <td>26.881363</td>\n",
       "      <td>28.053282</td>\n",
       "      <td>27.374329</td>\n",
       "      <td>26.418747</td>\n",
       "      <td>28.780844</td>\n",
       "      <td>...</td>\n",
       "      <td>28.681063</td>\n",
       "      <td>28.975096</td>\n",
       "      <td>28.900429</td>\n",
       "      <td>26.829094</td>\n",
       "      <td>26.539215</td>\n",
       "      <td>29.751904</td>\n",
       "      <td>30.078802</td>\n",
       "      <td>28.581896</td>\n",
       "      <td>29.628237</td>\n",
       "      <td>25.482264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>26.091764</td>\n",
       "      <td>27.820053</td>\n",
       "      <td>26.023531</td>\n",
       "      <td>27.598866</td>\n",
       "      <td>26.967910</td>\n",
       "      <td>26.393850</td>\n",
       "      <td>27.513660</td>\n",
       "      <td>27.002909</td>\n",
       "      <td>24.473782</td>\n",
       "      <td>26.639906</td>\n",
       "      <td>...</td>\n",
       "      <td>28.973751</td>\n",
       "      <td>28.909100</td>\n",
       "      <td>29.704836</td>\n",
       "      <td>27.409475</td>\n",
       "      <td>27.056643</td>\n",
       "      <td>30.415117</td>\n",
       "      <td>29.427864</td>\n",
       "      <td>27.950512</td>\n",
       "      <td>30.535990</td>\n",
       "      <td>25.054483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>26.751791</td>\n",
       "      <td>26.026066</td>\n",
       "      <td>26.021450</td>\n",
       "      <td>25.398706</td>\n",
       "      <td>24.784103</td>\n",
       "      <td>25.140700</td>\n",
       "      <td>26.575949</td>\n",
       "      <td>25.913294</td>\n",
       "      <td>25.060284</td>\n",
       "      <td>27.574995</td>\n",
       "      <td>...</td>\n",
       "      <td>27.340546</td>\n",
       "      <td>25.085630</td>\n",
       "      <td>26.068258</td>\n",
       "      <td>24.072630</td>\n",
       "      <td>24.105015</td>\n",
       "      <td>27.000053</td>\n",
       "      <td>27.767477</td>\n",
       "      <td>27.536013</td>\n",
       "      <td>27.078135</td>\n",
       "      <td>23.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>23.654373</td>\n",
       "      <td>24.116120</td>\n",
       "      <td>26.192616</td>\n",
       "      <td>23.795700</td>\n",
       "      <td>22.163174</td>\n",
       "      <td>21.682087</td>\n",
       "      <td>24.051205</td>\n",
       "      <td>23.334803</td>\n",
       "      <td>21.334528</td>\n",
       "      <td>24.451176</td>\n",
       "      <td>...</td>\n",
       "      <td>25.224850</td>\n",
       "      <td>23.427877</td>\n",
       "      <td>23.462593</td>\n",
       "      <td>22.515871</td>\n",
       "      <td>22.316580</td>\n",
       "      <td>24.643505</td>\n",
       "      <td>24.665611</td>\n",
       "      <td>26.606518</td>\n",
       "      <td>25.806068</td>\n",
       "      <td>21.112024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>27.307749</td>\n",
       "      <td>26.355450</td>\n",
       "      <td>26.681604</td>\n",
       "      <td>26.156374</td>\n",
       "      <td>25.597193</td>\n",
       "      <td>25.818184</td>\n",
       "      <td>26.785300</td>\n",
       "      <td>25.649847</td>\n",
       "      <td>25.274643</td>\n",
       "      <td>27.490402</td>\n",
       "      <td>...</td>\n",
       "      <td>27.041634</td>\n",
       "      <td>25.948750</td>\n",
       "      <td>25.441500</td>\n",
       "      <td>24.360624</td>\n",
       "      <td>24.354103</td>\n",
       "      <td>26.453676</td>\n",
       "      <td>27.573318</td>\n",
       "      <td>28.897660</td>\n",
       "      <td>27.154116</td>\n",
       "      <td>22.837412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5   \\\n",
       "0    26.341003  26.656830  26.352552  25.491250  24.819984  24.827883   \n",
       "1    27.881073  27.993652  26.099710  27.935818  27.565756  26.752098   \n",
       "2    27.414585  27.126595  26.828447  26.385307  25.922752  26.600958   \n",
       "3    26.745600  26.774225  26.553062  26.910463  26.352129  25.544851   \n",
       "4    26.757060  27.358963  26.543670  27.177164  26.990850  26.231775   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "985  27.378551  27.368256  25.883772  26.820885  28.309027  26.881363   \n",
       "986  26.091764  27.820053  26.023531  27.598866  26.967910  26.393850   \n",
       "987  26.751791  26.026066  26.021450  25.398706  24.784103  25.140700   \n",
       "988  23.654373  24.116120  26.192616  23.795700  22.163174  21.682087   \n",
       "989  27.307749  26.355450  26.681604  26.156374  25.597193  25.818184   \n",
       "\n",
       "            6          7          8          9   ...         33         34  \\\n",
       "0    25.827549  24.683477  24.523853  27.709467  ...  26.509752  23.898682   \n",
       "1    29.119207  28.774595  27.237530  28.858723  ...  29.536540  29.410208   \n",
       "2    26.962290  26.229030  26.019272  28.679815  ...  27.617813  27.505373   \n",
       "3    27.169287  26.221462  25.431541  28.292162  ...  27.375883  26.176968   \n",
       "4    28.325802  27.858091  26.216870  28.708954  ...  28.719084  29.340620   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "985  28.053282  27.374329  26.418747  28.780844  ...  28.681063  28.975096   \n",
       "986  27.513660  27.002909  24.473782  26.639906  ...  28.973751  28.909100   \n",
       "987  26.575949  25.913294  25.060284  27.574995  ...  27.340546  25.085630   \n",
       "988  24.051205  23.334803  21.334528  24.451176  ...  25.224850  23.427877   \n",
       "989  26.785300  25.649847  25.274643  27.490402  ...  27.041634  25.948750   \n",
       "\n",
       "            35         36         37         38         39         40  \\\n",
       "0    23.211130  21.625038  22.033453  24.113054  26.333778  28.235796   \n",
       "1    29.846620  27.975157  27.681910  30.598830  30.957146  27.624504   \n",
       "2    26.628490  25.453218  25.478966  27.470240  28.148418  29.334232   \n",
       "3    26.735678  24.759596  24.792559  27.608810  28.038498  29.231600   \n",
       "4    29.888842  28.091690  27.664377  30.876875  29.685616  28.151577   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "985  28.900429  26.829094  26.539215  29.751904  30.078802  28.581896   \n",
       "986  29.704836  27.409475  27.056643  30.415117  29.427864  27.950512   \n",
       "987  26.068258  24.072630  24.105015  27.000053  27.767477  27.536013   \n",
       "988  23.462593  22.515871  22.316580  24.643505  24.665611  26.606518   \n",
       "989  25.441500  24.360624  24.354103  26.453676  27.573318  28.897660   \n",
       "\n",
       "            41         42  \n",
       "0    24.908257  20.624952  \n",
       "1    30.912327  26.412512  \n",
       "2    28.301601  23.627237  \n",
       "3    28.211113  23.501852  \n",
       "4    31.054663  25.942402  \n",
       "..         ...        ...  \n",
       "985  29.628237  25.482264  \n",
       "986  30.535990  25.054483  \n",
       "987  27.078135  23.124800  \n",
       "988  25.806068  21.112024  \n",
       "989  27.154116  22.837412  \n",
       "\n",
       "[990 rows x 43 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan prediksi data testing diurutkan berdasarkan nilai validasi MSE terbaik.\n",
    "best_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfe25040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:33:51.545790Z",
     "iopub.status.busy": "2021-11-04T11:33:51.545175Z",
     "iopub.status.idle": "2021-11-04T11:33:51.553213Z",
     "shell.execute_reply": "2021-11-04T11:33:51.552561Z"
    },
    "papermill": {
     "duration": 0.17415,
     "end_time": "2021-11-04T11:33:51.553350",
     "exception": false,
     "start_time": "2021-11-04T11:33:51.379200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nilai MSE pada data validasi:  27.22737827214936\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan nilai MSE terbaik pada data validasi.\n",
    "error = MSE(y_valid, best_valid_preds[0])\n",
    "print('nilai MSE pada data validasi: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bc6acc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T11:33:51.888654Z",
     "iopub.status.busy": "2021-11-04T11:33:51.888015Z",
     "iopub.status.idle": "2021-11-04T11:33:51.892488Z",
     "shell.execute_reply": "2021-11-04T11:33:51.893023Z"
    },
    "papermill": {
     "duration": 0.175196,
     "end_time": "2021-11-04T11:33:51.893211",
     "exception": false,
     "start_time": "2021-11-04T11:33:51.718015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total execution time: 0:19:35.858455\n"
     ]
    }
   ],
   "source": [
    "# Mencatat waktu berakhirnya keseluruhan program model dan prediksi data.\n",
    "global_end_time = time.time()\n",
    "\n",
    "# Menampilkan waktu eksekusi dari keseluruhan program model dan prediksi data.\n",
    "total_execution_time = datetime.timedelta(seconds = global_end_time - global_start_time)\n",
    "print(\"total execution time: %s\" % (total_execution_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1196.732142,
   "end_time": "2021-11-04T11:33:55.358882",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-04T11:13:58.626740",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
